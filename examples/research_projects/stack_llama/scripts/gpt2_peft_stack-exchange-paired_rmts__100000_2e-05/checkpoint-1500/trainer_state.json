{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.2496671105193076,
  "eval_steps": 500,
  "global_step": 1500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0016644474034620505,
      "grad_norm": 82.0,
      "learning_rate": 1.996671105193076e-05,
      "loss": 3.0074,
      "step": 10
    },
    {
      "epoch": 0.003328894806924101,
      "grad_norm": 205.0,
      "learning_rate": 1.9933422103861518e-05,
      "loss": 3.1453,
      "step": 20
    },
    {
      "epoch": 0.004993342210386152,
      "grad_norm": 17.625,
      "learning_rate": 1.990013315579228e-05,
      "loss": 2.3703,
      "step": 30
    },
    {
      "epoch": 0.006657789613848202,
      "grad_norm": 18.875,
      "learning_rate": 1.9866844207723038e-05,
      "loss": 2.0053,
      "step": 40
    },
    {
      "epoch": 0.008322237017310254,
      "grad_norm": 68.5,
      "learning_rate": 1.9833555259653796e-05,
      "loss": 1.8797,
      "step": 50
    },
    {
      "epoch": 0.009986684420772303,
      "grad_norm": 102.0,
      "learning_rate": 1.9800266311584554e-05,
      "loss": 2.2539,
      "step": 60
    },
    {
      "epoch": 0.011651131824234355,
      "grad_norm": 68.5,
      "learning_rate": 1.9766977363515315e-05,
      "loss": 2.3381,
      "step": 70
    },
    {
      "epoch": 0.013315579227696404,
      "grad_norm": 43.75,
      "learning_rate": 1.9733688415446073e-05,
      "loss": 2.4234,
      "step": 80
    },
    {
      "epoch": 0.014980026631158456,
      "grad_norm": 80.5,
      "learning_rate": 1.970039946737683e-05,
      "loss": 2.9699,
      "step": 90
    },
    {
      "epoch": 0.016644474034620507,
      "grad_norm": 110.5,
      "learning_rate": 1.966711051930759e-05,
      "loss": 2.0242,
      "step": 100
    },
    {
      "epoch": 0.018308921438082555,
      "grad_norm": 83.0,
      "learning_rate": 1.963382157123835e-05,
      "loss": 1.9811,
      "step": 110
    },
    {
      "epoch": 0.019973368841544607,
      "grad_norm": 14.375,
      "learning_rate": 1.960053262316911e-05,
      "loss": 1.4082,
      "step": 120
    },
    {
      "epoch": 0.021637816245006658,
      "grad_norm": 6.5625,
      "learning_rate": 1.956724367509987e-05,
      "loss": 2.027,
      "step": 130
    },
    {
      "epoch": 0.02330226364846871,
      "grad_norm": 38.25,
      "learning_rate": 1.953395472703063e-05,
      "loss": 1.9574,
      "step": 140
    },
    {
      "epoch": 0.024966711051930757,
      "grad_norm": 33.75,
      "learning_rate": 1.9500665778961387e-05,
      "loss": 1.8313,
      "step": 150
    },
    {
      "epoch": 0.02663115845539281,
      "grad_norm": 18.875,
      "learning_rate": 1.9467376830892145e-05,
      "loss": 1.3441,
      "step": 160
    },
    {
      "epoch": 0.02829560585885486,
      "grad_norm": 17.5,
      "learning_rate": 1.9434087882822907e-05,
      "loss": 1.6559,
      "step": 170
    },
    {
      "epoch": 0.02996005326231691,
      "grad_norm": 36.5,
      "learning_rate": 1.9400798934753665e-05,
      "loss": 1.5535,
      "step": 180
    },
    {
      "epoch": 0.03162450066577896,
      "grad_norm": 5.90625,
      "learning_rate": 1.9367509986684423e-05,
      "loss": 1.448,
      "step": 190
    },
    {
      "epoch": 0.033288948069241014,
      "grad_norm": 23.875,
      "learning_rate": 1.933422103861518e-05,
      "loss": 1.709,
      "step": 200
    },
    {
      "epoch": 0.03495339547270306,
      "grad_norm": 75.5,
      "learning_rate": 1.930093209054594e-05,
      "loss": 1.5148,
      "step": 210
    },
    {
      "epoch": 0.03661784287616511,
      "grad_norm": 65.5,
      "learning_rate": 1.92676431424767e-05,
      "loss": 1.5078,
      "step": 220
    },
    {
      "epoch": 0.038282290279627165,
      "grad_norm": 29.5,
      "learning_rate": 1.923435419440746e-05,
      "loss": 1.4211,
      "step": 230
    },
    {
      "epoch": 0.03994673768308921,
      "grad_norm": 54.25,
      "learning_rate": 1.9201065246338217e-05,
      "loss": 1.3559,
      "step": 240
    },
    {
      "epoch": 0.04161118508655127,
      "grad_norm": 13.125,
      "learning_rate": 1.9167776298268975e-05,
      "loss": 1.2094,
      "step": 250
    },
    {
      "epoch": 0.043275632490013316,
      "grad_norm": 29.625,
      "learning_rate": 1.9134487350199737e-05,
      "loss": 1.1453,
      "step": 260
    },
    {
      "epoch": 0.044940079893475364,
      "grad_norm": 22.25,
      "learning_rate": 1.9101198402130495e-05,
      "loss": 1.1934,
      "step": 270
    },
    {
      "epoch": 0.04660452729693742,
      "grad_norm": 33.5,
      "learning_rate": 1.9067909454061253e-05,
      "loss": 1.3309,
      "step": 280
    },
    {
      "epoch": 0.04826897470039947,
      "grad_norm": 55.25,
      "learning_rate": 1.903462050599201e-05,
      "loss": 1.5771,
      "step": 290
    },
    {
      "epoch": 0.049933422103861515,
      "grad_norm": 29.75,
      "learning_rate": 1.900133155792277e-05,
      "loss": 1.4488,
      "step": 300
    },
    {
      "epoch": 0.05159786950732357,
      "grad_norm": 16.25,
      "learning_rate": 1.896804260985353e-05,
      "loss": 1.1566,
      "step": 310
    },
    {
      "epoch": 0.05326231691078562,
      "grad_norm": 7.25,
      "learning_rate": 1.893475366178429e-05,
      "loss": 1.1781,
      "step": 320
    },
    {
      "epoch": 0.05492676431424767,
      "grad_norm": 14.75,
      "learning_rate": 1.8901464713715047e-05,
      "loss": 1.4129,
      "step": 330
    },
    {
      "epoch": 0.05659121171770972,
      "grad_norm": 28.75,
      "learning_rate": 1.8868175765645805e-05,
      "loss": 1.2781,
      "step": 340
    },
    {
      "epoch": 0.05825565912117177,
      "grad_norm": 8.875,
      "learning_rate": 1.8834886817576567e-05,
      "loss": 1.3512,
      "step": 350
    },
    {
      "epoch": 0.05992010652463382,
      "grad_norm": 13.25,
      "learning_rate": 1.8801597869507325e-05,
      "loss": 1.3848,
      "step": 360
    },
    {
      "epoch": 0.06158455392809587,
      "grad_norm": 34.25,
      "learning_rate": 1.8768308921438083e-05,
      "loss": 1.1969,
      "step": 370
    },
    {
      "epoch": 0.06324900133155792,
      "grad_norm": 47.25,
      "learning_rate": 1.873501997336884e-05,
      "loss": 1.3902,
      "step": 380
    },
    {
      "epoch": 0.06491344873501997,
      "grad_norm": 9.5,
      "learning_rate": 1.8701731025299603e-05,
      "loss": 0.9904,
      "step": 390
    },
    {
      "epoch": 0.06657789613848203,
      "grad_norm": 47.75,
      "learning_rate": 1.866844207723036e-05,
      "loss": 1.3535,
      "step": 400
    },
    {
      "epoch": 0.06824234354194407,
      "grad_norm": 36.25,
      "learning_rate": 1.8635153129161122e-05,
      "loss": 0.8746,
      "step": 410
    },
    {
      "epoch": 0.06990679094540612,
      "grad_norm": 19.125,
      "learning_rate": 1.860186418109188e-05,
      "loss": 1.4457,
      "step": 420
    },
    {
      "epoch": 0.07157123834886818,
      "grad_norm": 27.875,
      "learning_rate": 1.856857523302264e-05,
      "loss": 1.0061,
      "step": 430
    },
    {
      "epoch": 0.07323568575233022,
      "grad_norm": 24.625,
      "learning_rate": 1.8535286284953397e-05,
      "loss": 1.0208,
      "step": 440
    },
    {
      "epoch": 0.07490013315579228,
      "grad_norm": 29.5,
      "learning_rate": 1.8501997336884158e-05,
      "loss": 1.2641,
      "step": 450
    },
    {
      "epoch": 0.07656458055925433,
      "grad_norm": 26.375,
      "learning_rate": 1.8468708388814916e-05,
      "loss": 1.2277,
      "step": 460
    },
    {
      "epoch": 0.07822902796271637,
      "grad_norm": 42.25,
      "learning_rate": 1.8435419440745674e-05,
      "loss": 1.2291,
      "step": 470
    },
    {
      "epoch": 0.07989347536617843,
      "grad_norm": 51.25,
      "learning_rate": 1.8402130492676432e-05,
      "loss": 1.2758,
      "step": 480
    },
    {
      "epoch": 0.08155792276964048,
      "grad_norm": 53.75,
      "learning_rate": 1.836884154460719e-05,
      "loss": 1.5547,
      "step": 490
    },
    {
      "epoch": 0.08322237017310254,
      "grad_norm": 36.0,
      "learning_rate": 1.8335552596537952e-05,
      "loss": 1.292,
      "step": 500
    },
    {
      "epoch": 0.08322237017310254,
      "eval_accuracy": 0.49730379956860793,
      "eval_loss": 1.3427207469940186,
      "eval_runtime": 697.9048,
      "eval_samples_per_second": 34.543,
      "eval_steps_per_second": 17.272,
      "step": 500
    },
    {
      "epoch": 0.08488681757656458,
      "grad_norm": 22.75,
      "learning_rate": 1.830226364846871e-05,
      "loss": 1.2182,
      "step": 510
    },
    {
      "epoch": 0.08655126498002663,
      "grad_norm": 19.875,
      "learning_rate": 1.826897470039947e-05,
      "loss": 1.0531,
      "step": 520
    },
    {
      "epoch": 0.08821571238348869,
      "grad_norm": 21.0,
      "learning_rate": 1.8235685752330227e-05,
      "loss": 1.0973,
      "step": 530
    },
    {
      "epoch": 0.08988015978695073,
      "grad_norm": 43.25,
      "learning_rate": 1.8202396804260988e-05,
      "loss": 1.0156,
      "step": 540
    },
    {
      "epoch": 0.09154460719041278,
      "grad_norm": 18.375,
      "learning_rate": 1.8169107856191746e-05,
      "loss": 1.0514,
      "step": 550
    },
    {
      "epoch": 0.09320905459387484,
      "grad_norm": 31.0,
      "learning_rate": 1.8135818908122504e-05,
      "loss": 1.1303,
      "step": 560
    },
    {
      "epoch": 0.09487350199733688,
      "grad_norm": 36.25,
      "learning_rate": 1.8102529960053262e-05,
      "loss": 1.1049,
      "step": 570
    },
    {
      "epoch": 0.09653794940079893,
      "grad_norm": 8.5,
      "learning_rate": 1.806924101198402e-05,
      "loss": 1.0469,
      "step": 580
    },
    {
      "epoch": 0.09820239680426099,
      "grad_norm": 12.125,
      "learning_rate": 1.8035952063914782e-05,
      "loss": 0.9684,
      "step": 590
    },
    {
      "epoch": 0.09986684420772303,
      "grad_norm": 46.75,
      "learning_rate": 1.800266311584554e-05,
      "loss": 1.166,
      "step": 600
    },
    {
      "epoch": 0.10153129161118508,
      "grad_norm": 22.125,
      "learning_rate": 1.79693741677763e-05,
      "loss": 1.1551,
      "step": 610
    },
    {
      "epoch": 0.10319573901464714,
      "grad_norm": 9.0,
      "learning_rate": 1.7936085219707056e-05,
      "loss": 1.0684,
      "step": 620
    },
    {
      "epoch": 0.1048601864181092,
      "grad_norm": 22.75,
      "learning_rate": 1.7902796271637818e-05,
      "loss": 1.0961,
      "step": 630
    },
    {
      "epoch": 0.10652463382157124,
      "grad_norm": 21.125,
      "learning_rate": 1.7869507323568576e-05,
      "loss": 1.0809,
      "step": 640
    },
    {
      "epoch": 0.10818908122503329,
      "grad_norm": 20.375,
      "learning_rate": 1.7836218375499338e-05,
      "loss": 0.9951,
      "step": 650
    },
    {
      "epoch": 0.10985352862849534,
      "grad_norm": 14.0625,
      "learning_rate": 1.7802929427430096e-05,
      "loss": 0.9477,
      "step": 660
    },
    {
      "epoch": 0.11151797603195739,
      "grad_norm": 19.25,
      "learning_rate": 1.7769640479360854e-05,
      "loss": 1.1016,
      "step": 670
    },
    {
      "epoch": 0.11318242343541944,
      "grad_norm": 20.625,
      "learning_rate": 1.7736351531291612e-05,
      "loss": 1.2195,
      "step": 680
    },
    {
      "epoch": 0.1148468708388815,
      "grad_norm": 35.5,
      "learning_rate": 1.7703062583222374e-05,
      "loss": 1.1961,
      "step": 690
    },
    {
      "epoch": 0.11651131824234354,
      "grad_norm": 42.75,
      "learning_rate": 1.766977363515313e-05,
      "loss": 1.1164,
      "step": 700
    },
    {
      "epoch": 0.11817576564580559,
      "grad_norm": 27.875,
      "learning_rate": 1.763648468708389e-05,
      "loss": 0.9984,
      "step": 710
    },
    {
      "epoch": 0.11984021304926765,
      "grad_norm": 32.0,
      "learning_rate": 1.7603195739014648e-05,
      "loss": 1.0512,
      "step": 720
    },
    {
      "epoch": 0.12150466045272969,
      "grad_norm": 45.25,
      "learning_rate": 1.756990679094541e-05,
      "loss": 1.302,
      "step": 730
    },
    {
      "epoch": 0.12316910785619174,
      "grad_norm": 10.0,
      "learning_rate": 1.7536617842876168e-05,
      "loss": 1.0992,
      "step": 740
    },
    {
      "epoch": 0.1248335552596538,
      "grad_norm": 9.625,
      "learning_rate": 1.7503328894806926e-05,
      "loss": 0.9535,
      "step": 750
    },
    {
      "epoch": 0.12649800266311584,
      "grad_norm": 23.0,
      "learning_rate": 1.7470039946737684e-05,
      "loss": 1.1754,
      "step": 760
    },
    {
      "epoch": 0.1281624500665779,
      "grad_norm": 17.25,
      "learning_rate": 1.7436750998668442e-05,
      "loss": 1.1402,
      "step": 770
    },
    {
      "epoch": 0.12982689747003995,
      "grad_norm": 39.25,
      "learning_rate": 1.7403462050599203e-05,
      "loss": 1.0141,
      "step": 780
    },
    {
      "epoch": 0.131491344873502,
      "grad_norm": 11.0625,
      "learning_rate": 1.737017310252996e-05,
      "loss": 1.2168,
      "step": 790
    },
    {
      "epoch": 0.13315579227696406,
      "grad_norm": 40.75,
      "learning_rate": 1.733688415446072e-05,
      "loss": 1.027,
      "step": 800
    },
    {
      "epoch": 0.13482023968042608,
      "grad_norm": 34.0,
      "learning_rate": 1.7303595206391478e-05,
      "loss": 1.0939,
      "step": 810
    },
    {
      "epoch": 0.13648468708388814,
      "grad_norm": 22.875,
      "learning_rate": 1.727030625832224e-05,
      "loss": 0.9584,
      "step": 820
    },
    {
      "epoch": 0.1381491344873502,
      "grad_norm": 11.0625,
      "learning_rate": 1.7237017310252998e-05,
      "loss": 1.1285,
      "step": 830
    },
    {
      "epoch": 0.13981358189081225,
      "grad_norm": 11.5,
      "learning_rate": 1.7203728362183756e-05,
      "loss": 1.0547,
      "step": 840
    },
    {
      "epoch": 0.1414780292942743,
      "grad_norm": 8.8125,
      "learning_rate": 1.7170439414114514e-05,
      "loss": 1.0344,
      "step": 850
    },
    {
      "epoch": 0.14314247669773636,
      "grad_norm": 25.875,
      "learning_rate": 1.7137150466045275e-05,
      "loss": 1.2516,
      "step": 860
    },
    {
      "epoch": 0.14480692410119841,
      "grad_norm": 9.75,
      "learning_rate": 1.7103861517976033e-05,
      "loss": 1.1129,
      "step": 870
    },
    {
      "epoch": 0.14647137150466044,
      "grad_norm": 7.75,
      "learning_rate": 1.707057256990679e-05,
      "loss": 1.0324,
      "step": 880
    },
    {
      "epoch": 0.1481358189081225,
      "grad_norm": 6.25,
      "learning_rate": 1.703728362183755e-05,
      "loss": 1.0527,
      "step": 890
    },
    {
      "epoch": 0.14980026631158455,
      "grad_norm": 9.25,
      "learning_rate": 1.7003994673768308e-05,
      "loss": 0.9162,
      "step": 900
    },
    {
      "epoch": 0.1514647137150466,
      "grad_norm": 16.625,
      "learning_rate": 1.697070572569907e-05,
      "loss": 0.8867,
      "step": 910
    },
    {
      "epoch": 0.15312916111850866,
      "grad_norm": 13.4375,
      "learning_rate": 1.693741677762983e-05,
      "loss": 0.9637,
      "step": 920
    },
    {
      "epoch": 0.15479360852197072,
      "grad_norm": 8.125,
      "learning_rate": 1.690412782956059e-05,
      "loss": 1.0559,
      "step": 930
    },
    {
      "epoch": 0.15645805592543274,
      "grad_norm": 32.75,
      "learning_rate": 1.6870838881491347e-05,
      "loss": 0.8594,
      "step": 940
    },
    {
      "epoch": 0.1581225033288948,
      "grad_norm": 20.125,
      "learning_rate": 1.6837549933422105e-05,
      "loss": 1.0273,
      "step": 950
    },
    {
      "epoch": 0.15978695073235685,
      "grad_norm": 7.4375,
      "learning_rate": 1.6804260985352863e-05,
      "loss": 0.9008,
      "step": 960
    },
    {
      "epoch": 0.1614513981358189,
      "grad_norm": 8.75,
      "learning_rate": 1.6770972037283625e-05,
      "loss": 1.1035,
      "step": 970
    },
    {
      "epoch": 0.16311584553928096,
      "grad_norm": 59.25,
      "learning_rate": 1.6737683089214383e-05,
      "loss": 1.166,
      "step": 980
    },
    {
      "epoch": 0.16478029294274302,
      "grad_norm": 23.125,
      "learning_rate": 1.670439414114514e-05,
      "loss": 1.1871,
      "step": 990
    },
    {
      "epoch": 0.16644474034620507,
      "grad_norm": 16.625,
      "learning_rate": 1.66711051930759e-05,
      "loss": 0.9184,
      "step": 1000
    },
    {
      "epoch": 0.16644474034620507,
      "eval_accuracy": 0.5005392400862784,
      "eval_loss": 1.0660072565078735,
      "eval_runtime": 698.2983,
      "eval_samples_per_second": 34.524,
      "eval_steps_per_second": 17.262,
      "step": 1000
    },
    {
      "epoch": 0.1681091877496671,
      "grad_norm": 20.875,
      "learning_rate": 1.663781624500666e-05,
      "loss": 0.9357,
      "step": 1010
    },
    {
      "epoch": 0.16977363515312915,
      "grad_norm": 18.75,
      "learning_rate": 1.660452729693742e-05,
      "loss": 1.4559,
      "step": 1020
    },
    {
      "epoch": 0.1714380825565912,
      "grad_norm": 14.9375,
      "learning_rate": 1.6571238348868177e-05,
      "loss": 1.0592,
      "step": 1030
    },
    {
      "epoch": 0.17310252996005326,
      "grad_norm": 32.5,
      "learning_rate": 1.6537949400798935e-05,
      "loss": 0.9965,
      "step": 1040
    },
    {
      "epoch": 0.17476697736351532,
      "grad_norm": 34.5,
      "learning_rate": 1.6504660452729693e-05,
      "loss": 1.0926,
      "step": 1050
    },
    {
      "epoch": 0.17643142476697737,
      "grad_norm": 15.125,
      "learning_rate": 1.6471371504660455e-05,
      "loss": 0.8855,
      "step": 1060
    },
    {
      "epoch": 0.1780958721704394,
      "grad_norm": 10.375,
      "learning_rate": 1.6438082556591213e-05,
      "loss": 1.0387,
      "step": 1070
    },
    {
      "epoch": 0.17976031957390146,
      "grad_norm": 23.125,
      "learning_rate": 1.640479360852197e-05,
      "loss": 0.8895,
      "step": 1080
    },
    {
      "epoch": 0.1814247669773635,
      "grad_norm": 8.75,
      "learning_rate": 1.637150466045273e-05,
      "loss": 0.918,
      "step": 1090
    },
    {
      "epoch": 0.18308921438082557,
      "grad_norm": 13.0625,
      "learning_rate": 1.633821571238349e-05,
      "loss": 1.3723,
      "step": 1100
    },
    {
      "epoch": 0.18475366178428762,
      "grad_norm": 21.25,
      "learning_rate": 1.630492676431425e-05,
      "loss": 1.1203,
      "step": 1110
    },
    {
      "epoch": 0.18641810918774968,
      "grad_norm": 11.25,
      "learning_rate": 1.6271637816245007e-05,
      "loss": 0.9287,
      "step": 1120
    },
    {
      "epoch": 0.18808255659121173,
      "grad_norm": 10.0,
      "learning_rate": 1.6238348868175765e-05,
      "loss": 0.9258,
      "step": 1130
    },
    {
      "epoch": 0.18974700399467376,
      "grad_norm": 15.0,
      "learning_rate": 1.6205059920106527e-05,
      "loss": 1.1258,
      "step": 1140
    },
    {
      "epoch": 0.1914114513981358,
      "grad_norm": 6.84375,
      "learning_rate": 1.6171770972037285e-05,
      "loss": 0.9473,
      "step": 1150
    },
    {
      "epoch": 0.19307589880159787,
      "grad_norm": 8.5,
      "learning_rate": 1.6138482023968043e-05,
      "loss": 0.9902,
      "step": 1160
    },
    {
      "epoch": 0.19474034620505992,
      "grad_norm": 10.625,
      "learning_rate": 1.6105193075898804e-05,
      "loss": 1.0793,
      "step": 1170
    },
    {
      "epoch": 0.19640479360852198,
      "grad_norm": 14.0625,
      "learning_rate": 1.6071904127829563e-05,
      "loss": 0.9207,
      "step": 1180
    },
    {
      "epoch": 0.19806924101198403,
      "grad_norm": 23.375,
      "learning_rate": 1.603861517976032e-05,
      "loss": 1.0547,
      "step": 1190
    },
    {
      "epoch": 0.19973368841544606,
      "grad_norm": 3.578125,
      "learning_rate": 1.6005326231691082e-05,
      "loss": 0.9613,
      "step": 1200
    },
    {
      "epoch": 0.20139813581890811,
      "grad_norm": 15.0,
      "learning_rate": 1.597203728362184e-05,
      "loss": 0.932,
      "step": 1210
    },
    {
      "epoch": 0.20306258322237017,
      "grad_norm": 8.0625,
      "learning_rate": 1.59387483355526e-05,
      "loss": 0.9164,
      "step": 1220
    },
    {
      "epoch": 0.20472703062583222,
      "grad_norm": 40.5,
      "learning_rate": 1.5905459387483357e-05,
      "loss": 1.0641,
      "step": 1230
    },
    {
      "epoch": 0.20639147802929428,
      "grad_norm": 24.0,
      "learning_rate": 1.5872170439414115e-05,
      "loss": 0.99,
      "step": 1240
    },
    {
      "epoch": 0.20805592543275633,
      "grad_norm": 7.09375,
      "learning_rate": 1.5838881491344876e-05,
      "loss": 0.8512,
      "step": 1250
    },
    {
      "epoch": 0.2097203728362184,
      "grad_norm": 8.1875,
      "learning_rate": 1.5805592543275634e-05,
      "loss": 1.0039,
      "step": 1260
    },
    {
      "epoch": 0.21138482023968042,
      "grad_norm": 22.25,
      "learning_rate": 1.5772303595206392e-05,
      "loss": 1.1766,
      "step": 1270
    },
    {
      "epoch": 0.21304926764314247,
      "grad_norm": 19.0,
      "learning_rate": 1.573901464713715e-05,
      "loss": 0.9977,
      "step": 1280
    },
    {
      "epoch": 0.21471371504660453,
      "grad_norm": 24.125,
      "learning_rate": 1.5705725699067912e-05,
      "loss": 1.0371,
      "step": 1290
    },
    {
      "epoch": 0.21637816245006658,
      "grad_norm": 14.75,
      "learning_rate": 1.567243675099867e-05,
      "loss": 1.0277,
      "step": 1300
    },
    {
      "epoch": 0.21804260985352863,
      "grad_norm": 19.625,
      "learning_rate": 1.563914780292943e-05,
      "loss": 1.0273,
      "step": 1310
    },
    {
      "epoch": 0.2197070572569907,
      "grad_norm": 11.5,
      "learning_rate": 1.5605858854860187e-05,
      "loss": 0.9012,
      "step": 1320
    },
    {
      "epoch": 0.22137150466045272,
      "grad_norm": 59.0,
      "learning_rate": 1.5572569906790948e-05,
      "loss": 0.9426,
      "step": 1330
    },
    {
      "epoch": 0.22303595206391477,
      "grad_norm": 22.5,
      "learning_rate": 1.5539280958721706e-05,
      "loss": 1.1695,
      "step": 1340
    },
    {
      "epoch": 0.22470039946737683,
      "grad_norm": 11.5,
      "learning_rate": 1.5505992010652464e-05,
      "loss": 0.9965,
      "step": 1350
    },
    {
      "epoch": 0.22636484687083888,
      "grad_norm": 15.0625,
      "learning_rate": 1.5472703062583222e-05,
      "loss": 1.1371,
      "step": 1360
    },
    {
      "epoch": 0.22802929427430094,
      "grad_norm": 40.0,
      "learning_rate": 1.543941411451398e-05,
      "loss": 1.0285,
      "step": 1370
    },
    {
      "epoch": 0.229693741677763,
      "grad_norm": 7.5625,
      "learning_rate": 1.5406125166444742e-05,
      "loss": 1.2141,
      "step": 1380
    },
    {
      "epoch": 0.23135818908122505,
      "grad_norm": 40.25,
      "learning_rate": 1.53728362183755e-05,
      "loss": 1.1344,
      "step": 1390
    },
    {
      "epoch": 0.23302263648468707,
      "grad_norm": 14.25,
      "learning_rate": 1.533954727030626e-05,
      "loss": 1.0766,
      "step": 1400
    },
    {
      "epoch": 0.23468708388814913,
      "grad_norm": 34.25,
      "learning_rate": 1.5306258322237016e-05,
      "loss": 1.2734,
      "step": 1410
    },
    {
      "epoch": 0.23635153129161118,
      "grad_norm": 14.375,
      "learning_rate": 1.5272969374167778e-05,
      "loss": 1.0312,
      "step": 1420
    },
    {
      "epoch": 0.23801597869507324,
      "grad_norm": 29.75,
      "learning_rate": 1.5239680426098538e-05,
      "loss": 1.143,
      "step": 1430
    },
    {
      "epoch": 0.2396804260985353,
      "grad_norm": 16.125,
      "learning_rate": 1.5206391478029296e-05,
      "loss": 0.9922,
      "step": 1440
    },
    {
      "epoch": 0.24134487350199735,
      "grad_norm": 24.0,
      "learning_rate": 1.5173102529960056e-05,
      "loss": 1.0809,
      "step": 1450
    },
    {
      "epoch": 0.24300932090545938,
      "grad_norm": 29.875,
      "learning_rate": 1.5139813581890814e-05,
      "loss": 1.0395,
      "step": 1460
    },
    {
      "epoch": 0.24467376830892143,
      "grad_norm": 7.65625,
      "learning_rate": 1.5106524633821574e-05,
      "loss": 0.8957,
      "step": 1470
    },
    {
      "epoch": 0.24633821571238348,
      "grad_norm": 25.5,
      "learning_rate": 1.5073235685752332e-05,
      "loss": 0.891,
      "step": 1480
    },
    {
      "epoch": 0.24800266311584554,
      "grad_norm": 20.5,
      "learning_rate": 1.5039946737683092e-05,
      "loss": 0.8908,
      "step": 1490
    },
    {
      "epoch": 0.2496671105193076,
      "grad_norm": 21.375,
      "learning_rate": 1.500665778961385e-05,
      "loss": 0.9566,
      "step": 1500
    },
    {
      "epoch": 0.2496671105193076,
      "eval_accuracy": 0.5007881201260992,
      "eval_loss": 1.013507604598999,
      "eval_runtime": 697.1064,
      "eval_samples_per_second": 34.583,
      "eval_steps_per_second": 17.291,
      "step": 1500
    }
  ],
  "logging_steps": 10,
  "max_steps": 6008,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "total_flos": 0.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
