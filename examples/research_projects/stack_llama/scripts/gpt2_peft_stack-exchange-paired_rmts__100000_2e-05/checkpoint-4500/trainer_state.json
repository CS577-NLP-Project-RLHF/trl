{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.22626709573612228,
  "eval_steps": 500,
  "global_step": 4500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.000502815768302494,
      "grad_norm": 17.25,
      "learning_rate": 1.9998994368463394e-05,
      "loss": 1.755,
      "step": 10
    },
    {
      "epoch": 0.001005631536604988,
      "grad_norm": 70.0,
      "learning_rate": 1.9997988736926793e-05,
      "loss": 2.3226,
      "step": 20
    },
    {
      "epoch": 0.0015084473049074819,
      "grad_norm": 196.0,
      "learning_rate": 1.9996983105390186e-05,
      "loss": 3.7719,
      "step": 30
    },
    {
      "epoch": 0.002011263073209976,
      "grad_norm": 40.0,
      "learning_rate": 1.9995977473853582e-05,
      "loss": 2.4239,
      "step": 40
    },
    {
      "epoch": 0.00251407884151247,
      "grad_norm": 31.125,
      "learning_rate": 1.9994971842316978e-05,
      "loss": 2.9258,
      "step": 50
    },
    {
      "epoch": 0.0030168946098149637,
      "grad_norm": 23.25,
      "learning_rate": 1.999396621078037e-05,
      "loss": 1.6977,
      "step": 60
    },
    {
      "epoch": 0.0035197103781174576,
      "grad_norm": 121.5,
      "learning_rate": 1.9992960579243766e-05,
      "loss": 1.8602,
      "step": 70
    },
    {
      "epoch": 0.004022526146419952,
      "grad_norm": 62.25,
      "learning_rate": 1.9991954947707162e-05,
      "loss": 1.9538,
      "step": 80
    },
    {
      "epoch": 0.004525341914722446,
      "grad_norm": 86.0,
      "learning_rate": 1.9990949316170554e-05,
      "loss": 1.708,
      "step": 90
    },
    {
      "epoch": 0.00502815768302494,
      "grad_norm": 20.5,
      "learning_rate": 1.9989943684633954e-05,
      "loss": 2.9422,
      "step": 100
    },
    {
      "epoch": 0.0055309734513274336,
      "grad_norm": 28.0,
      "learning_rate": 1.9988938053097346e-05,
      "loss": 2.1455,
      "step": 110
    },
    {
      "epoch": 0.006033789219629927,
      "grad_norm": 31.125,
      "learning_rate": 1.9987932421560742e-05,
      "loss": 2.0912,
      "step": 120
    },
    {
      "epoch": 0.006536604987932421,
      "grad_norm": 129.0,
      "learning_rate": 1.9986926790024138e-05,
      "loss": 2.2301,
      "step": 130
    },
    {
      "epoch": 0.007039420756234915,
      "grad_norm": 30.0,
      "learning_rate": 1.998592115848753e-05,
      "loss": 3.5905,
      "step": 140
    },
    {
      "epoch": 0.007542236524537409,
      "grad_norm": 48.5,
      "learning_rate": 1.9984915526950926e-05,
      "loss": 2.2544,
      "step": 150
    },
    {
      "epoch": 0.008045052292839904,
      "grad_norm": 26.375,
      "learning_rate": 1.9983909895414322e-05,
      "loss": 2.4787,
      "step": 160
    },
    {
      "epoch": 0.008547868061142397,
      "grad_norm": 44.5,
      "learning_rate": 1.9982904263877715e-05,
      "loss": 1.9704,
      "step": 170
    },
    {
      "epoch": 0.009050683829444892,
      "grad_norm": 92.5,
      "learning_rate": 1.9981898632341114e-05,
      "loss": 1.738,
      "step": 180
    },
    {
      "epoch": 0.009553499597747385,
      "grad_norm": 63.0,
      "learning_rate": 1.9980893000804506e-05,
      "loss": 2.3344,
      "step": 190
    },
    {
      "epoch": 0.01005631536604988,
      "grad_norm": 99.5,
      "learning_rate": 1.9979887369267902e-05,
      "loss": 1.3479,
      "step": 200
    },
    {
      "epoch": 0.010559131134352374,
      "grad_norm": 24.375,
      "learning_rate": 1.9978881737731298e-05,
      "loss": 1.9866,
      "step": 210
    },
    {
      "epoch": 0.011061946902654867,
      "grad_norm": 36.5,
      "learning_rate": 1.997787610619469e-05,
      "loss": 1.9526,
      "step": 220
    },
    {
      "epoch": 0.011564762670957362,
      "grad_norm": 68.0,
      "learning_rate": 1.9976870474658087e-05,
      "loss": 2.4033,
      "step": 230
    },
    {
      "epoch": 0.012067578439259855,
      "grad_norm": 96.0,
      "learning_rate": 1.9975864843121482e-05,
      "loss": 2.0509,
      "step": 240
    },
    {
      "epoch": 0.01257039420756235,
      "grad_norm": 1.796875,
      "learning_rate": 1.9974859211584875e-05,
      "loss": 2.1263,
      "step": 250
    },
    {
      "epoch": 0.013073209975864843,
      "grad_norm": 41.25,
      "learning_rate": 1.997385358004827e-05,
      "loss": 1.4645,
      "step": 260
    },
    {
      "epoch": 0.013576025744167337,
      "grad_norm": 4.25,
      "learning_rate": 1.9972847948511667e-05,
      "loss": 1.9332,
      "step": 270
    },
    {
      "epoch": 0.01407884151246983,
      "grad_norm": 53.0,
      "learning_rate": 1.9971842316975063e-05,
      "loss": 1.3064,
      "step": 280
    },
    {
      "epoch": 0.014581657280772325,
      "grad_norm": 25.0,
      "learning_rate": 1.997083668543846e-05,
      "loss": 1.4321,
      "step": 290
    },
    {
      "epoch": 0.015084473049074818,
      "grad_norm": 127.5,
      "learning_rate": 1.996983105390185e-05,
      "loss": 1.9563,
      "step": 300
    },
    {
      "epoch": 0.015587288817377313,
      "grad_norm": 12.625,
      "learning_rate": 1.9968825422365247e-05,
      "loss": 1.7906,
      "step": 310
    },
    {
      "epoch": 0.016090104585679808,
      "grad_norm": 150.0,
      "learning_rate": 1.9967819790828643e-05,
      "loss": 1.7745,
      "step": 320
    },
    {
      "epoch": 0.016592920353982302,
      "grad_norm": 86.5,
      "learning_rate": 1.9966814159292035e-05,
      "loss": 1.9699,
      "step": 330
    },
    {
      "epoch": 0.017095736122284794,
      "grad_norm": 17.5,
      "learning_rate": 1.996580852775543e-05,
      "loss": 1.6041,
      "step": 340
    },
    {
      "epoch": 0.01759855189058729,
      "grad_norm": 126.0,
      "learning_rate": 1.9964802896218827e-05,
      "loss": 1.3953,
      "step": 350
    },
    {
      "epoch": 0.018101367658889783,
      "grad_norm": 94.5,
      "learning_rate": 1.9963797264682223e-05,
      "loss": 1.5418,
      "step": 360
    },
    {
      "epoch": 0.018604183427192278,
      "grad_norm": 162.0,
      "learning_rate": 1.996279163314562e-05,
      "loss": 1.7346,
      "step": 370
    },
    {
      "epoch": 0.01910699919549477,
      "grad_norm": 11.625,
      "learning_rate": 1.996178600160901e-05,
      "loss": 1.8128,
      "step": 380
    },
    {
      "epoch": 0.019609814963797264,
      "grad_norm": 17.0,
      "learning_rate": 1.9960780370072407e-05,
      "loss": 1.4312,
      "step": 390
    },
    {
      "epoch": 0.02011263073209976,
      "grad_norm": 12.375,
      "learning_rate": 1.9959774738535803e-05,
      "loss": 1.3423,
      "step": 400
    },
    {
      "epoch": 0.020615446500402253,
      "grad_norm": 16.875,
      "learning_rate": 1.9958769106999195e-05,
      "loss": 1.0962,
      "step": 410
    },
    {
      "epoch": 0.021118262268704748,
      "grad_norm": 78.5,
      "learning_rate": 1.995776347546259e-05,
      "loss": 1.5727,
      "step": 420
    },
    {
      "epoch": 0.02162107803700724,
      "grad_norm": 21.375,
      "learning_rate": 1.9956757843925987e-05,
      "loss": 1.3668,
      "step": 430
    },
    {
      "epoch": 0.022123893805309734,
      "grad_norm": 25.875,
      "learning_rate": 1.9955752212389383e-05,
      "loss": 1.4074,
      "step": 440
    },
    {
      "epoch": 0.02262670957361223,
      "grad_norm": 16.875,
      "learning_rate": 1.995474658085278e-05,
      "loss": 1.1227,
      "step": 450
    },
    {
      "epoch": 0.023129525341914724,
      "grad_norm": 71.0,
      "learning_rate": 1.995374094931617e-05,
      "loss": 1.2776,
      "step": 460
    },
    {
      "epoch": 0.023632341110217215,
      "grad_norm": 24.875,
      "learning_rate": 1.9952735317779567e-05,
      "loss": 1.55,
      "step": 470
    },
    {
      "epoch": 0.02413515687851971,
      "grad_norm": 89.0,
      "learning_rate": 1.9951729686242963e-05,
      "loss": 1.364,
      "step": 480
    },
    {
      "epoch": 0.024637972646822204,
      "grad_norm": 17.625,
      "learning_rate": 1.9950724054706356e-05,
      "loss": 1.0853,
      "step": 490
    },
    {
      "epoch": 0.0251407884151247,
      "grad_norm": 39.25,
      "learning_rate": 1.994971842316975e-05,
      "loss": 1.1744,
      "step": 500
    },
    {
      "epoch": 0.0251407884151247,
      "eval_accuracy": 0.49266236985622214,
      "eval_loss": 2.2441346645355225,
      "eval_runtime": 463.561,
      "eval_samples_per_second": 87.022,
      "eval_steps_per_second": 87.022,
      "step": 500
    },
    {
      "epoch": 0.025643604183427194,
      "grad_norm": 32.75,
      "learning_rate": 1.9948712791633147e-05,
      "loss": 1.1669,
      "step": 510
    },
    {
      "epoch": 0.026146419951729685,
      "grad_norm": 27.375,
      "learning_rate": 1.9947707160096543e-05,
      "loss": 1.0588,
      "step": 520
    },
    {
      "epoch": 0.02664923572003218,
      "grad_norm": 6.875,
      "learning_rate": 1.9946701528559936e-05,
      "loss": 1.3489,
      "step": 530
    },
    {
      "epoch": 0.027152051488334675,
      "grad_norm": 18.5,
      "learning_rate": 1.994569589702333e-05,
      "loss": 1.0483,
      "step": 540
    },
    {
      "epoch": 0.02765486725663717,
      "grad_norm": 16.625,
      "learning_rate": 1.9944690265486728e-05,
      "loss": 1.063,
      "step": 550
    },
    {
      "epoch": 0.02815768302493966,
      "grad_norm": 138.0,
      "learning_rate": 1.9943684633950123e-05,
      "loss": 1.7311,
      "step": 560
    },
    {
      "epoch": 0.028660498793242156,
      "grad_norm": 26.5,
      "learning_rate": 1.9942679002413516e-05,
      "loss": 1.0805,
      "step": 570
    },
    {
      "epoch": 0.02916331456154465,
      "grad_norm": 50.0,
      "learning_rate": 1.9941673370876912e-05,
      "loss": 0.9571,
      "step": 580
    },
    {
      "epoch": 0.029666130329847145,
      "grad_norm": 41.25,
      "learning_rate": 1.9940667739340308e-05,
      "loss": 1.4236,
      "step": 590
    },
    {
      "epoch": 0.030168946098149636,
      "grad_norm": 65.0,
      "learning_rate": 1.9939662107803704e-05,
      "loss": 0.8414,
      "step": 600
    },
    {
      "epoch": 0.03067176186645213,
      "grad_norm": 7.1875,
      "learning_rate": 1.9938656476267096e-05,
      "loss": 0.7962,
      "step": 610
    },
    {
      "epoch": 0.031174577634754626,
      "grad_norm": 30.25,
      "learning_rate": 1.9937650844730492e-05,
      "loss": 1.4491,
      "step": 620
    },
    {
      "epoch": 0.03167739340305712,
      "grad_norm": 7.84375,
      "learning_rate": 1.9936645213193888e-05,
      "loss": 1.1464,
      "step": 630
    },
    {
      "epoch": 0.032180209171359615,
      "grad_norm": 9.875,
      "learning_rate": 1.9935639581657284e-05,
      "loss": 1.0437,
      "step": 640
    },
    {
      "epoch": 0.03268302493966211,
      "grad_norm": 21.0,
      "learning_rate": 1.9934633950120676e-05,
      "loss": 1.3236,
      "step": 650
    },
    {
      "epoch": 0.033185840707964605,
      "grad_norm": 15.8125,
      "learning_rate": 1.9933628318584072e-05,
      "loss": 1.1448,
      "step": 660
    },
    {
      "epoch": 0.03368865647626709,
      "grad_norm": 63.75,
      "learning_rate": 1.9932622687047468e-05,
      "loss": 1.1797,
      "step": 670
    },
    {
      "epoch": 0.03419147224456959,
      "grad_norm": 34.5,
      "learning_rate": 1.9931617055510864e-05,
      "loss": 1.8753,
      "step": 680
    },
    {
      "epoch": 0.03469428801287208,
      "grad_norm": 30.25,
      "learning_rate": 1.9930611423974256e-05,
      "loss": 1.5983,
      "step": 690
    },
    {
      "epoch": 0.03519710378117458,
      "grad_norm": 24.25,
      "learning_rate": 1.9929605792437652e-05,
      "loss": 1.2898,
      "step": 700
    },
    {
      "epoch": 0.03569991954947707,
      "grad_norm": 72.0,
      "learning_rate": 1.9928600160901048e-05,
      "loss": 1.5699,
      "step": 710
    },
    {
      "epoch": 0.036202735317779566,
      "grad_norm": 63.5,
      "learning_rate": 1.9927594529364444e-05,
      "loss": 1.2395,
      "step": 720
    },
    {
      "epoch": 0.03670555108608206,
      "grad_norm": 4.3125,
      "learning_rate": 1.9926588897827836e-05,
      "loss": 1.0974,
      "step": 730
    },
    {
      "epoch": 0.037208366854384556,
      "grad_norm": 6.46875,
      "learning_rate": 1.9925583266291232e-05,
      "loss": 1.0399,
      "step": 740
    },
    {
      "epoch": 0.03771118262268705,
      "grad_norm": 10.125,
      "learning_rate": 1.9924577634754628e-05,
      "loss": 1.2209,
      "step": 750
    },
    {
      "epoch": 0.03821399839098954,
      "grad_norm": 30.25,
      "learning_rate": 1.9923572003218024e-05,
      "loss": 1.2585,
      "step": 760
    },
    {
      "epoch": 0.03871681415929203,
      "grad_norm": 9.3125,
      "learning_rate": 1.9922566371681417e-05,
      "loss": 1.0356,
      "step": 770
    },
    {
      "epoch": 0.03921962992759453,
      "grad_norm": 87.0,
      "learning_rate": 1.9921560740144812e-05,
      "loss": 1.3323,
      "step": 780
    },
    {
      "epoch": 0.03972244569589702,
      "grad_norm": 5.21875,
      "learning_rate": 1.992055510860821e-05,
      "loss": 0.837,
      "step": 790
    },
    {
      "epoch": 0.04022526146419952,
      "grad_norm": 46.75,
      "learning_rate": 1.99195494770716e-05,
      "loss": 1.1189,
      "step": 800
    },
    {
      "epoch": 0.04072807723250201,
      "grad_norm": 19.625,
      "learning_rate": 1.9918543845534997e-05,
      "loss": 0.8339,
      "step": 810
    },
    {
      "epoch": 0.04123089300080451,
      "grad_norm": 22.875,
      "learning_rate": 1.9917538213998393e-05,
      "loss": 1.0547,
      "step": 820
    },
    {
      "epoch": 0.041733708769107,
      "grad_norm": 70.5,
      "learning_rate": 1.991653258246179e-05,
      "loss": 1.4902,
      "step": 830
    },
    {
      "epoch": 0.042236524537409496,
      "grad_norm": 27.375,
      "learning_rate": 1.9915526950925184e-05,
      "loss": 1.0908,
      "step": 840
    },
    {
      "epoch": 0.042739340305711984,
      "grad_norm": 41.75,
      "learning_rate": 1.9914521319388577e-05,
      "loss": 1.2615,
      "step": 850
    },
    {
      "epoch": 0.04324215607401448,
      "grad_norm": 10.0,
      "learning_rate": 1.9913515687851973e-05,
      "loss": 1.4291,
      "step": 860
    },
    {
      "epoch": 0.043744971842316974,
      "grad_norm": 33.5,
      "learning_rate": 1.991251005631537e-05,
      "loss": 1.3932,
      "step": 870
    },
    {
      "epoch": 0.04424778761061947,
      "grad_norm": 30.875,
      "learning_rate": 1.991150442477876e-05,
      "loss": 1.3297,
      "step": 880
    },
    {
      "epoch": 0.04475060337892196,
      "grad_norm": 27.75,
      "learning_rate": 1.9910498793242157e-05,
      "loss": 1.0875,
      "step": 890
    },
    {
      "epoch": 0.04525341914722446,
      "grad_norm": 43.75,
      "learning_rate": 1.9909493161705553e-05,
      "loss": 1.151,
      "step": 900
    },
    {
      "epoch": 0.04575623491552695,
      "grad_norm": 14.5,
      "learning_rate": 1.990848753016895e-05,
      "loss": 0.8733,
      "step": 910
    },
    {
      "epoch": 0.04625905068382945,
      "grad_norm": 43.5,
      "learning_rate": 1.9907481898632345e-05,
      "loss": 1.2638,
      "step": 920
    },
    {
      "epoch": 0.04676186645213194,
      "grad_norm": 52.75,
      "learning_rate": 1.9906476267095737e-05,
      "loss": 1.1483,
      "step": 930
    },
    {
      "epoch": 0.04726468222043443,
      "grad_norm": 52.75,
      "learning_rate": 1.9905470635559133e-05,
      "loss": 1.3098,
      "step": 940
    },
    {
      "epoch": 0.047767497988736925,
      "grad_norm": 40.5,
      "learning_rate": 1.990446500402253e-05,
      "loss": 1.3221,
      "step": 950
    },
    {
      "epoch": 0.04827031375703942,
      "grad_norm": 13.0,
      "learning_rate": 1.990345937248592e-05,
      "loss": 1.1198,
      "step": 960
    },
    {
      "epoch": 0.048773129525341914,
      "grad_norm": 58.0,
      "learning_rate": 1.9902453740949317e-05,
      "loss": 1.2282,
      "step": 970
    },
    {
      "epoch": 0.04927594529364441,
      "grad_norm": 61.5,
      "learning_rate": 1.9901448109412713e-05,
      "loss": 1.322,
      "step": 980
    },
    {
      "epoch": 0.049778761061946904,
      "grad_norm": 11.75,
      "learning_rate": 1.990044247787611e-05,
      "loss": 0.9185,
      "step": 990
    },
    {
      "epoch": 0.0502815768302494,
      "grad_norm": 13.25,
      "learning_rate": 1.9899436846339505e-05,
      "loss": 1.1724,
      "step": 1000
    },
    {
      "epoch": 0.0502815768302494,
      "eval_accuracy": 0.49848785324739714,
      "eval_loss": 1.5374782085418701,
      "eval_runtime": 463.8368,
      "eval_samples_per_second": 86.97,
      "eval_steps_per_second": 86.97,
      "step": 1000
    },
    {
      "epoch": 0.05078439259855189,
      "grad_norm": 40.0,
      "learning_rate": 1.9898431214802897e-05,
      "loss": 1.4855,
      "step": 1010
    },
    {
      "epoch": 0.05128720836685439,
      "grad_norm": 40.5,
      "learning_rate": 1.9897425583266293e-05,
      "loss": 1.0843,
      "step": 1020
    },
    {
      "epoch": 0.051790024135156876,
      "grad_norm": 8.0,
      "learning_rate": 1.989641995172969e-05,
      "loss": 1.3188,
      "step": 1030
    },
    {
      "epoch": 0.05229283990345937,
      "grad_norm": 64.5,
      "learning_rate": 1.989541432019308e-05,
      "loss": 1.2116,
      "step": 1040
    },
    {
      "epoch": 0.052795655671761865,
      "grad_norm": 8.125,
      "learning_rate": 1.9894408688656477e-05,
      "loss": 0.8206,
      "step": 1050
    },
    {
      "epoch": 0.05329847144006436,
      "grad_norm": 23.125,
      "learning_rate": 1.9893403057119873e-05,
      "loss": 0.896,
      "step": 1060
    },
    {
      "epoch": 0.053801287208366855,
      "grad_norm": 11.0625,
      "learning_rate": 1.9892397425583266e-05,
      "loss": 1.1027,
      "step": 1070
    },
    {
      "epoch": 0.05430410297666935,
      "grad_norm": 57.25,
      "learning_rate": 1.9891391794046665e-05,
      "loss": 1.4035,
      "step": 1080
    },
    {
      "epoch": 0.054806918744971844,
      "grad_norm": 10.3125,
      "learning_rate": 1.9890386162510058e-05,
      "loss": 1.3311,
      "step": 1090
    },
    {
      "epoch": 0.05530973451327434,
      "grad_norm": 34.25,
      "learning_rate": 1.9889380530973453e-05,
      "loss": 1.6882,
      "step": 1100
    },
    {
      "epoch": 0.05581255028157683,
      "grad_norm": 36.0,
      "learning_rate": 1.988837489943685e-05,
      "loss": 0.9455,
      "step": 1110
    },
    {
      "epoch": 0.05631536604987932,
      "grad_norm": 56.5,
      "learning_rate": 1.9887369267900242e-05,
      "loss": 1.5086,
      "step": 1120
    },
    {
      "epoch": 0.056818181818181816,
      "grad_norm": 9.6875,
      "learning_rate": 1.9886363636363638e-05,
      "loss": 1.2461,
      "step": 1130
    },
    {
      "epoch": 0.05732099758648431,
      "grad_norm": 61.5,
      "learning_rate": 1.9885358004827034e-05,
      "loss": 1.1075,
      "step": 1140
    },
    {
      "epoch": 0.057823813354786806,
      "grad_norm": 35.25,
      "learning_rate": 1.9884352373290426e-05,
      "loss": 1.0538,
      "step": 1150
    },
    {
      "epoch": 0.0583266291230893,
      "grad_norm": 7.8125,
      "learning_rate": 1.9883346741753825e-05,
      "loss": 1.0417,
      "step": 1160
    },
    {
      "epoch": 0.058829444891391795,
      "grad_norm": 10.5,
      "learning_rate": 1.9882341110217218e-05,
      "loss": 1.1981,
      "step": 1170
    },
    {
      "epoch": 0.05933226065969429,
      "grad_norm": 35.75,
      "learning_rate": 1.9881335478680614e-05,
      "loss": 1.2672,
      "step": 1180
    },
    {
      "epoch": 0.059835076427996785,
      "grad_norm": 39.5,
      "learning_rate": 1.988032984714401e-05,
      "loss": 1.1306,
      "step": 1190
    },
    {
      "epoch": 0.06033789219629927,
      "grad_norm": 65.5,
      "learning_rate": 1.9879324215607402e-05,
      "loss": 1.3169,
      "step": 1200
    },
    {
      "epoch": 0.06084070796460177,
      "grad_norm": 29.625,
      "learning_rate": 1.9878318584070798e-05,
      "loss": 0.8346,
      "step": 1210
    },
    {
      "epoch": 0.06134352373290426,
      "grad_norm": 14.625,
      "learning_rate": 1.9877312952534194e-05,
      "loss": 0.8522,
      "step": 1220
    },
    {
      "epoch": 0.06184633950120676,
      "grad_norm": 18.5,
      "learning_rate": 1.9876307320997586e-05,
      "loss": 1.443,
      "step": 1230
    },
    {
      "epoch": 0.06234915526950925,
      "grad_norm": 67.0,
      "learning_rate": 1.9875301689460986e-05,
      "loss": 1.1026,
      "step": 1240
    },
    {
      "epoch": 0.06285197103781175,
      "grad_norm": 18.75,
      "learning_rate": 1.9874296057924378e-05,
      "loss": 0.8279,
      "step": 1250
    },
    {
      "epoch": 0.06335478680611424,
      "grad_norm": 22.625,
      "learning_rate": 1.9873290426387774e-05,
      "loss": 1.4913,
      "step": 1260
    },
    {
      "epoch": 0.06385760257441674,
      "grad_norm": 12.4375,
      "learning_rate": 1.987228479485117e-05,
      "loss": 0.9585,
      "step": 1270
    },
    {
      "epoch": 0.06436041834271923,
      "grad_norm": 27.25,
      "learning_rate": 1.9871279163314562e-05,
      "loss": 0.8827,
      "step": 1280
    },
    {
      "epoch": 0.06486323411102173,
      "grad_norm": 29.125,
      "learning_rate": 1.9870273531777958e-05,
      "loss": 1.0718,
      "step": 1290
    },
    {
      "epoch": 0.06536604987932422,
      "grad_norm": 11.4375,
      "learning_rate": 1.9869267900241354e-05,
      "loss": 0.8838,
      "step": 1300
    },
    {
      "epoch": 0.06586886564762671,
      "grad_norm": 26.0,
      "learning_rate": 1.9868262268704747e-05,
      "loss": 1.2334,
      "step": 1310
    },
    {
      "epoch": 0.06637168141592921,
      "grad_norm": 33.0,
      "learning_rate": 1.9867256637168142e-05,
      "loss": 1.2418,
      "step": 1320
    },
    {
      "epoch": 0.0668744971842317,
      "grad_norm": 23.125,
      "learning_rate": 1.986625100563154e-05,
      "loss": 1.353,
      "step": 1330
    },
    {
      "epoch": 0.06737731295253419,
      "grad_norm": 32.75,
      "learning_rate": 1.986524537409493e-05,
      "loss": 1.3633,
      "step": 1340
    },
    {
      "epoch": 0.06788012872083668,
      "grad_norm": 28.25,
      "learning_rate": 1.986423974255833e-05,
      "loss": 1.2437,
      "step": 1350
    },
    {
      "epoch": 0.06838294448913917,
      "grad_norm": 12.4375,
      "learning_rate": 1.9863234111021723e-05,
      "loss": 0.8242,
      "step": 1360
    },
    {
      "epoch": 0.06888576025744167,
      "grad_norm": 29.625,
      "learning_rate": 1.986222847948512e-05,
      "loss": 1.03,
      "step": 1370
    },
    {
      "epoch": 0.06938857602574416,
      "grad_norm": 20.75,
      "learning_rate": 1.9861222847948514e-05,
      "loss": 1.0067,
      "step": 1380
    },
    {
      "epoch": 0.06989139179404666,
      "grad_norm": 22.625,
      "learning_rate": 1.9860217216411907e-05,
      "loss": 1.2769,
      "step": 1390
    },
    {
      "epoch": 0.07039420756234915,
      "grad_norm": 27.875,
      "learning_rate": 1.9859211584875303e-05,
      "loss": 1.0452,
      "step": 1400
    },
    {
      "epoch": 0.07089702333065165,
      "grad_norm": 32.75,
      "learning_rate": 1.98582059533387e-05,
      "loss": 1.1272,
      "step": 1410
    },
    {
      "epoch": 0.07139983909895414,
      "grad_norm": 40.0,
      "learning_rate": 1.985720032180209e-05,
      "loss": 1.0697,
      "step": 1420
    },
    {
      "epoch": 0.07190265486725664,
      "grad_norm": 21.125,
      "learning_rate": 1.985619469026549e-05,
      "loss": 0.9728,
      "step": 1430
    },
    {
      "epoch": 0.07240547063555913,
      "grad_norm": 38.25,
      "learning_rate": 1.9855189058728883e-05,
      "loss": 1.0221,
      "step": 1440
    },
    {
      "epoch": 0.07290828640386163,
      "grad_norm": 13.5,
      "learning_rate": 1.985418342719228e-05,
      "loss": 0.9772,
      "step": 1450
    },
    {
      "epoch": 0.07341110217216412,
      "grad_norm": 66.0,
      "learning_rate": 1.9853177795655675e-05,
      "loss": 0.8205,
      "step": 1460
    },
    {
      "epoch": 0.07391391794046662,
      "grad_norm": 25.875,
      "learning_rate": 1.9852172164119067e-05,
      "loss": 0.9795,
      "step": 1470
    },
    {
      "epoch": 0.07441673370876911,
      "grad_norm": 15.4375,
      "learning_rate": 1.9851166532582463e-05,
      "loss": 1.1292,
      "step": 1480
    },
    {
      "epoch": 0.0749195494770716,
      "grad_norm": 11.8125,
      "learning_rate": 1.985016090104586e-05,
      "loss": 1.1356,
      "step": 1490
    },
    {
      "epoch": 0.0754223652453741,
      "grad_norm": 23.5,
      "learning_rate": 1.984915526950925e-05,
      "loss": 1.1094,
      "step": 1500
    },
    {
      "epoch": 0.0754223652453741,
      "eval_accuracy": 0.5020575111551809,
      "eval_loss": 1.2778980731964111,
      "eval_runtime": 464.4728,
      "eval_samples_per_second": 86.851,
      "eval_steps_per_second": 86.851,
      "step": 1500
    },
    {
      "epoch": 0.07592518101367658,
      "grad_norm": 20.625,
      "learning_rate": 1.984814963797265e-05,
      "loss": 1.2984,
      "step": 1510
    },
    {
      "epoch": 0.07642799678197908,
      "grad_norm": 16.5,
      "learning_rate": 1.9847144006436043e-05,
      "loss": 0.9923,
      "step": 1520
    },
    {
      "epoch": 0.07693081255028157,
      "grad_norm": 54.25,
      "learning_rate": 1.984613837489944e-05,
      "loss": 1.1829,
      "step": 1530
    },
    {
      "epoch": 0.07743362831858407,
      "grad_norm": 12.5625,
      "learning_rate": 1.9845132743362835e-05,
      "loss": 0.9829,
      "step": 1540
    },
    {
      "epoch": 0.07793644408688656,
      "grad_norm": 15.125,
      "learning_rate": 1.9844127111826227e-05,
      "loss": 0.9298,
      "step": 1550
    },
    {
      "epoch": 0.07843925985518906,
      "grad_norm": 14.3125,
      "learning_rate": 1.9843121480289623e-05,
      "loss": 0.948,
      "step": 1560
    },
    {
      "epoch": 0.07894207562349155,
      "grad_norm": 23.5,
      "learning_rate": 1.984211584875302e-05,
      "loss": 1.2381,
      "step": 1570
    },
    {
      "epoch": 0.07944489139179405,
      "grad_norm": 21.25,
      "learning_rate": 1.984111021721641e-05,
      "loss": 1.0238,
      "step": 1580
    },
    {
      "epoch": 0.07994770716009654,
      "grad_norm": 18.875,
      "learning_rate": 1.9840104585679807e-05,
      "loss": 0.7515,
      "step": 1590
    },
    {
      "epoch": 0.08045052292839903,
      "grad_norm": 45.5,
      "learning_rate": 1.9839098954143203e-05,
      "loss": 0.9784,
      "step": 1600
    },
    {
      "epoch": 0.08095333869670153,
      "grad_norm": 15.6875,
      "learning_rate": 1.9838093322606596e-05,
      "loss": 0.9643,
      "step": 1610
    },
    {
      "epoch": 0.08145615446500402,
      "grad_norm": 14.375,
      "learning_rate": 1.9837087691069995e-05,
      "loss": 0.6581,
      "step": 1620
    },
    {
      "epoch": 0.08195897023330652,
      "grad_norm": 8.6875,
      "learning_rate": 1.9836082059533388e-05,
      "loss": 1.0244,
      "step": 1630
    },
    {
      "epoch": 0.08246178600160901,
      "grad_norm": 20.0,
      "learning_rate": 1.9835076427996783e-05,
      "loss": 1.1502,
      "step": 1640
    },
    {
      "epoch": 0.08296460176991151,
      "grad_norm": 45.0,
      "learning_rate": 1.983407079646018e-05,
      "loss": 1.0626,
      "step": 1650
    },
    {
      "epoch": 0.083467417538214,
      "grad_norm": 45.75,
      "learning_rate": 1.9833065164923572e-05,
      "loss": 1.0124,
      "step": 1660
    },
    {
      "epoch": 0.0839702333065165,
      "grad_norm": 27.125,
      "learning_rate": 1.9832059533386968e-05,
      "loss": 1.2806,
      "step": 1670
    },
    {
      "epoch": 0.08447304907481899,
      "grad_norm": 58.5,
      "learning_rate": 1.9831053901850364e-05,
      "loss": 1.5004,
      "step": 1680
    },
    {
      "epoch": 0.08497586484312147,
      "grad_norm": 33.75,
      "learning_rate": 1.9830048270313756e-05,
      "loss": 1.586,
      "step": 1690
    },
    {
      "epoch": 0.08547868061142397,
      "grad_norm": 14.375,
      "learning_rate": 1.9829042638777155e-05,
      "loss": 0.9594,
      "step": 1700
    },
    {
      "epoch": 0.08598149637972646,
      "grad_norm": 28.875,
      "learning_rate": 1.9828037007240548e-05,
      "loss": 1.0504,
      "step": 1710
    },
    {
      "epoch": 0.08648431214802896,
      "grad_norm": 32.5,
      "learning_rate": 1.9827031375703944e-05,
      "loss": 0.8961,
      "step": 1720
    },
    {
      "epoch": 0.08698712791633145,
      "grad_norm": 30.75,
      "learning_rate": 1.982602574416734e-05,
      "loss": 1.0909,
      "step": 1730
    },
    {
      "epoch": 0.08748994368463395,
      "grad_norm": 18.125,
      "learning_rate": 1.9825020112630732e-05,
      "loss": 1.0049,
      "step": 1740
    },
    {
      "epoch": 0.08799275945293644,
      "grad_norm": 8.0,
      "learning_rate": 1.9824014481094128e-05,
      "loss": 0.9059,
      "step": 1750
    },
    {
      "epoch": 0.08849557522123894,
      "grad_norm": 44.5,
      "learning_rate": 1.9823008849557524e-05,
      "loss": 0.8509,
      "step": 1760
    },
    {
      "epoch": 0.08899839098954143,
      "grad_norm": 7.8125,
      "learning_rate": 1.9822003218020916e-05,
      "loss": 0.9924,
      "step": 1770
    },
    {
      "epoch": 0.08950120675784393,
      "grad_norm": 15.9375,
      "learning_rate": 1.9820997586484316e-05,
      "loss": 1.0462,
      "step": 1780
    },
    {
      "epoch": 0.09000402252614642,
      "grad_norm": 8.375,
      "learning_rate": 1.9819991954947708e-05,
      "loss": 0.863,
      "step": 1790
    },
    {
      "epoch": 0.09050683829444892,
      "grad_norm": 17.875,
      "learning_rate": 1.9818986323411104e-05,
      "loss": 1.0664,
      "step": 1800
    },
    {
      "epoch": 0.09100965406275141,
      "grad_norm": 21.625,
      "learning_rate": 1.98179806918745e-05,
      "loss": 1.023,
      "step": 1810
    },
    {
      "epoch": 0.0915124698310539,
      "grad_norm": 8.4375,
      "learning_rate": 1.9816975060337892e-05,
      "loss": 1.2834,
      "step": 1820
    },
    {
      "epoch": 0.0920152855993564,
      "grad_norm": 69.5,
      "learning_rate": 1.9815969428801288e-05,
      "loss": 1.231,
      "step": 1830
    },
    {
      "epoch": 0.0925181013676589,
      "grad_norm": 22.375,
      "learning_rate": 1.9814963797264684e-05,
      "loss": 1.0259,
      "step": 1840
    },
    {
      "epoch": 0.09302091713596139,
      "grad_norm": 7.0625,
      "learning_rate": 1.981395816572808e-05,
      "loss": 1.2927,
      "step": 1850
    },
    {
      "epoch": 0.09352373290426388,
      "grad_norm": 53.0,
      "learning_rate": 1.9812952534191472e-05,
      "loss": 0.8671,
      "step": 1860
    },
    {
      "epoch": 0.09402654867256637,
      "grad_norm": 13.8125,
      "learning_rate": 1.981194690265487e-05,
      "loss": 1.1904,
      "step": 1870
    },
    {
      "epoch": 0.09452936444086886,
      "grad_norm": 24.375,
      "learning_rate": 1.9810941271118264e-05,
      "loss": 1.4408,
      "step": 1880
    },
    {
      "epoch": 0.09503218020917135,
      "grad_norm": 9.25,
      "learning_rate": 1.980993563958166e-05,
      "loss": 1.2783,
      "step": 1890
    },
    {
      "epoch": 0.09553499597747385,
      "grad_norm": 47.5,
      "learning_rate": 1.9808930008045053e-05,
      "loss": 1.1093,
      "step": 1900
    },
    {
      "epoch": 0.09603781174577634,
      "grad_norm": 58.5,
      "learning_rate": 1.980792437650845e-05,
      "loss": 1.2751,
      "step": 1910
    },
    {
      "epoch": 0.09654062751407884,
      "grad_norm": 3.03125,
      "learning_rate": 1.9806918744971844e-05,
      "loss": 0.8366,
      "step": 1920
    },
    {
      "epoch": 0.09704344328238133,
      "grad_norm": 27.125,
      "learning_rate": 1.980591311343524e-05,
      "loss": 1.0107,
      "step": 1930
    },
    {
      "epoch": 0.09754625905068383,
      "grad_norm": 20.0,
      "learning_rate": 1.9804907481898633e-05,
      "loss": 0.9459,
      "step": 1940
    },
    {
      "epoch": 0.09804907481898632,
      "grad_norm": 13.0,
      "learning_rate": 1.980390185036203e-05,
      "loss": 0.9708,
      "step": 1950
    },
    {
      "epoch": 0.09855189058728882,
      "grad_norm": 8.5,
      "learning_rate": 1.9802896218825425e-05,
      "loss": 0.7031,
      "step": 1960
    },
    {
      "epoch": 0.09905470635559131,
      "grad_norm": 6.75,
      "learning_rate": 1.980189058728882e-05,
      "loss": 1.0424,
      "step": 1970
    },
    {
      "epoch": 0.09955752212389381,
      "grad_norm": 20.875,
      "learning_rate": 1.9800884955752213e-05,
      "loss": 1.4547,
      "step": 1980
    },
    {
      "epoch": 0.1000603378921963,
      "grad_norm": 19.125,
      "learning_rate": 1.979987932421561e-05,
      "loss": 1.0723,
      "step": 1990
    },
    {
      "epoch": 0.1005631536604988,
      "grad_norm": 25.625,
      "learning_rate": 1.9798873692679005e-05,
      "loss": 0.7404,
      "step": 2000
    },
    {
      "epoch": 0.1005631536604988,
      "eval_accuracy": 0.5057759048091225,
      "eval_loss": 1.196290373802185,
      "eval_runtime": 463.4626,
      "eval_samples_per_second": 87.04,
      "eval_steps_per_second": 87.04,
      "step": 2000
    },
    {
      "epoch": 0.10106596942880129,
      "grad_norm": 6.09375,
      "learning_rate": 1.97978680611424e-05,
      "loss": 0.7338,
      "step": 2010
    },
    {
      "epoch": 0.10156878519710379,
      "grad_norm": 11.4375,
      "learning_rate": 1.9796862429605793e-05,
      "loss": 1.273,
      "step": 2020
    },
    {
      "epoch": 0.10207160096540628,
      "grad_norm": 17.75,
      "learning_rate": 1.979585679806919e-05,
      "loss": 0.9983,
      "step": 2030
    },
    {
      "epoch": 0.10257441673370878,
      "grad_norm": 20.375,
      "learning_rate": 1.9794851166532585e-05,
      "loss": 1.306,
      "step": 2040
    },
    {
      "epoch": 0.10307723250201126,
      "grad_norm": 5.21875,
      "learning_rate": 1.979384553499598e-05,
      "loss": 0.8712,
      "step": 2050
    },
    {
      "epoch": 0.10358004827031375,
      "grad_norm": 14.125,
      "learning_rate": 1.9792839903459373e-05,
      "loss": 0.9737,
      "step": 2060
    },
    {
      "epoch": 0.10408286403861625,
      "grad_norm": 10.6875,
      "learning_rate": 1.979183427192277e-05,
      "loss": 0.835,
      "step": 2070
    },
    {
      "epoch": 0.10458567980691874,
      "grad_norm": 15.5,
      "learning_rate": 1.9790828640386165e-05,
      "loss": 1.0255,
      "step": 2080
    },
    {
      "epoch": 0.10508849557522124,
      "grad_norm": 12.125,
      "learning_rate": 1.978982300884956e-05,
      "loss": 0.9322,
      "step": 2090
    },
    {
      "epoch": 0.10559131134352373,
      "grad_norm": 66.0,
      "learning_rate": 1.9788817377312953e-05,
      "loss": 1.3371,
      "step": 2100
    },
    {
      "epoch": 0.10609412711182623,
      "grad_norm": 15.3125,
      "learning_rate": 1.978781174577635e-05,
      "loss": 1.0585,
      "step": 2110
    },
    {
      "epoch": 0.10659694288012872,
      "grad_norm": 35.0,
      "learning_rate": 1.9786806114239745e-05,
      "loss": 1.0711,
      "step": 2120
    },
    {
      "epoch": 0.10709975864843121,
      "grad_norm": 24.75,
      "learning_rate": 1.9785800482703138e-05,
      "loss": 1.3138,
      "step": 2130
    },
    {
      "epoch": 0.10760257441673371,
      "grad_norm": 41.75,
      "learning_rate": 1.9784794851166533e-05,
      "loss": 1.34,
      "step": 2140
    },
    {
      "epoch": 0.1081053901850362,
      "grad_norm": 7.34375,
      "learning_rate": 1.978378921962993e-05,
      "loss": 0.9177,
      "step": 2150
    },
    {
      "epoch": 0.1086082059533387,
      "grad_norm": 37.75,
      "learning_rate": 1.9782783588093325e-05,
      "loss": 1.1133,
      "step": 2160
    },
    {
      "epoch": 0.1091110217216412,
      "grad_norm": 63.75,
      "learning_rate": 1.978177795655672e-05,
      "loss": 1.0031,
      "step": 2170
    },
    {
      "epoch": 0.10961383748994369,
      "grad_norm": 5.875,
      "learning_rate": 1.9780772325020114e-05,
      "loss": 0.898,
      "step": 2180
    },
    {
      "epoch": 0.11011665325824618,
      "grad_norm": 12.5,
      "learning_rate": 1.977976669348351e-05,
      "loss": 1.0838,
      "step": 2190
    },
    {
      "epoch": 0.11061946902654868,
      "grad_norm": 20.25,
      "learning_rate": 1.9778761061946905e-05,
      "loss": 1.614,
      "step": 2200
    },
    {
      "epoch": 0.11112228479485117,
      "grad_norm": 29.375,
      "learning_rate": 1.9777755430410298e-05,
      "loss": 1.0045,
      "step": 2210
    },
    {
      "epoch": 0.11162510056315365,
      "grad_norm": 29.625,
      "learning_rate": 1.9776749798873694e-05,
      "loss": 1.08,
      "step": 2220
    },
    {
      "epoch": 0.11212791633145615,
      "grad_norm": 8.9375,
      "learning_rate": 1.977574416733709e-05,
      "loss": 0.9126,
      "step": 2230
    },
    {
      "epoch": 0.11263073209975864,
      "grad_norm": 20.5,
      "learning_rate": 1.9774738535800485e-05,
      "loss": 0.868,
      "step": 2240
    },
    {
      "epoch": 0.11313354786806114,
      "grad_norm": 25.375,
      "learning_rate": 1.977373290426388e-05,
      "loss": 0.7441,
      "step": 2250
    },
    {
      "epoch": 0.11363636363636363,
      "grad_norm": 30.25,
      "learning_rate": 1.9772727272727274e-05,
      "loss": 1.2848,
      "step": 2260
    },
    {
      "epoch": 0.11413917940466613,
      "grad_norm": 5.625,
      "learning_rate": 1.977172164119067e-05,
      "loss": 1.0578,
      "step": 2270
    },
    {
      "epoch": 0.11464199517296862,
      "grad_norm": 22.625,
      "learning_rate": 1.9770716009654066e-05,
      "loss": 1.399,
      "step": 2280
    },
    {
      "epoch": 0.11514481094127112,
      "grad_norm": 7.96875,
      "learning_rate": 1.9769710378117458e-05,
      "loss": 0.9063,
      "step": 2290
    },
    {
      "epoch": 0.11564762670957361,
      "grad_norm": 6.5625,
      "learning_rate": 1.9768704746580854e-05,
      "loss": 1.0792,
      "step": 2300
    },
    {
      "epoch": 0.1161504424778761,
      "grad_norm": 9.9375,
      "learning_rate": 1.976769911504425e-05,
      "loss": 0.8213,
      "step": 2310
    },
    {
      "epoch": 0.1166532582461786,
      "grad_norm": 17.0,
      "learning_rate": 1.9766693483507646e-05,
      "loss": 1.2637,
      "step": 2320
    },
    {
      "epoch": 0.1171560740144811,
      "grad_norm": 23.875,
      "learning_rate": 1.976568785197104e-05,
      "loss": 0.8917,
      "step": 2330
    },
    {
      "epoch": 0.11765888978278359,
      "grad_norm": 18.0,
      "learning_rate": 1.9764682220434434e-05,
      "loss": 0.849,
      "step": 2340
    },
    {
      "epoch": 0.11816170555108609,
      "grad_norm": 9.5625,
      "learning_rate": 1.976367658889783e-05,
      "loss": 0.9853,
      "step": 2350
    },
    {
      "epoch": 0.11866452131938858,
      "grad_norm": 12.5625,
      "learning_rate": 1.9762670957361226e-05,
      "loss": 1.1028,
      "step": 2360
    },
    {
      "epoch": 0.11916733708769107,
      "grad_norm": 7.375,
      "learning_rate": 1.9761665325824618e-05,
      "loss": 1.2908,
      "step": 2370
    },
    {
      "epoch": 0.11967015285599357,
      "grad_norm": 70.0,
      "learning_rate": 1.9760659694288014e-05,
      "loss": 1.004,
      "step": 2380
    },
    {
      "epoch": 0.12017296862429606,
      "grad_norm": 6.25,
      "learning_rate": 1.975965406275141e-05,
      "loss": 1.0106,
      "step": 2390
    },
    {
      "epoch": 0.12067578439259855,
      "grad_norm": 30.125,
      "learning_rate": 1.9758648431214803e-05,
      "loss": 1.4111,
      "step": 2400
    },
    {
      "epoch": 0.12117860016090104,
      "grad_norm": 5.625,
      "learning_rate": 1.9757642799678202e-05,
      "loss": 1.2037,
      "step": 2410
    },
    {
      "epoch": 0.12168141592920353,
      "grad_norm": 37.0,
      "learning_rate": 1.9756637168141594e-05,
      "loss": 1.2363,
      "step": 2420
    },
    {
      "epoch": 0.12218423169750603,
      "grad_norm": 11.75,
      "learning_rate": 1.975563153660499e-05,
      "loss": 1.027,
      "step": 2430
    },
    {
      "epoch": 0.12268704746580852,
      "grad_norm": 24.5,
      "learning_rate": 1.9754625905068386e-05,
      "loss": 1.0427,
      "step": 2440
    },
    {
      "epoch": 0.12318986323411102,
      "grad_norm": 21.125,
      "learning_rate": 1.975362027353178e-05,
      "loss": 0.6839,
      "step": 2450
    },
    {
      "epoch": 0.12369267900241351,
      "grad_norm": 20.75,
      "learning_rate": 1.9752614641995174e-05,
      "loss": 1.0212,
      "step": 2460
    },
    {
      "epoch": 0.12419549477071601,
      "grad_norm": 4.625,
      "learning_rate": 1.975160901045857e-05,
      "loss": 0.7714,
      "step": 2470
    },
    {
      "epoch": 0.1246983105390185,
      "grad_norm": 24.125,
      "learning_rate": 1.9750603378921963e-05,
      "loss": 1.0904,
      "step": 2480
    },
    {
      "epoch": 0.125201126307321,
      "grad_norm": 29.0,
      "learning_rate": 1.9749597747385362e-05,
      "loss": 0.9094,
      "step": 2490
    },
    {
      "epoch": 0.1257039420756235,
      "grad_norm": 10.75,
      "learning_rate": 1.9748592115848755e-05,
      "loss": 0.9452,
      "step": 2500
    },
    {
      "epoch": 0.1257039420756235,
      "eval_accuracy": 0.5054784333168071,
      "eval_loss": 1.1597926616668701,
      "eval_runtime": 462.8178,
      "eval_samples_per_second": 87.162,
      "eval_steps_per_second": 87.162,
      "step": 2500
    },
    {
      "epoch": 0.126206757843926,
      "grad_norm": 51.5,
      "learning_rate": 1.974758648431215e-05,
      "loss": 1.0503,
      "step": 2510
    },
    {
      "epoch": 0.12670957361222848,
      "grad_norm": 38.75,
      "learning_rate": 1.9746580852775546e-05,
      "loss": 1.1281,
      "step": 2520
    },
    {
      "epoch": 0.12721238938053098,
      "grad_norm": 40.5,
      "learning_rate": 1.974557522123894e-05,
      "loss": 1.3772,
      "step": 2530
    },
    {
      "epoch": 0.12771520514883347,
      "grad_norm": 28.125,
      "learning_rate": 1.9744569589702335e-05,
      "loss": 1.1235,
      "step": 2540
    },
    {
      "epoch": 0.12821802091713597,
      "grad_norm": 14.4375,
      "learning_rate": 1.974356395816573e-05,
      "loss": 1.1356,
      "step": 2550
    },
    {
      "epoch": 0.12872083668543846,
      "grad_norm": 6.875,
      "learning_rate": 1.9742558326629123e-05,
      "loss": 0.6989,
      "step": 2560
    },
    {
      "epoch": 0.12922365245374096,
      "grad_norm": 24.375,
      "learning_rate": 1.9741552695092522e-05,
      "loss": 0.9068,
      "step": 2570
    },
    {
      "epoch": 0.12972646822204345,
      "grad_norm": 33.0,
      "learning_rate": 1.9740547063555915e-05,
      "loss": 0.6883,
      "step": 2580
    },
    {
      "epoch": 0.13022928399034595,
      "grad_norm": 9.5,
      "learning_rate": 1.973954143201931e-05,
      "loss": 0.8915,
      "step": 2590
    },
    {
      "epoch": 0.13073209975864844,
      "grad_norm": 10.6875,
      "learning_rate": 1.9738535800482707e-05,
      "loss": 1.1406,
      "step": 2600
    },
    {
      "epoch": 0.13123491552695093,
      "grad_norm": 9.5625,
      "learning_rate": 1.97375301689461e-05,
      "loss": 1.1171,
      "step": 2610
    },
    {
      "epoch": 0.13173773129525343,
      "grad_norm": 8.6875,
      "learning_rate": 1.9736524537409495e-05,
      "loss": 0.8735,
      "step": 2620
    },
    {
      "epoch": 0.13224054706355592,
      "grad_norm": 20.5,
      "learning_rate": 1.973551890587289e-05,
      "loss": 1.0478,
      "step": 2630
    },
    {
      "epoch": 0.13274336283185842,
      "grad_norm": 16.625,
      "learning_rate": 1.9734513274336283e-05,
      "loss": 0.9281,
      "step": 2640
    },
    {
      "epoch": 0.1332461786001609,
      "grad_norm": 25.75,
      "learning_rate": 1.973350764279968e-05,
      "loss": 1.0036,
      "step": 2650
    },
    {
      "epoch": 0.1337489943684634,
      "grad_norm": 42.25,
      "learning_rate": 1.9732502011263075e-05,
      "loss": 1.0214,
      "step": 2660
    },
    {
      "epoch": 0.13425181013676588,
      "grad_norm": 55.75,
      "learning_rate": 1.9731496379726468e-05,
      "loss": 1.173,
      "step": 2670
    },
    {
      "epoch": 0.13475462590506837,
      "grad_norm": 36.75,
      "learning_rate": 1.9730490748189867e-05,
      "loss": 1.1137,
      "step": 2680
    },
    {
      "epoch": 0.13525744167337087,
      "grad_norm": 19.375,
      "learning_rate": 1.972948511665326e-05,
      "loss": 0.8623,
      "step": 2690
    },
    {
      "epoch": 0.13576025744167336,
      "grad_norm": 11.4375,
      "learning_rate": 1.9728479485116655e-05,
      "loss": 0.8267,
      "step": 2700
    },
    {
      "epoch": 0.13626307320997585,
      "grad_norm": 8.25,
      "learning_rate": 1.972747385358005e-05,
      "loss": 1.0373,
      "step": 2710
    },
    {
      "epoch": 0.13676588897827835,
      "grad_norm": 47.25,
      "learning_rate": 1.9726468222043444e-05,
      "loss": 1.0575,
      "step": 2720
    },
    {
      "epoch": 0.13726870474658084,
      "grad_norm": 24.75,
      "learning_rate": 1.972546259050684e-05,
      "loss": 1.1627,
      "step": 2730
    },
    {
      "epoch": 0.13777152051488334,
      "grad_norm": 18.875,
      "learning_rate": 1.9724456958970235e-05,
      "loss": 1.1038,
      "step": 2740
    },
    {
      "epoch": 0.13827433628318583,
      "grad_norm": 58.5,
      "learning_rate": 1.9723451327433628e-05,
      "loss": 1.2842,
      "step": 2750
    },
    {
      "epoch": 0.13877715205148833,
      "grad_norm": 33.0,
      "learning_rate": 1.9722445695897027e-05,
      "loss": 1.2195,
      "step": 2760
    },
    {
      "epoch": 0.13927996781979082,
      "grad_norm": 39.0,
      "learning_rate": 1.972144006436042e-05,
      "loss": 1.0509,
      "step": 2770
    },
    {
      "epoch": 0.13978278358809332,
      "grad_norm": 4.90625,
      "learning_rate": 1.9720434432823815e-05,
      "loss": 0.9176,
      "step": 2780
    },
    {
      "epoch": 0.1402855993563958,
      "grad_norm": 43.75,
      "learning_rate": 1.971942880128721e-05,
      "loss": 1.0877,
      "step": 2790
    },
    {
      "epoch": 0.1407884151246983,
      "grad_norm": 15.75,
      "learning_rate": 1.9718423169750604e-05,
      "loss": 1.0382,
      "step": 2800
    },
    {
      "epoch": 0.1412912308930008,
      "grad_norm": 29.75,
      "learning_rate": 1.9717417538214e-05,
      "loss": 0.9011,
      "step": 2810
    },
    {
      "epoch": 0.1417940466613033,
      "grad_norm": 8.5,
      "learning_rate": 1.9716411906677396e-05,
      "loss": 0.8672,
      "step": 2820
    },
    {
      "epoch": 0.1422968624296058,
      "grad_norm": 17.375,
      "learning_rate": 1.9715406275140788e-05,
      "loss": 0.9634,
      "step": 2830
    },
    {
      "epoch": 0.1427996781979083,
      "grad_norm": 43.0,
      "learning_rate": 1.9714400643604187e-05,
      "loss": 1.1591,
      "step": 2840
    },
    {
      "epoch": 0.14330249396621078,
      "grad_norm": 11.5625,
      "learning_rate": 1.971339501206758e-05,
      "loss": 0.8279,
      "step": 2850
    },
    {
      "epoch": 0.14380530973451328,
      "grad_norm": 16.75,
      "learning_rate": 1.9712389380530976e-05,
      "loss": 1.342,
      "step": 2860
    },
    {
      "epoch": 0.14430812550281577,
      "grad_norm": 43.75,
      "learning_rate": 1.971138374899437e-05,
      "loss": 0.9795,
      "step": 2870
    },
    {
      "epoch": 0.14481094127111827,
      "grad_norm": 19.875,
      "learning_rate": 1.9710378117457764e-05,
      "loss": 1.1341,
      "step": 2880
    },
    {
      "epoch": 0.14531375703942076,
      "grad_norm": 12.3125,
      "learning_rate": 1.970937248592116e-05,
      "loss": 1.4276,
      "step": 2890
    },
    {
      "epoch": 0.14581657280772325,
      "grad_norm": 14.9375,
      "learning_rate": 1.9708366854384556e-05,
      "loss": 1.3269,
      "step": 2900
    },
    {
      "epoch": 0.14631938857602575,
      "grad_norm": 42.0,
      "learning_rate": 1.9707361222847948e-05,
      "loss": 1.1609,
      "step": 2910
    },
    {
      "epoch": 0.14682220434432824,
      "grad_norm": 4.59375,
      "learning_rate": 1.9706355591311344e-05,
      "loss": 0.7524,
      "step": 2920
    },
    {
      "epoch": 0.14732502011263074,
      "grad_norm": 10.6875,
      "learning_rate": 1.970534995977474e-05,
      "loss": 0.9016,
      "step": 2930
    },
    {
      "epoch": 0.14782783588093323,
      "grad_norm": 24.0,
      "learning_rate": 1.9704344328238133e-05,
      "loss": 0.8496,
      "step": 2940
    },
    {
      "epoch": 0.14833065164923573,
      "grad_norm": 5.28125,
      "learning_rate": 1.9703338696701532e-05,
      "loss": 1.0099,
      "step": 2950
    },
    {
      "epoch": 0.14883346741753822,
      "grad_norm": 23.75,
      "learning_rate": 1.9702333065164924e-05,
      "loss": 1.2633,
      "step": 2960
    },
    {
      "epoch": 0.14933628318584072,
      "grad_norm": 6.21875,
      "learning_rate": 1.970132743362832e-05,
      "loss": 1.1463,
      "step": 2970
    },
    {
      "epoch": 0.1498390989541432,
      "grad_norm": 20.375,
      "learning_rate": 1.9700321802091716e-05,
      "loss": 1.2526,
      "step": 2980
    },
    {
      "epoch": 0.1503419147224457,
      "grad_norm": 7.40625,
      "learning_rate": 1.969931617055511e-05,
      "loss": 1.258,
      "step": 2990
    },
    {
      "epoch": 0.1508447304907482,
      "grad_norm": 65.5,
      "learning_rate": 1.9698310539018504e-05,
      "loss": 1.0141,
      "step": 3000
    },
    {
      "epoch": 0.1508447304907482,
      "eval_accuracy": 0.5075359444719881,
      "eval_loss": 1.1231328248977661,
      "eval_runtime": 463.832,
      "eval_samples_per_second": 86.971,
      "eval_steps_per_second": 86.971,
      "step": 3000
    },
    {
      "epoch": 0.1513475462590507,
      "grad_norm": 31.875,
      "learning_rate": 1.96973049074819e-05,
      "loss": 1.0824,
      "step": 3010
    },
    {
      "epoch": 0.15185036202735316,
      "grad_norm": 16.75,
      "learning_rate": 1.9696299275945293e-05,
      "loss": 1.2176,
      "step": 3020
    },
    {
      "epoch": 0.15235317779565566,
      "grad_norm": 21.875,
      "learning_rate": 1.9695293644408692e-05,
      "loss": 0.918,
      "step": 3030
    },
    {
      "epoch": 0.15285599356395815,
      "grad_norm": 18.875,
      "learning_rate": 1.9694288012872085e-05,
      "loss": 0.9132,
      "step": 3040
    },
    {
      "epoch": 0.15335880933226065,
      "grad_norm": 19.375,
      "learning_rate": 1.969328238133548e-05,
      "loss": 1.0541,
      "step": 3050
    },
    {
      "epoch": 0.15386162510056314,
      "grad_norm": 31.0,
      "learning_rate": 1.9692276749798876e-05,
      "loss": 1.023,
      "step": 3060
    },
    {
      "epoch": 0.15436444086886564,
      "grad_norm": 24.625,
      "learning_rate": 1.969127111826227e-05,
      "loss": 1.2168,
      "step": 3070
    },
    {
      "epoch": 0.15486725663716813,
      "grad_norm": 19.5,
      "learning_rate": 1.9690265486725665e-05,
      "loss": 0.968,
      "step": 3080
    },
    {
      "epoch": 0.15537007240547063,
      "grad_norm": 64.5,
      "learning_rate": 1.968925985518906e-05,
      "loss": 1.3459,
      "step": 3090
    },
    {
      "epoch": 0.15587288817377312,
      "grad_norm": 9.0,
      "learning_rate": 1.9688254223652453e-05,
      "loss": 0.8097,
      "step": 3100
    },
    {
      "epoch": 0.15637570394207562,
      "grad_norm": 16.375,
      "learning_rate": 1.9687248592115852e-05,
      "loss": 0.6782,
      "step": 3110
    },
    {
      "epoch": 0.1568785197103781,
      "grad_norm": 9.375,
      "learning_rate": 1.9686242960579245e-05,
      "loss": 1.1597,
      "step": 3120
    },
    {
      "epoch": 0.1573813354786806,
      "grad_norm": 19.875,
      "learning_rate": 1.968523732904264e-05,
      "loss": 1.2039,
      "step": 3130
    },
    {
      "epoch": 0.1578841512469831,
      "grad_norm": 13.875,
      "learning_rate": 1.9684231697506037e-05,
      "loss": 0.9437,
      "step": 3140
    },
    {
      "epoch": 0.1583869670152856,
      "grad_norm": 125.5,
      "learning_rate": 1.968322606596943e-05,
      "loss": 1.0803,
      "step": 3150
    },
    {
      "epoch": 0.1588897827835881,
      "grad_norm": 11.875,
      "learning_rate": 1.9682220434432825e-05,
      "loss": 1.1613,
      "step": 3160
    },
    {
      "epoch": 0.15939259855189059,
      "grad_norm": 17.5,
      "learning_rate": 1.968121480289622e-05,
      "loss": 1.1287,
      "step": 3170
    },
    {
      "epoch": 0.15989541432019308,
      "grad_norm": 27.125,
      "learning_rate": 1.9680209171359613e-05,
      "loss": 1.0549,
      "step": 3180
    },
    {
      "epoch": 0.16039823008849557,
      "grad_norm": 16.0,
      "learning_rate": 1.967920353982301e-05,
      "loss": 1.2829,
      "step": 3190
    },
    {
      "epoch": 0.16090104585679807,
      "grad_norm": 33.5,
      "learning_rate": 1.9678197908286405e-05,
      "loss": 0.6152,
      "step": 3200
    },
    {
      "epoch": 0.16140386162510056,
      "grad_norm": 44.5,
      "learning_rate": 1.96771922767498e-05,
      "loss": 1.0514,
      "step": 3210
    },
    {
      "epoch": 0.16190667739340306,
      "grad_norm": 80.5,
      "learning_rate": 1.9676186645213197e-05,
      "loss": 1.0487,
      "step": 3220
    },
    {
      "epoch": 0.16240949316170555,
      "grad_norm": 48.25,
      "learning_rate": 1.967518101367659e-05,
      "loss": 1.0744,
      "step": 3230
    },
    {
      "epoch": 0.16291230893000805,
      "grad_norm": 24.875,
      "learning_rate": 1.9674175382139985e-05,
      "loss": 1.1655,
      "step": 3240
    },
    {
      "epoch": 0.16341512469831054,
      "grad_norm": 37.0,
      "learning_rate": 1.967316975060338e-05,
      "loss": 1.0573,
      "step": 3250
    },
    {
      "epoch": 0.16391794046661304,
      "grad_norm": 9.0,
      "learning_rate": 1.9672164119066774e-05,
      "loss": 1.0104,
      "step": 3260
    },
    {
      "epoch": 0.16442075623491553,
      "grad_norm": 3.90625,
      "learning_rate": 1.967115848753017e-05,
      "loss": 0.8098,
      "step": 3270
    },
    {
      "epoch": 0.16492357200321803,
      "grad_norm": 15.375,
      "learning_rate": 1.9670152855993565e-05,
      "loss": 0.8626,
      "step": 3280
    },
    {
      "epoch": 0.16542638777152052,
      "grad_norm": 40.5,
      "learning_rate": 1.966914722445696e-05,
      "loss": 0.9948,
      "step": 3290
    },
    {
      "epoch": 0.16592920353982302,
      "grad_norm": 22.375,
      "learning_rate": 1.9668141592920357e-05,
      "loss": 0.9389,
      "step": 3300
    },
    {
      "epoch": 0.1664320193081255,
      "grad_norm": 19.375,
      "learning_rate": 1.966713596138375e-05,
      "loss": 1.3179,
      "step": 3310
    },
    {
      "epoch": 0.166934835076428,
      "grad_norm": 8.9375,
      "learning_rate": 1.9666130329847145e-05,
      "loss": 0.8864,
      "step": 3320
    },
    {
      "epoch": 0.1674376508447305,
      "grad_norm": 17.5,
      "learning_rate": 1.966512469831054e-05,
      "loss": 1.1146,
      "step": 3330
    },
    {
      "epoch": 0.167940466613033,
      "grad_norm": 29.5,
      "learning_rate": 1.9664119066773934e-05,
      "loss": 1.1229,
      "step": 3340
    },
    {
      "epoch": 0.1684432823813355,
      "grad_norm": 54.25,
      "learning_rate": 1.966311343523733e-05,
      "loss": 1.0238,
      "step": 3350
    },
    {
      "epoch": 0.16894609814963799,
      "grad_norm": 33.0,
      "learning_rate": 1.9662107803700726e-05,
      "loss": 1.0284,
      "step": 3360
    },
    {
      "epoch": 0.16944891391794048,
      "grad_norm": 26.375,
      "learning_rate": 1.966110217216412e-05,
      "loss": 1.0578,
      "step": 3370
    },
    {
      "epoch": 0.16995172968624295,
      "grad_norm": 66.5,
      "learning_rate": 1.9660096540627517e-05,
      "loss": 1.3476,
      "step": 3380
    },
    {
      "epoch": 0.17045454545454544,
      "grad_norm": 20.625,
      "learning_rate": 1.965909090909091e-05,
      "loss": 1.038,
      "step": 3390
    },
    {
      "epoch": 0.17095736122284794,
      "grad_norm": 23.625,
      "learning_rate": 1.9658085277554306e-05,
      "loss": 0.8734,
      "step": 3400
    },
    {
      "epoch": 0.17146017699115043,
      "grad_norm": 25.75,
      "learning_rate": 1.96570796460177e-05,
      "loss": 0.9469,
      "step": 3410
    },
    {
      "epoch": 0.17196299275945293,
      "grad_norm": 39.0,
      "learning_rate": 1.9656074014481094e-05,
      "loss": 1.0126,
      "step": 3420
    },
    {
      "epoch": 0.17246580852775542,
      "grad_norm": 11.125,
      "learning_rate": 1.965506838294449e-05,
      "loss": 1.171,
      "step": 3430
    },
    {
      "epoch": 0.17296862429605792,
      "grad_norm": 14.9375,
      "learning_rate": 1.9654062751407886e-05,
      "loss": 0.8855,
      "step": 3440
    },
    {
      "epoch": 0.1734714400643604,
      "grad_norm": 18.375,
      "learning_rate": 1.9653057119871282e-05,
      "loss": 0.826,
      "step": 3450
    },
    {
      "epoch": 0.1739742558326629,
      "grad_norm": 34.25,
      "learning_rate": 1.9652051488334674e-05,
      "loss": 1.0488,
      "step": 3460
    },
    {
      "epoch": 0.1744770716009654,
      "grad_norm": 25.5,
      "learning_rate": 1.965104585679807e-05,
      "loss": 1.3076,
      "step": 3470
    },
    {
      "epoch": 0.1749798873692679,
      "grad_norm": 48.25,
      "learning_rate": 1.9650040225261466e-05,
      "loss": 1.0111,
      "step": 3480
    },
    {
      "epoch": 0.1754827031375704,
      "grad_norm": 12.625,
      "learning_rate": 1.9649034593724862e-05,
      "loss": 0.8922,
      "step": 3490
    },
    {
      "epoch": 0.17598551890587288,
      "grad_norm": 9.375,
      "learning_rate": 1.9648028962188254e-05,
      "loss": 0.8531,
      "step": 3500
    },
    {
      "epoch": 0.17598551890587288,
      "eval_accuracy": 0.5079573624194348,
      "eval_loss": 1.1100460290908813,
      "eval_runtime": 464.6001,
      "eval_samples_per_second": 86.827,
      "eval_steps_per_second": 86.827,
      "step": 3500
    },
    {
      "epoch": 0.17648833467417538,
      "grad_norm": 8.75,
      "learning_rate": 1.964702333065165e-05,
      "loss": 0.9134,
      "step": 3510
    },
    {
      "epoch": 0.17699115044247787,
      "grad_norm": 28.375,
      "learning_rate": 1.9646017699115046e-05,
      "loss": 0.8783,
      "step": 3520
    },
    {
      "epoch": 0.17749396621078037,
      "grad_norm": 50.75,
      "learning_rate": 1.9645012067578442e-05,
      "loss": 1.157,
      "step": 3530
    },
    {
      "epoch": 0.17799678197908286,
      "grad_norm": 7.1875,
      "learning_rate": 1.9644006436041834e-05,
      "loss": 0.9487,
      "step": 3540
    },
    {
      "epoch": 0.17849959774738536,
      "grad_norm": 20.625,
      "learning_rate": 1.964300080450523e-05,
      "loss": 1.0309,
      "step": 3550
    },
    {
      "epoch": 0.17900241351568785,
      "grad_norm": 11.125,
      "learning_rate": 1.9641995172968626e-05,
      "loss": 1.1905,
      "step": 3560
    },
    {
      "epoch": 0.17950522928399035,
      "grad_norm": 48.75,
      "learning_rate": 1.9640989541432022e-05,
      "loss": 1.1218,
      "step": 3570
    },
    {
      "epoch": 0.18000804505229284,
      "grad_norm": 19.0,
      "learning_rate": 1.9639983909895418e-05,
      "loss": 0.6753,
      "step": 3580
    },
    {
      "epoch": 0.18051086082059534,
      "grad_norm": 77.5,
      "learning_rate": 1.963897827835881e-05,
      "loss": 1.2511,
      "step": 3590
    },
    {
      "epoch": 0.18101367658889783,
      "grad_norm": 5.40625,
      "learning_rate": 1.9637972646822206e-05,
      "loss": 0.9225,
      "step": 3600
    },
    {
      "epoch": 0.18151649235720033,
      "grad_norm": 19.625,
      "learning_rate": 1.9636967015285602e-05,
      "loss": 0.8115,
      "step": 3610
    },
    {
      "epoch": 0.18201930812550282,
      "grad_norm": 32.0,
      "learning_rate": 1.9635961383748995e-05,
      "loss": 1.2921,
      "step": 3620
    },
    {
      "epoch": 0.18252212389380532,
      "grad_norm": 8.375,
      "learning_rate": 1.963495575221239e-05,
      "loss": 1.0419,
      "step": 3630
    },
    {
      "epoch": 0.1830249396621078,
      "grad_norm": 20.875,
      "learning_rate": 1.9633950120675786e-05,
      "loss": 0.98,
      "step": 3640
    },
    {
      "epoch": 0.1835277554304103,
      "grad_norm": 9.1875,
      "learning_rate": 1.9632944489139182e-05,
      "loss": 0.9442,
      "step": 3650
    },
    {
      "epoch": 0.1840305711987128,
      "grad_norm": 45.75,
      "learning_rate": 1.9631938857602578e-05,
      "loss": 1.0846,
      "step": 3660
    },
    {
      "epoch": 0.1845333869670153,
      "grad_norm": 22.125,
      "learning_rate": 1.963093322606597e-05,
      "loss": 1.0126,
      "step": 3670
    },
    {
      "epoch": 0.1850362027353178,
      "grad_norm": 43.75,
      "learning_rate": 1.9629927594529367e-05,
      "loss": 1.1099,
      "step": 3680
    },
    {
      "epoch": 0.18553901850362028,
      "grad_norm": 46.75,
      "learning_rate": 1.9628921962992762e-05,
      "loss": 1.1183,
      "step": 3690
    },
    {
      "epoch": 0.18604183427192278,
      "grad_norm": 13.75,
      "learning_rate": 1.9627916331456155e-05,
      "loss": 0.9883,
      "step": 3700
    },
    {
      "epoch": 0.18654465004022527,
      "grad_norm": 25.875,
      "learning_rate": 1.962691069991955e-05,
      "loss": 1.2724,
      "step": 3710
    },
    {
      "epoch": 0.18704746580852777,
      "grad_norm": 24.625,
      "learning_rate": 1.9625905068382947e-05,
      "loss": 1.1897,
      "step": 3720
    },
    {
      "epoch": 0.18755028157683024,
      "grad_norm": 6.1875,
      "learning_rate": 1.962489943684634e-05,
      "loss": 1.0065,
      "step": 3730
    },
    {
      "epoch": 0.18805309734513273,
      "grad_norm": 31.75,
      "learning_rate": 1.962389380530974e-05,
      "loss": 0.7861,
      "step": 3740
    },
    {
      "epoch": 0.18855591311343523,
      "grad_norm": 10.375,
      "learning_rate": 1.962288817377313e-05,
      "loss": 1.023,
      "step": 3750
    },
    {
      "epoch": 0.18905872888173772,
      "grad_norm": 44.75,
      "learning_rate": 1.9621882542236527e-05,
      "loss": 1.2087,
      "step": 3760
    },
    {
      "epoch": 0.18956154465004021,
      "grad_norm": 35.75,
      "learning_rate": 1.9620876910699923e-05,
      "loss": 1.0604,
      "step": 3770
    },
    {
      "epoch": 0.1900643604183427,
      "grad_norm": 12.75,
      "learning_rate": 1.9619871279163315e-05,
      "loss": 1.0656,
      "step": 3780
    },
    {
      "epoch": 0.1905671761866452,
      "grad_norm": 12.375,
      "learning_rate": 1.961886564762671e-05,
      "loss": 0.9752,
      "step": 3790
    },
    {
      "epoch": 0.1910699919549477,
      "grad_norm": 17.0,
      "learning_rate": 1.9617860016090107e-05,
      "loss": 1.2524,
      "step": 3800
    },
    {
      "epoch": 0.1915728077232502,
      "grad_norm": 19.375,
      "learning_rate": 1.96168543845535e-05,
      "loss": 0.7638,
      "step": 3810
    },
    {
      "epoch": 0.1920756234915527,
      "grad_norm": 26.75,
      "learning_rate": 1.96158487530169e-05,
      "loss": 1.0806,
      "step": 3820
    },
    {
      "epoch": 0.19257843925985518,
      "grad_norm": 17.125,
      "learning_rate": 1.961484312148029e-05,
      "loss": 0.9267,
      "step": 3830
    },
    {
      "epoch": 0.19308125502815768,
      "grad_norm": 6.09375,
      "learning_rate": 1.9613837489943687e-05,
      "loss": 1.0405,
      "step": 3840
    },
    {
      "epoch": 0.19358407079646017,
      "grad_norm": 10.5,
      "learning_rate": 1.9612831858407083e-05,
      "loss": 0.968,
      "step": 3850
    },
    {
      "epoch": 0.19408688656476267,
      "grad_norm": 52.25,
      "learning_rate": 1.9611826226870475e-05,
      "loss": 1.0611,
      "step": 3860
    },
    {
      "epoch": 0.19458970233306516,
      "grad_norm": 16.875,
      "learning_rate": 1.961082059533387e-05,
      "loss": 1.0277,
      "step": 3870
    },
    {
      "epoch": 0.19509251810136766,
      "grad_norm": 29.125,
      "learning_rate": 1.9609814963797267e-05,
      "loss": 1.0115,
      "step": 3880
    },
    {
      "epoch": 0.19559533386967015,
      "grad_norm": 17.125,
      "learning_rate": 1.960880933226066e-05,
      "loss": 0.7579,
      "step": 3890
    },
    {
      "epoch": 0.19609814963797265,
      "grad_norm": 12.3125,
      "learning_rate": 1.960780370072406e-05,
      "loss": 0.9264,
      "step": 3900
    },
    {
      "epoch": 0.19660096540627514,
      "grad_norm": 10.25,
      "learning_rate": 1.960679806918745e-05,
      "loss": 0.982,
      "step": 3910
    },
    {
      "epoch": 0.19710378117457764,
      "grad_norm": 17.375,
      "learning_rate": 1.9605792437650847e-05,
      "loss": 1.0946,
      "step": 3920
    },
    {
      "epoch": 0.19760659694288013,
      "grad_norm": 8.3125,
      "learning_rate": 1.9604786806114243e-05,
      "loss": 0.8287,
      "step": 3930
    },
    {
      "epoch": 0.19810941271118263,
      "grad_norm": 60.25,
      "learning_rate": 1.9603781174577636e-05,
      "loss": 0.6994,
      "step": 3940
    },
    {
      "epoch": 0.19861222847948512,
      "grad_norm": 25.375,
      "learning_rate": 1.960277554304103e-05,
      "loss": 1.2245,
      "step": 3950
    },
    {
      "epoch": 0.19911504424778761,
      "grad_norm": 8.5625,
      "learning_rate": 1.9601769911504427e-05,
      "loss": 0.9013,
      "step": 3960
    },
    {
      "epoch": 0.1996178600160901,
      "grad_norm": 27.5,
      "learning_rate": 1.960076427996782e-05,
      "loss": 1.1515,
      "step": 3970
    },
    {
      "epoch": 0.2001206757843926,
      "grad_norm": 10.25,
      "learning_rate": 1.9599758648431216e-05,
      "loss": 1.1107,
      "step": 3980
    },
    {
      "epoch": 0.2006234915526951,
      "grad_norm": 28.75,
      "learning_rate": 1.9598753016894612e-05,
      "loss": 1.2571,
      "step": 3990
    },
    {
      "epoch": 0.2011263073209976,
      "grad_norm": 33.5,
      "learning_rate": 1.9597747385358004e-05,
      "loss": 1.0971,
      "step": 4000
    },
    {
      "epoch": 0.2011263073209976,
      "eval_accuracy": 0.5077590480912246,
      "eval_loss": 1.097894310951233,
      "eval_runtime": 464.6177,
      "eval_samples_per_second": 86.824,
      "eval_steps_per_second": 86.824,
      "step": 4000
    },
    {
      "epoch": 0.2016291230893001,
      "grad_norm": 3.84375,
      "learning_rate": 1.9596741753821404e-05,
      "loss": 1.1303,
      "step": 4010
    },
    {
      "epoch": 0.20213193885760258,
      "grad_norm": 22.375,
      "learning_rate": 1.9595736122284796e-05,
      "loss": 1.0239,
      "step": 4020
    },
    {
      "epoch": 0.20263475462590508,
      "grad_norm": 16.625,
      "learning_rate": 1.9594730490748192e-05,
      "loss": 1.1429,
      "step": 4030
    },
    {
      "epoch": 0.20313757039420757,
      "grad_norm": 36.0,
      "learning_rate": 1.9593724859211588e-05,
      "loss": 0.7378,
      "step": 4040
    },
    {
      "epoch": 0.20364038616251007,
      "grad_norm": 28.375,
      "learning_rate": 1.959271922767498e-05,
      "loss": 0.969,
      "step": 4050
    },
    {
      "epoch": 0.20414320193081256,
      "grad_norm": 14.75,
      "learning_rate": 1.9591713596138376e-05,
      "loss": 0.9995,
      "step": 4060
    },
    {
      "epoch": 0.20464601769911506,
      "grad_norm": 20.125,
      "learning_rate": 1.9590707964601772e-05,
      "loss": 1.1259,
      "step": 4070
    },
    {
      "epoch": 0.20514883346741755,
      "grad_norm": 51.0,
      "learning_rate": 1.9589702333065164e-05,
      "loss": 1.1447,
      "step": 4080
    },
    {
      "epoch": 0.20565164923572002,
      "grad_norm": 23.875,
      "learning_rate": 1.9588696701528564e-05,
      "loss": 0.8061,
      "step": 4090
    },
    {
      "epoch": 0.2061544650040225,
      "grad_norm": 8.6875,
      "learning_rate": 1.9587691069991956e-05,
      "loss": 1.1893,
      "step": 4100
    },
    {
      "epoch": 0.206657280772325,
      "grad_norm": 22.375,
      "learning_rate": 1.9586685438455352e-05,
      "loss": 0.7757,
      "step": 4110
    },
    {
      "epoch": 0.2071600965406275,
      "grad_norm": 22.75,
      "learning_rate": 1.9585679806918748e-05,
      "loss": 1.3131,
      "step": 4120
    },
    {
      "epoch": 0.20766291230893,
      "grad_norm": 9.4375,
      "learning_rate": 1.958467417538214e-05,
      "loss": 0.9484,
      "step": 4130
    },
    {
      "epoch": 0.2081657280772325,
      "grad_norm": 19.875,
      "learning_rate": 1.9583668543845536e-05,
      "loss": 1.1217,
      "step": 4140
    },
    {
      "epoch": 0.208668543845535,
      "grad_norm": 21.25,
      "learning_rate": 1.9582662912308932e-05,
      "loss": 0.8891,
      "step": 4150
    },
    {
      "epoch": 0.20917135961383748,
      "grad_norm": 29.875,
      "learning_rate": 1.9581657280772325e-05,
      "loss": 1.356,
      "step": 4160
    },
    {
      "epoch": 0.20967417538213998,
      "grad_norm": 27.5,
      "learning_rate": 1.9580651649235724e-05,
      "loss": 0.953,
      "step": 4170
    },
    {
      "epoch": 0.21017699115044247,
      "grad_norm": 16.375,
      "learning_rate": 1.9579646017699117e-05,
      "loss": 1.2229,
      "step": 4180
    },
    {
      "epoch": 0.21067980691874497,
      "grad_norm": 10.8125,
      "learning_rate": 1.9578640386162512e-05,
      "loss": 0.8228,
      "step": 4190
    },
    {
      "epoch": 0.21118262268704746,
      "grad_norm": 38.0,
      "learning_rate": 1.9577634754625908e-05,
      "loss": 1.3557,
      "step": 4200
    },
    {
      "epoch": 0.21168543845534996,
      "grad_norm": 39.5,
      "learning_rate": 1.95766291230893e-05,
      "loss": 1.24,
      "step": 4210
    },
    {
      "epoch": 0.21218825422365245,
      "grad_norm": 35.0,
      "learning_rate": 1.9575623491552697e-05,
      "loss": 1.0844,
      "step": 4220
    },
    {
      "epoch": 0.21269106999195495,
      "grad_norm": 28.375,
      "learning_rate": 1.9574617860016093e-05,
      "loss": 1.1495,
      "step": 4230
    },
    {
      "epoch": 0.21319388576025744,
      "grad_norm": 18.75,
      "learning_rate": 1.9573612228479485e-05,
      "loss": 0.9143,
      "step": 4240
    },
    {
      "epoch": 0.21369670152855993,
      "grad_norm": 25.375,
      "learning_rate": 1.957260659694288e-05,
      "loss": 1.1959,
      "step": 4250
    },
    {
      "epoch": 0.21419951729686243,
      "grad_norm": 17.875,
      "learning_rate": 1.9571600965406277e-05,
      "loss": 1.0442,
      "step": 4260
    },
    {
      "epoch": 0.21470233306516492,
      "grad_norm": 13.25,
      "learning_rate": 1.957059533386967e-05,
      "loss": 1.0244,
      "step": 4270
    },
    {
      "epoch": 0.21520514883346742,
      "grad_norm": 21.0,
      "learning_rate": 1.956958970233307e-05,
      "loss": 1.0442,
      "step": 4280
    },
    {
      "epoch": 0.2157079646017699,
      "grad_norm": 15.375,
      "learning_rate": 1.956858407079646e-05,
      "loss": 0.861,
      "step": 4290
    },
    {
      "epoch": 0.2162107803700724,
      "grad_norm": 65.5,
      "learning_rate": 1.9567578439259857e-05,
      "loss": 1.4535,
      "step": 4300
    },
    {
      "epoch": 0.2167135961383749,
      "grad_norm": 23.25,
      "learning_rate": 1.9566572807723253e-05,
      "loss": 1.0114,
      "step": 4310
    },
    {
      "epoch": 0.2172164119066774,
      "grad_norm": 14.1875,
      "learning_rate": 1.9565567176186645e-05,
      "loss": 1.2991,
      "step": 4320
    },
    {
      "epoch": 0.2177192276749799,
      "grad_norm": 48.75,
      "learning_rate": 1.956456154465004e-05,
      "loss": 1.323,
      "step": 4330
    },
    {
      "epoch": 0.2182220434432824,
      "grad_norm": 25.75,
      "learning_rate": 1.9563555913113437e-05,
      "loss": 1.0964,
      "step": 4340
    },
    {
      "epoch": 0.21872485921158488,
      "grad_norm": 12.3125,
      "learning_rate": 1.956255028157683e-05,
      "loss": 1.1695,
      "step": 4350
    },
    {
      "epoch": 0.21922767497988738,
      "grad_norm": 28.625,
      "learning_rate": 1.956154465004023e-05,
      "loss": 1.1963,
      "step": 4360
    },
    {
      "epoch": 0.21973049074818987,
      "grad_norm": 11.9375,
      "learning_rate": 1.956053901850362e-05,
      "loss": 0.8997,
      "step": 4370
    },
    {
      "epoch": 0.22023330651649237,
      "grad_norm": 18.5,
      "learning_rate": 1.9559533386967017e-05,
      "loss": 1.2917,
      "step": 4380
    },
    {
      "epoch": 0.22073612228479486,
      "grad_norm": 6.96875,
      "learning_rate": 1.9558527755430413e-05,
      "loss": 0.684,
      "step": 4390
    },
    {
      "epoch": 0.22123893805309736,
      "grad_norm": 22.25,
      "learning_rate": 1.9557522123893806e-05,
      "loss": 0.9889,
      "step": 4400
    },
    {
      "epoch": 0.22174175382139985,
      "grad_norm": 39.25,
      "learning_rate": 1.95565164923572e-05,
      "loss": 0.9339,
      "step": 4410
    },
    {
      "epoch": 0.22224456958970235,
      "grad_norm": 46.25,
      "learning_rate": 1.9555510860820597e-05,
      "loss": 0.9435,
      "step": 4420
    },
    {
      "epoch": 0.22274738535800484,
      "grad_norm": 36.75,
      "learning_rate": 1.955450522928399e-05,
      "loss": 1.0856,
      "step": 4430
    },
    {
      "epoch": 0.2232502011263073,
      "grad_norm": 15.625,
      "learning_rate": 1.955349959774739e-05,
      "loss": 0.9348,
      "step": 4440
    },
    {
      "epoch": 0.2237530168946098,
      "grad_norm": 27.25,
      "learning_rate": 1.955249396621078e-05,
      "loss": 0.9071,
      "step": 4450
    },
    {
      "epoch": 0.2242558326629123,
      "grad_norm": 25.75,
      "learning_rate": 1.9551488334674177e-05,
      "loss": 0.9518,
      "step": 4460
    },
    {
      "epoch": 0.2247586484312148,
      "grad_norm": 38.25,
      "learning_rate": 1.9550482703137573e-05,
      "loss": 1.0416,
      "step": 4470
    },
    {
      "epoch": 0.2252614641995173,
      "grad_norm": 7.625,
      "learning_rate": 1.9549477071600966e-05,
      "loss": 1.0962,
      "step": 4480
    },
    {
      "epoch": 0.22576427996781978,
      "grad_norm": 47.5,
      "learning_rate": 1.954847144006436e-05,
      "loss": 1.1588,
      "step": 4490
    },
    {
      "epoch": 0.22626709573612228,
      "grad_norm": 31.25,
      "learning_rate": 1.9547465808527758e-05,
      "loss": 1.0928,
      "step": 4500
    },
    {
      "epoch": 0.22626709573612228,
      "eval_accuracy": 0.5092464055528012,
      "eval_loss": 1.0858546495437622,
      "eval_runtime": 465.0066,
      "eval_samples_per_second": 86.751,
      "eval_steps_per_second": 86.751,
      "step": 4500
    }
  ],
  "logging_steps": 10,
  "max_steps": 198880,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "total_flos": 0.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
