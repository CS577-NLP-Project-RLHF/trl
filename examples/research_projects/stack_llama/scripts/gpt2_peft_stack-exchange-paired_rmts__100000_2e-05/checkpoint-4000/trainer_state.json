{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.6657789613848203,
  "eval_steps": 500,
  "global_step": 4000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0016644474034620505,
      "grad_norm": 82.0,
      "learning_rate": 1.996671105193076e-05,
      "loss": 3.0074,
      "step": 10
    },
    {
      "epoch": 0.003328894806924101,
      "grad_norm": 205.0,
      "learning_rate": 1.9933422103861518e-05,
      "loss": 3.1453,
      "step": 20
    },
    {
      "epoch": 0.004993342210386152,
      "grad_norm": 17.625,
      "learning_rate": 1.990013315579228e-05,
      "loss": 2.3703,
      "step": 30
    },
    {
      "epoch": 0.006657789613848202,
      "grad_norm": 18.875,
      "learning_rate": 1.9866844207723038e-05,
      "loss": 2.0053,
      "step": 40
    },
    {
      "epoch": 0.008322237017310254,
      "grad_norm": 68.5,
      "learning_rate": 1.9833555259653796e-05,
      "loss": 1.8797,
      "step": 50
    },
    {
      "epoch": 0.009986684420772303,
      "grad_norm": 102.0,
      "learning_rate": 1.9800266311584554e-05,
      "loss": 2.2539,
      "step": 60
    },
    {
      "epoch": 0.011651131824234355,
      "grad_norm": 68.5,
      "learning_rate": 1.9766977363515315e-05,
      "loss": 2.3381,
      "step": 70
    },
    {
      "epoch": 0.013315579227696404,
      "grad_norm": 43.75,
      "learning_rate": 1.9733688415446073e-05,
      "loss": 2.4234,
      "step": 80
    },
    {
      "epoch": 0.014980026631158456,
      "grad_norm": 80.5,
      "learning_rate": 1.970039946737683e-05,
      "loss": 2.9699,
      "step": 90
    },
    {
      "epoch": 0.016644474034620507,
      "grad_norm": 110.5,
      "learning_rate": 1.966711051930759e-05,
      "loss": 2.0242,
      "step": 100
    },
    {
      "epoch": 0.018308921438082555,
      "grad_norm": 83.0,
      "learning_rate": 1.963382157123835e-05,
      "loss": 1.9811,
      "step": 110
    },
    {
      "epoch": 0.019973368841544607,
      "grad_norm": 14.375,
      "learning_rate": 1.960053262316911e-05,
      "loss": 1.4082,
      "step": 120
    },
    {
      "epoch": 0.021637816245006658,
      "grad_norm": 6.5625,
      "learning_rate": 1.956724367509987e-05,
      "loss": 2.027,
      "step": 130
    },
    {
      "epoch": 0.02330226364846871,
      "grad_norm": 38.25,
      "learning_rate": 1.953395472703063e-05,
      "loss": 1.9574,
      "step": 140
    },
    {
      "epoch": 0.024966711051930757,
      "grad_norm": 33.75,
      "learning_rate": 1.9500665778961387e-05,
      "loss": 1.8313,
      "step": 150
    },
    {
      "epoch": 0.02663115845539281,
      "grad_norm": 18.875,
      "learning_rate": 1.9467376830892145e-05,
      "loss": 1.3441,
      "step": 160
    },
    {
      "epoch": 0.02829560585885486,
      "grad_norm": 17.5,
      "learning_rate": 1.9434087882822907e-05,
      "loss": 1.6559,
      "step": 170
    },
    {
      "epoch": 0.02996005326231691,
      "grad_norm": 36.5,
      "learning_rate": 1.9400798934753665e-05,
      "loss": 1.5535,
      "step": 180
    },
    {
      "epoch": 0.03162450066577896,
      "grad_norm": 5.90625,
      "learning_rate": 1.9367509986684423e-05,
      "loss": 1.448,
      "step": 190
    },
    {
      "epoch": 0.033288948069241014,
      "grad_norm": 23.875,
      "learning_rate": 1.933422103861518e-05,
      "loss": 1.709,
      "step": 200
    },
    {
      "epoch": 0.03495339547270306,
      "grad_norm": 75.5,
      "learning_rate": 1.930093209054594e-05,
      "loss": 1.5148,
      "step": 210
    },
    {
      "epoch": 0.03661784287616511,
      "grad_norm": 65.5,
      "learning_rate": 1.92676431424767e-05,
      "loss": 1.5078,
      "step": 220
    },
    {
      "epoch": 0.038282290279627165,
      "grad_norm": 29.5,
      "learning_rate": 1.923435419440746e-05,
      "loss": 1.4211,
      "step": 230
    },
    {
      "epoch": 0.03994673768308921,
      "grad_norm": 54.25,
      "learning_rate": 1.9201065246338217e-05,
      "loss": 1.3559,
      "step": 240
    },
    {
      "epoch": 0.04161118508655127,
      "grad_norm": 13.125,
      "learning_rate": 1.9167776298268975e-05,
      "loss": 1.2094,
      "step": 250
    },
    {
      "epoch": 0.043275632490013316,
      "grad_norm": 29.625,
      "learning_rate": 1.9134487350199737e-05,
      "loss": 1.1453,
      "step": 260
    },
    {
      "epoch": 0.044940079893475364,
      "grad_norm": 22.25,
      "learning_rate": 1.9101198402130495e-05,
      "loss": 1.1934,
      "step": 270
    },
    {
      "epoch": 0.04660452729693742,
      "grad_norm": 33.5,
      "learning_rate": 1.9067909454061253e-05,
      "loss": 1.3309,
      "step": 280
    },
    {
      "epoch": 0.04826897470039947,
      "grad_norm": 55.25,
      "learning_rate": 1.903462050599201e-05,
      "loss": 1.5771,
      "step": 290
    },
    {
      "epoch": 0.049933422103861515,
      "grad_norm": 29.75,
      "learning_rate": 1.900133155792277e-05,
      "loss": 1.4488,
      "step": 300
    },
    {
      "epoch": 0.05159786950732357,
      "grad_norm": 16.25,
      "learning_rate": 1.896804260985353e-05,
      "loss": 1.1566,
      "step": 310
    },
    {
      "epoch": 0.05326231691078562,
      "grad_norm": 7.25,
      "learning_rate": 1.893475366178429e-05,
      "loss": 1.1781,
      "step": 320
    },
    {
      "epoch": 0.05492676431424767,
      "grad_norm": 14.75,
      "learning_rate": 1.8901464713715047e-05,
      "loss": 1.4129,
      "step": 330
    },
    {
      "epoch": 0.05659121171770972,
      "grad_norm": 28.75,
      "learning_rate": 1.8868175765645805e-05,
      "loss": 1.2781,
      "step": 340
    },
    {
      "epoch": 0.05825565912117177,
      "grad_norm": 8.875,
      "learning_rate": 1.8834886817576567e-05,
      "loss": 1.3512,
      "step": 350
    },
    {
      "epoch": 0.05992010652463382,
      "grad_norm": 13.25,
      "learning_rate": 1.8801597869507325e-05,
      "loss": 1.3848,
      "step": 360
    },
    {
      "epoch": 0.06158455392809587,
      "grad_norm": 34.25,
      "learning_rate": 1.8768308921438083e-05,
      "loss": 1.1969,
      "step": 370
    },
    {
      "epoch": 0.06324900133155792,
      "grad_norm": 47.25,
      "learning_rate": 1.873501997336884e-05,
      "loss": 1.3902,
      "step": 380
    },
    {
      "epoch": 0.06491344873501997,
      "grad_norm": 9.5,
      "learning_rate": 1.8701731025299603e-05,
      "loss": 0.9904,
      "step": 390
    },
    {
      "epoch": 0.06657789613848203,
      "grad_norm": 47.75,
      "learning_rate": 1.866844207723036e-05,
      "loss": 1.3535,
      "step": 400
    },
    {
      "epoch": 0.06824234354194407,
      "grad_norm": 36.25,
      "learning_rate": 1.8635153129161122e-05,
      "loss": 0.8746,
      "step": 410
    },
    {
      "epoch": 0.06990679094540612,
      "grad_norm": 19.125,
      "learning_rate": 1.860186418109188e-05,
      "loss": 1.4457,
      "step": 420
    },
    {
      "epoch": 0.07157123834886818,
      "grad_norm": 27.875,
      "learning_rate": 1.856857523302264e-05,
      "loss": 1.0061,
      "step": 430
    },
    {
      "epoch": 0.07323568575233022,
      "grad_norm": 24.625,
      "learning_rate": 1.8535286284953397e-05,
      "loss": 1.0208,
      "step": 440
    },
    {
      "epoch": 0.07490013315579228,
      "grad_norm": 29.5,
      "learning_rate": 1.8501997336884158e-05,
      "loss": 1.2641,
      "step": 450
    },
    {
      "epoch": 0.07656458055925433,
      "grad_norm": 26.375,
      "learning_rate": 1.8468708388814916e-05,
      "loss": 1.2277,
      "step": 460
    },
    {
      "epoch": 0.07822902796271637,
      "grad_norm": 42.25,
      "learning_rate": 1.8435419440745674e-05,
      "loss": 1.2291,
      "step": 470
    },
    {
      "epoch": 0.07989347536617843,
      "grad_norm": 51.25,
      "learning_rate": 1.8402130492676432e-05,
      "loss": 1.2758,
      "step": 480
    },
    {
      "epoch": 0.08155792276964048,
      "grad_norm": 53.75,
      "learning_rate": 1.836884154460719e-05,
      "loss": 1.5547,
      "step": 490
    },
    {
      "epoch": 0.08322237017310254,
      "grad_norm": 36.0,
      "learning_rate": 1.8335552596537952e-05,
      "loss": 1.292,
      "step": 500
    },
    {
      "epoch": 0.08322237017310254,
      "eval_accuracy": 0.49730379956860793,
      "eval_loss": 1.3427207469940186,
      "eval_runtime": 697.9048,
      "eval_samples_per_second": 34.543,
      "eval_steps_per_second": 17.272,
      "step": 500
    },
    {
      "epoch": 0.08488681757656458,
      "grad_norm": 22.75,
      "learning_rate": 1.830226364846871e-05,
      "loss": 1.2182,
      "step": 510
    },
    {
      "epoch": 0.08655126498002663,
      "grad_norm": 19.875,
      "learning_rate": 1.826897470039947e-05,
      "loss": 1.0531,
      "step": 520
    },
    {
      "epoch": 0.08821571238348869,
      "grad_norm": 21.0,
      "learning_rate": 1.8235685752330227e-05,
      "loss": 1.0973,
      "step": 530
    },
    {
      "epoch": 0.08988015978695073,
      "grad_norm": 43.25,
      "learning_rate": 1.8202396804260988e-05,
      "loss": 1.0156,
      "step": 540
    },
    {
      "epoch": 0.09154460719041278,
      "grad_norm": 18.375,
      "learning_rate": 1.8169107856191746e-05,
      "loss": 1.0514,
      "step": 550
    },
    {
      "epoch": 0.09320905459387484,
      "grad_norm": 31.0,
      "learning_rate": 1.8135818908122504e-05,
      "loss": 1.1303,
      "step": 560
    },
    {
      "epoch": 0.09487350199733688,
      "grad_norm": 36.25,
      "learning_rate": 1.8102529960053262e-05,
      "loss": 1.1049,
      "step": 570
    },
    {
      "epoch": 0.09653794940079893,
      "grad_norm": 8.5,
      "learning_rate": 1.806924101198402e-05,
      "loss": 1.0469,
      "step": 580
    },
    {
      "epoch": 0.09820239680426099,
      "grad_norm": 12.125,
      "learning_rate": 1.8035952063914782e-05,
      "loss": 0.9684,
      "step": 590
    },
    {
      "epoch": 0.09986684420772303,
      "grad_norm": 46.75,
      "learning_rate": 1.800266311584554e-05,
      "loss": 1.166,
      "step": 600
    },
    {
      "epoch": 0.10153129161118508,
      "grad_norm": 22.125,
      "learning_rate": 1.79693741677763e-05,
      "loss": 1.1551,
      "step": 610
    },
    {
      "epoch": 0.10319573901464714,
      "grad_norm": 9.0,
      "learning_rate": 1.7936085219707056e-05,
      "loss": 1.0684,
      "step": 620
    },
    {
      "epoch": 0.1048601864181092,
      "grad_norm": 22.75,
      "learning_rate": 1.7902796271637818e-05,
      "loss": 1.0961,
      "step": 630
    },
    {
      "epoch": 0.10652463382157124,
      "grad_norm": 21.125,
      "learning_rate": 1.7869507323568576e-05,
      "loss": 1.0809,
      "step": 640
    },
    {
      "epoch": 0.10818908122503329,
      "grad_norm": 20.375,
      "learning_rate": 1.7836218375499338e-05,
      "loss": 0.9951,
      "step": 650
    },
    {
      "epoch": 0.10985352862849534,
      "grad_norm": 14.0625,
      "learning_rate": 1.7802929427430096e-05,
      "loss": 0.9477,
      "step": 660
    },
    {
      "epoch": 0.11151797603195739,
      "grad_norm": 19.25,
      "learning_rate": 1.7769640479360854e-05,
      "loss": 1.1016,
      "step": 670
    },
    {
      "epoch": 0.11318242343541944,
      "grad_norm": 20.625,
      "learning_rate": 1.7736351531291612e-05,
      "loss": 1.2195,
      "step": 680
    },
    {
      "epoch": 0.1148468708388815,
      "grad_norm": 35.5,
      "learning_rate": 1.7703062583222374e-05,
      "loss": 1.1961,
      "step": 690
    },
    {
      "epoch": 0.11651131824234354,
      "grad_norm": 42.75,
      "learning_rate": 1.766977363515313e-05,
      "loss": 1.1164,
      "step": 700
    },
    {
      "epoch": 0.11817576564580559,
      "grad_norm": 27.875,
      "learning_rate": 1.763648468708389e-05,
      "loss": 0.9984,
      "step": 710
    },
    {
      "epoch": 0.11984021304926765,
      "grad_norm": 32.0,
      "learning_rate": 1.7603195739014648e-05,
      "loss": 1.0512,
      "step": 720
    },
    {
      "epoch": 0.12150466045272969,
      "grad_norm": 45.25,
      "learning_rate": 1.756990679094541e-05,
      "loss": 1.302,
      "step": 730
    },
    {
      "epoch": 0.12316910785619174,
      "grad_norm": 10.0,
      "learning_rate": 1.7536617842876168e-05,
      "loss": 1.0992,
      "step": 740
    },
    {
      "epoch": 0.1248335552596538,
      "grad_norm": 9.625,
      "learning_rate": 1.7503328894806926e-05,
      "loss": 0.9535,
      "step": 750
    },
    {
      "epoch": 0.12649800266311584,
      "grad_norm": 23.0,
      "learning_rate": 1.7470039946737684e-05,
      "loss": 1.1754,
      "step": 760
    },
    {
      "epoch": 0.1281624500665779,
      "grad_norm": 17.25,
      "learning_rate": 1.7436750998668442e-05,
      "loss": 1.1402,
      "step": 770
    },
    {
      "epoch": 0.12982689747003995,
      "grad_norm": 39.25,
      "learning_rate": 1.7403462050599203e-05,
      "loss": 1.0141,
      "step": 780
    },
    {
      "epoch": 0.131491344873502,
      "grad_norm": 11.0625,
      "learning_rate": 1.737017310252996e-05,
      "loss": 1.2168,
      "step": 790
    },
    {
      "epoch": 0.13315579227696406,
      "grad_norm": 40.75,
      "learning_rate": 1.733688415446072e-05,
      "loss": 1.027,
      "step": 800
    },
    {
      "epoch": 0.13482023968042608,
      "grad_norm": 34.0,
      "learning_rate": 1.7303595206391478e-05,
      "loss": 1.0939,
      "step": 810
    },
    {
      "epoch": 0.13648468708388814,
      "grad_norm": 22.875,
      "learning_rate": 1.727030625832224e-05,
      "loss": 0.9584,
      "step": 820
    },
    {
      "epoch": 0.1381491344873502,
      "grad_norm": 11.0625,
      "learning_rate": 1.7237017310252998e-05,
      "loss": 1.1285,
      "step": 830
    },
    {
      "epoch": 0.13981358189081225,
      "grad_norm": 11.5,
      "learning_rate": 1.7203728362183756e-05,
      "loss": 1.0547,
      "step": 840
    },
    {
      "epoch": 0.1414780292942743,
      "grad_norm": 8.8125,
      "learning_rate": 1.7170439414114514e-05,
      "loss": 1.0344,
      "step": 850
    },
    {
      "epoch": 0.14314247669773636,
      "grad_norm": 25.875,
      "learning_rate": 1.7137150466045275e-05,
      "loss": 1.2516,
      "step": 860
    },
    {
      "epoch": 0.14480692410119841,
      "grad_norm": 9.75,
      "learning_rate": 1.7103861517976033e-05,
      "loss": 1.1129,
      "step": 870
    },
    {
      "epoch": 0.14647137150466044,
      "grad_norm": 7.75,
      "learning_rate": 1.707057256990679e-05,
      "loss": 1.0324,
      "step": 880
    },
    {
      "epoch": 0.1481358189081225,
      "grad_norm": 6.25,
      "learning_rate": 1.703728362183755e-05,
      "loss": 1.0527,
      "step": 890
    },
    {
      "epoch": 0.14980026631158455,
      "grad_norm": 9.25,
      "learning_rate": 1.7003994673768308e-05,
      "loss": 0.9162,
      "step": 900
    },
    {
      "epoch": 0.1514647137150466,
      "grad_norm": 16.625,
      "learning_rate": 1.697070572569907e-05,
      "loss": 0.8867,
      "step": 910
    },
    {
      "epoch": 0.15312916111850866,
      "grad_norm": 13.4375,
      "learning_rate": 1.693741677762983e-05,
      "loss": 0.9637,
      "step": 920
    },
    {
      "epoch": 0.15479360852197072,
      "grad_norm": 8.125,
      "learning_rate": 1.690412782956059e-05,
      "loss": 1.0559,
      "step": 930
    },
    {
      "epoch": 0.15645805592543274,
      "grad_norm": 32.75,
      "learning_rate": 1.6870838881491347e-05,
      "loss": 0.8594,
      "step": 940
    },
    {
      "epoch": 0.1581225033288948,
      "grad_norm": 20.125,
      "learning_rate": 1.6837549933422105e-05,
      "loss": 1.0273,
      "step": 950
    },
    {
      "epoch": 0.15978695073235685,
      "grad_norm": 7.4375,
      "learning_rate": 1.6804260985352863e-05,
      "loss": 0.9008,
      "step": 960
    },
    {
      "epoch": 0.1614513981358189,
      "grad_norm": 8.75,
      "learning_rate": 1.6770972037283625e-05,
      "loss": 1.1035,
      "step": 970
    },
    {
      "epoch": 0.16311584553928096,
      "grad_norm": 59.25,
      "learning_rate": 1.6737683089214383e-05,
      "loss": 1.166,
      "step": 980
    },
    {
      "epoch": 0.16478029294274302,
      "grad_norm": 23.125,
      "learning_rate": 1.670439414114514e-05,
      "loss": 1.1871,
      "step": 990
    },
    {
      "epoch": 0.16644474034620507,
      "grad_norm": 16.625,
      "learning_rate": 1.66711051930759e-05,
      "loss": 0.9184,
      "step": 1000
    },
    {
      "epoch": 0.16644474034620507,
      "eval_accuracy": 0.5005392400862784,
      "eval_loss": 1.0660072565078735,
      "eval_runtime": 698.2983,
      "eval_samples_per_second": 34.524,
      "eval_steps_per_second": 17.262,
      "step": 1000
    },
    {
      "epoch": 0.1681091877496671,
      "grad_norm": 20.875,
      "learning_rate": 1.663781624500666e-05,
      "loss": 0.9357,
      "step": 1010
    },
    {
      "epoch": 0.16977363515312915,
      "grad_norm": 18.75,
      "learning_rate": 1.660452729693742e-05,
      "loss": 1.4559,
      "step": 1020
    },
    {
      "epoch": 0.1714380825565912,
      "grad_norm": 14.9375,
      "learning_rate": 1.6571238348868177e-05,
      "loss": 1.0592,
      "step": 1030
    },
    {
      "epoch": 0.17310252996005326,
      "grad_norm": 32.5,
      "learning_rate": 1.6537949400798935e-05,
      "loss": 0.9965,
      "step": 1040
    },
    {
      "epoch": 0.17476697736351532,
      "grad_norm": 34.5,
      "learning_rate": 1.6504660452729693e-05,
      "loss": 1.0926,
      "step": 1050
    },
    {
      "epoch": 0.17643142476697737,
      "grad_norm": 15.125,
      "learning_rate": 1.6471371504660455e-05,
      "loss": 0.8855,
      "step": 1060
    },
    {
      "epoch": 0.1780958721704394,
      "grad_norm": 10.375,
      "learning_rate": 1.6438082556591213e-05,
      "loss": 1.0387,
      "step": 1070
    },
    {
      "epoch": 0.17976031957390146,
      "grad_norm": 23.125,
      "learning_rate": 1.640479360852197e-05,
      "loss": 0.8895,
      "step": 1080
    },
    {
      "epoch": 0.1814247669773635,
      "grad_norm": 8.75,
      "learning_rate": 1.637150466045273e-05,
      "loss": 0.918,
      "step": 1090
    },
    {
      "epoch": 0.18308921438082557,
      "grad_norm": 13.0625,
      "learning_rate": 1.633821571238349e-05,
      "loss": 1.3723,
      "step": 1100
    },
    {
      "epoch": 0.18475366178428762,
      "grad_norm": 21.25,
      "learning_rate": 1.630492676431425e-05,
      "loss": 1.1203,
      "step": 1110
    },
    {
      "epoch": 0.18641810918774968,
      "grad_norm": 11.25,
      "learning_rate": 1.6271637816245007e-05,
      "loss": 0.9287,
      "step": 1120
    },
    {
      "epoch": 0.18808255659121173,
      "grad_norm": 10.0,
      "learning_rate": 1.6238348868175765e-05,
      "loss": 0.9258,
      "step": 1130
    },
    {
      "epoch": 0.18974700399467376,
      "grad_norm": 15.0,
      "learning_rate": 1.6205059920106527e-05,
      "loss": 1.1258,
      "step": 1140
    },
    {
      "epoch": 0.1914114513981358,
      "grad_norm": 6.84375,
      "learning_rate": 1.6171770972037285e-05,
      "loss": 0.9473,
      "step": 1150
    },
    {
      "epoch": 0.19307589880159787,
      "grad_norm": 8.5,
      "learning_rate": 1.6138482023968043e-05,
      "loss": 0.9902,
      "step": 1160
    },
    {
      "epoch": 0.19474034620505992,
      "grad_norm": 10.625,
      "learning_rate": 1.6105193075898804e-05,
      "loss": 1.0793,
      "step": 1170
    },
    {
      "epoch": 0.19640479360852198,
      "grad_norm": 14.0625,
      "learning_rate": 1.6071904127829563e-05,
      "loss": 0.9207,
      "step": 1180
    },
    {
      "epoch": 0.19806924101198403,
      "grad_norm": 23.375,
      "learning_rate": 1.603861517976032e-05,
      "loss": 1.0547,
      "step": 1190
    },
    {
      "epoch": 0.19973368841544606,
      "grad_norm": 3.578125,
      "learning_rate": 1.6005326231691082e-05,
      "loss": 0.9613,
      "step": 1200
    },
    {
      "epoch": 0.20139813581890811,
      "grad_norm": 15.0,
      "learning_rate": 1.597203728362184e-05,
      "loss": 0.932,
      "step": 1210
    },
    {
      "epoch": 0.20306258322237017,
      "grad_norm": 8.0625,
      "learning_rate": 1.59387483355526e-05,
      "loss": 0.9164,
      "step": 1220
    },
    {
      "epoch": 0.20472703062583222,
      "grad_norm": 40.5,
      "learning_rate": 1.5905459387483357e-05,
      "loss": 1.0641,
      "step": 1230
    },
    {
      "epoch": 0.20639147802929428,
      "grad_norm": 24.0,
      "learning_rate": 1.5872170439414115e-05,
      "loss": 0.99,
      "step": 1240
    },
    {
      "epoch": 0.20805592543275633,
      "grad_norm": 7.09375,
      "learning_rate": 1.5838881491344876e-05,
      "loss": 0.8512,
      "step": 1250
    },
    {
      "epoch": 0.2097203728362184,
      "grad_norm": 8.1875,
      "learning_rate": 1.5805592543275634e-05,
      "loss": 1.0039,
      "step": 1260
    },
    {
      "epoch": 0.21138482023968042,
      "grad_norm": 22.25,
      "learning_rate": 1.5772303595206392e-05,
      "loss": 1.1766,
      "step": 1270
    },
    {
      "epoch": 0.21304926764314247,
      "grad_norm": 19.0,
      "learning_rate": 1.573901464713715e-05,
      "loss": 0.9977,
      "step": 1280
    },
    {
      "epoch": 0.21471371504660453,
      "grad_norm": 24.125,
      "learning_rate": 1.5705725699067912e-05,
      "loss": 1.0371,
      "step": 1290
    },
    {
      "epoch": 0.21637816245006658,
      "grad_norm": 14.75,
      "learning_rate": 1.567243675099867e-05,
      "loss": 1.0277,
      "step": 1300
    },
    {
      "epoch": 0.21804260985352863,
      "grad_norm": 19.625,
      "learning_rate": 1.563914780292943e-05,
      "loss": 1.0273,
      "step": 1310
    },
    {
      "epoch": 0.2197070572569907,
      "grad_norm": 11.5,
      "learning_rate": 1.5605858854860187e-05,
      "loss": 0.9012,
      "step": 1320
    },
    {
      "epoch": 0.22137150466045272,
      "grad_norm": 59.0,
      "learning_rate": 1.5572569906790948e-05,
      "loss": 0.9426,
      "step": 1330
    },
    {
      "epoch": 0.22303595206391477,
      "grad_norm": 22.5,
      "learning_rate": 1.5539280958721706e-05,
      "loss": 1.1695,
      "step": 1340
    },
    {
      "epoch": 0.22470039946737683,
      "grad_norm": 11.5,
      "learning_rate": 1.5505992010652464e-05,
      "loss": 0.9965,
      "step": 1350
    },
    {
      "epoch": 0.22636484687083888,
      "grad_norm": 15.0625,
      "learning_rate": 1.5472703062583222e-05,
      "loss": 1.1371,
      "step": 1360
    },
    {
      "epoch": 0.22802929427430094,
      "grad_norm": 40.0,
      "learning_rate": 1.543941411451398e-05,
      "loss": 1.0285,
      "step": 1370
    },
    {
      "epoch": 0.229693741677763,
      "grad_norm": 7.5625,
      "learning_rate": 1.5406125166444742e-05,
      "loss": 1.2141,
      "step": 1380
    },
    {
      "epoch": 0.23135818908122505,
      "grad_norm": 40.25,
      "learning_rate": 1.53728362183755e-05,
      "loss": 1.1344,
      "step": 1390
    },
    {
      "epoch": 0.23302263648468707,
      "grad_norm": 14.25,
      "learning_rate": 1.533954727030626e-05,
      "loss": 1.0766,
      "step": 1400
    },
    {
      "epoch": 0.23468708388814913,
      "grad_norm": 34.25,
      "learning_rate": 1.5306258322237016e-05,
      "loss": 1.2734,
      "step": 1410
    },
    {
      "epoch": 0.23635153129161118,
      "grad_norm": 14.375,
      "learning_rate": 1.5272969374167778e-05,
      "loss": 1.0312,
      "step": 1420
    },
    {
      "epoch": 0.23801597869507324,
      "grad_norm": 29.75,
      "learning_rate": 1.5239680426098538e-05,
      "loss": 1.143,
      "step": 1430
    },
    {
      "epoch": 0.2396804260985353,
      "grad_norm": 16.125,
      "learning_rate": 1.5206391478029296e-05,
      "loss": 0.9922,
      "step": 1440
    },
    {
      "epoch": 0.24134487350199735,
      "grad_norm": 24.0,
      "learning_rate": 1.5173102529960056e-05,
      "loss": 1.0809,
      "step": 1450
    },
    {
      "epoch": 0.24300932090545938,
      "grad_norm": 29.875,
      "learning_rate": 1.5139813581890814e-05,
      "loss": 1.0395,
      "step": 1460
    },
    {
      "epoch": 0.24467376830892143,
      "grad_norm": 7.65625,
      "learning_rate": 1.5106524633821574e-05,
      "loss": 0.8957,
      "step": 1470
    },
    {
      "epoch": 0.24633821571238348,
      "grad_norm": 25.5,
      "learning_rate": 1.5073235685752332e-05,
      "loss": 0.891,
      "step": 1480
    },
    {
      "epoch": 0.24800266311584554,
      "grad_norm": 20.5,
      "learning_rate": 1.5039946737683092e-05,
      "loss": 0.8908,
      "step": 1490
    },
    {
      "epoch": 0.2496671105193076,
      "grad_norm": 21.375,
      "learning_rate": 1.500665778961385e-05,
      "loss": 0.9566,
      "step": 1500
    },
    {
      "epoch": 0.2496671105193076,
      "eval_accuracy": 0.5007881201260992,
      "eval_loss": 1.013507604598999,
      "eval_runtime": 697.1064,
      "eval_samples_per_second": 34.583,
      "eval_steps_per_second": 17.291,
      "step": 1500
    },
    {
      "epoch": 0.2513315579227696,
      "grad_norm": 36.25,
      "learning_rate": 1.497336884154461e-05,
      "loss": 0.9961,
      "step": 1510
    },
    {
      "epoch": 0.2529960053262317,
      "grad_norm": 10.1875,
      "learning_rate": 1.4940079893475368e-05,
      "loss": 0.909,
      "step": 1520
    },
    {
      "epoch": 0.25466045272969373,
      "grad_norm": 34.0,
      "learning_rate": 1.4906790945406126e-05,
      "loss": 0.9395,
      "step": 1530
    },
    {
      "epoch": 0.2563249001331558,
      "grad_norm": 14.25,
      "learning_rate": 1.4873501997336886e-05,
      "loss": 0.891,
      "step": 1540
    },
    {
      "epoch": 0.25798934753661784,
      "grad_norm": 14.1875,
      "learning_rate": 1.4840213049267644e-05,
      "loss": 1.2559,
      "step": 1550
    },
    {
      "epoch": 0.2596537949400799,
      "grad_norm": 17.5,
      "learning_rate": 1.4806924101198404e-05,
      "loss": 0.9992,
      "step": 1560
    },
    {
      "epoch": 0.26131824234354195,
      "grad_norm": 12.3125,
      "learning_rate": 1.4773635153129162e-05,
      "loss": 0.8766,
      "step": 1570
    },
    {
      "epoch": 0.262982689747004,
      "grad_norm": 6.875,
      "learning_rate": 1.4740346205059922e-05,
      "loss": 0.9133,
      "step": 1580
    },
    {
      "epoch": 0.26464713715046606,
      "grad_norm": 7.5625,
      "learning_rate": 1.470705725699068e-05,
      "loss": 1.0344,
      "step": 1590
    },
    {
      "epoch": 0.2663115845539281,
      "grad_norm": 28.5,
      "learning_rate": 1.467376830892144e-05,
      "loss": 1.0488,
      "step": 1600
    },
    {
      "epoch": 0.26797603195739017,
      "grad_norm": 37.5,
      "learning_rate": 1.4640479360852198e-05,
      "loss": 0.9721,
      "step": 1610
    },
    {
      "epoch": 0.26964047936085217,
      "grad_norm": 21.125,
      "learning_rate": 1.4607190412782957e-05,
      "loss": 0.8549,
      "step": 1620
    },
    {
      "epoch": 0.2713049267643142,
      "grad_norm": 15.9375,
      "learning_rate": 1.4573901464713716e-05,
      "loss": 0.8758,
      "step": 1630
    },
    {
      "epoch": 0.2729693741677763,
      "grad_norm": 7.8125,
      "learning_rate": 1.4540612516644474e-05,
      "loss": 0.8523,
      "step": 1640
    },
    {
      "epoch": 0.27463382157123833,
      "grad_norm": 12.75,
      "learning_rate": 1.4507323568575234e-05,
      "loss": 0.9883,
      "step": 1650
    },
    {
      "epoch": 0.2762982689747004,
      "grad_norm": 25.125,
      "learning_rate": 1.4474034620505992e-05,
      "loss": 0.9488,
      "step": 1660
    },
    {
      "epoch": 0.27796271637816244,
      "grad_norm": 39.75,
      "learning_rate": 1.4440745672436752e-05,
      "loss": 1.1777,
      "step": 1670
    },
    {
      "epoch": 0.2796271637816245,
      "grad_norm": 14.375,
      "learning_rate": 1.440745672436751e-05,
      "loss": 0.9859,
      "step": 1680
    },
    {
      "epoch": 0.28129161118508655,
      "grad_norm": 17.0,
      "learning_rate": 1.4374167776298271e-05,
      "loss": 1.1844,
      "step": 1690
    },
    {
      "epoch": 0.2829560585885486,
      "grad_norm": 21.375,
      "learning_rate": 1.434087882822903e-05,
      "loss": 1.1875,
      "step": 1700
    },
    {
      "epoch": 0.28462050599201066,
      "grad_norm": 10.0,
      "learning_rate": 1.4307589880159789e-05,
      "loss": 1.0121,
      "step": 1710
    },
    {
      "epoch": 0.2862849533954727,
      "grad_norm": 5.40625,
      "learning_rate": 1.4274300932090547e-05,
      "loss": 1.1633,
      "step": 1720
    },
    {
      "epoch": 0.2879494007989348,
      "grad_norm": 32.5,
      "learning_rate": 1.4241011984021307e-05,
      "loss": 1.1305,
      "step": 1730
    },
    {
      "epoch": 0.28961384820239683,
      "grad_norm": 33.75,
      "learning_rate": 1.4207723035952065e-05,
      "loss": 0.9428,
      "step": 1740
    },
    {
      "epoch": 0.29127829560585883,
      "grad_norm": 4.8125,
      "learning_rate": 1.4174434087882825e-05,
      "loss": 1.1418,
      "step": 1750
    },
    {
      "epoch": 0.2929427430093209,
      "grad_norm": 11.0,
      "learning_rate": 1.4141145139813583e-05,
      "loss": 1.2621,
      "step": 1760
    },
    {
      "epoch": 0.29460719041278294,
      "grad_norm": 5.28125,
      "learning_rate": 1.4107856191744343e-05,
      "loss": 1.1992,
      "step": 1770
    },
    {
      "epoch": 0.296271637816245,
      "grad_norm": 51.25,
      "learning_rate": 1.4074567243675101e-05,
      "loss": 0.9014,
      "step": 1780
    },
    {
      "epoch": 0.29793608521970705,
      "grad_norm": 9.875,
      "learning_rate": 1.4041278295605861e-05,
      "loss": 0.9402,
      "step": 1790
    },
    {
      "epoch": 0.2996005326231691,
      "grad_norm": 5.96875,
      "learning_rate": 1.4007989347536619e-05,
      "loss": 0.8076,
      "step": 1800
    },
    {
      "epoch": 0.30126498002663116,
      "grad_norm": 44.0,
      "learning_rate": 1.3974700399467377e-05,
      "loss": 0.9398,
      "step": 1810
    },
    {
      "epoch": 0.3029294274300932,
      "grad_norm": 16.125,
      "learning_rate": 1.3941411451398137e-05,
      "loss": 0.959,
      "step": 1820
    },
    {
      "epoch": 0.30459387483355527,
      "grad_norm": 8.25,
      "learning_rate": 1.3908122503328895e-05,
      "loss": 1.0063,
      "step": 1830
    },
    {
      "epoch": 0.3062583222370173,
      "grad_norm": 15.0,
      "learning_rate": 1.3874833555259655e-05,
      "loss": 0.8613,
      "step": 1840
    },
    {
      "epoch": 0.3079227696404794,
      "grad_norm": 15.25,
      "learning_rate": 1.3841544607190413e-05,
      "loss": 0.9707,
      "step": 1850
    },
    {
      "epoch": 0.30958721704394143,
      "grad_norm": 21.375,
      "learning_rate": 1.3808255659121173e-05,
      "loss": 0.9945,
      "step": 1860
    },
    {
      "epoch": 0.3112516644474035,
      "grad_norm": 6.03125,
      "learning_rate": 1.3774966711051931e-05,
      "loss": 0.952,
      "step": 1870
    },
    {
      "epoch": 0.3129161118508655,
      "grad_norm": 50.5,
      "learning_rate": 1.3741677762982691e-05,
      "loss": 1.1105,
      "step": 1880
    },
    {
      "epoch": 0.31458055925432754,
      "grad_norm": 13.4375,
      "learning_rate": 1.3708388814913449e-05,
      "loss": 0.8543,
      "step": 1890
    },
    {
      "epoch": 0.3162450066577896,
      "grad_norm": 24.75,
      "learning_rate": 1.3675099866844209e-05,
      "loss": 0.9219,
      "step": 1900
    },
    {
      "epoch": 0.31790945406125165,
      "grad_norm": 7.53125,
      "learning_rate": 1.3641810918774967e-05,
      "loss": 1.0535,
      "step": 1910
    },
    {
      "epoch": 0.3195739014647137,
      "grad_norm": 5.9375,
      "learning_rate": 1.3608521970705725e-05,
      "loss": 0.8891,
      "step": 1920
    },
    {
      "epoch": 0.32123834886817576,
      "grad_norm": 37.0,
      "learning_rate": 1.3575233022636485e-05,
      "loss": 0.9184,
      "step": 1930
    },
    {
      "epoch": 0.3229027962716378,
      "grad_norm": 35.5,
      "learning_rate": 1.3541944074567243e-05,
      "loss": 0.9041,
      "step": 1940
    },
    {
      "epoch": 0.32456724367509987,
      "grad_norm": 7.25,
      "learning_rate": 1.3508655126498005e-05,
      "loss": 0.9281,
      "step": 1950
    },
    {
      "epoch": 0.3262316910785619,
      "grad_norm": 13.4375,
      "learning_rate": 1.3475366178428764e-05,
      "loss": 0.884,
      "step": 1960
    },
    {
      "epoch": 0.327896138482024,
      "grad_norm": 5.90625,
      "learning_rate": 1.3442077230359523e-05,
      "loss": 0.9852,
      "step": 1970
    },
    {
      "epoch": 0.32956058588548603,
      "grad_norm": 22.5,
      "learning_rate": 1.3408788282290282e-05,
      "loss": 1.1225,
      "step": 1980
    },
    {
      "epoch": 0.3312250332889481,
      "grad_norm": 17.125,
      "learning_rate": 1.337549933422104e-05,
      "loss": 0.9168,
      "step": 1990
    },
    {
      "epoch": 0.33288948069241014,
      "grad_norm": 41.25,
      "learning_rate": 1.3342210386151799e-05,
      "loss": 1.1748,
      "step": 2000
    },
    {
      "epoch": 0.33288948069241014,
      "eval_accuracy": 0.5040235606437697,
      "eval_loss": 0.9969163537025452,
      "eval_runtime": 697.1431,
      "eval_samples_per_second": 34.581,
      "eval_steps_per_second": 17.291,
      "step": 2000
    },
    {
      "epoch": 0.33455392809587214,
      "grad_norm": 2.3125,
      "learning_rate": 1.3308921438082558e-05,
      "loss": 0.9891,
      "step": 2010
    },
    {
      "epoch": 0.3362183754993342,
      "grad_norm": 11.375,
      "learning_rate": 1.3275632490013317e-05,
      "loss": 0.7824,
      "step": 2020
    },
    {
      "epoch": 0.33788282290279625,
      "grad_norm": 23.5,
      "learning_rate": 1.3242343541944076e-05,
      "loss": 1.2852,
      "step": 2030
    },
    {
      "epoch": 0.3395472703062583,
      "grad_norm": 23.125,
      "learning_rate": 1.3209054593874834e-05,
      "loss": 1.0637,
      "step": 2040
    },
    {
      "epoch": 0.34121171770972036,
      "grad_norm": 20.5,
      "learning_rate": 1.3175765645805594e-05,
      "loss": 1.0863,
      "step": 2050
    },
    {
      "epoch": 0.3428761651131824,
      "grad_norm": 10.5625,
      "learning_rate": 1.3142476697736352e-05,
      "loss": 0.9801,
      "step": 2060
    },
    {
      "epoch": 0.3445406125166445,
      "grad_norm": 33.75,
      "learning_rate": 1.3109187749667112e-05,
      "loss": 0.9543,
      "step": 2070
    },
    {
      "epoch": 0.34620505992010653,
      "grad_norm": 34.0,
      "learning_rate": 1.307589880159787e-05,
      "loss": 0.8656,
      "step": 2080
    },
    {
      "epoch": 0.3478695073235686,
      "grad_norm": 34.5,
      "learning_rate": 1.304260985352863e-05,
      "loss": 1.1738,
      "step": 2090
    },
    {
      "epoch": 0.34953395472703064,
      "grad_norm": 31.5,
      "learning_rate": 1.3009320905459388e-05,
      "loss": 1.0939,
      "step": 2100
    },
    {
      "epoch": 0.3511984021304927,
      "grad_norm": 14.5625,
      "learning_rate": 1.2976031957390146e-05,
      "loss": 0.901,
      "step": 2110
    },
    {
      "epoch": 0.35286284953395475,
      "grad_norm": 14.0,
      "learning_rate": 1.2942743009320906e-05,
      "loss": 0.7342,
      "step": 2120
    },
    {
      "epoch": 0.3545272969374168,
      "grad_norm": 9.875,
      "learning_rate": 1.2909454061251664e-05,
      "loss": 0.9273,
      "step": 2130
    },
    {
      "epoch": 0.3561917443408788,
      "grad_norm": 12.375,
      "learning_rate": 1.2876165113182424e-05,
      "loss": 0.7799,
      "step": 2140
    },
    {
      "epoch": 0.35785619174434086,
      "grad_norm": 6.90625,
      "learning_rate": 1.2842876165113182e-05,
      "loss": 0.9666,
      "step": 2150
    },
    {
      "epoch": 0.3595206391478029,
      "grad_norm": 4.625,
      "learning_rate": 1.2809587217043942e-05,
      "loss": 0.8662,
      "step": 2160
    },
    {
      "epoch": 0.36118508655126497,
      "grad_norm": 14.4375,
      "learning_rate": 1.27762982689747e-05,
      "loss": 1.0312,
      "step": 2170
    },
    {
      "epoch": 0.362849533954727,
      "grad_norm": 19.5,
      "learning_rate": 1.274300932090546e-05,
      "loss": 0.9666,
      "step": 2180
    },
    {
      "epoch": 0.3645139813581891,
      "grad_norm": 8.25,
      "learning_rate": 1.2709720372836218e-05,
      "loss": 1.066,
      "step": 2190
    },
    {
      "epoch": 0.36617842876165113,
      "grad_norm": 13.875,
      "learning_rate": 1.2676431424766978e-05,
      "loss": 0.968,
      "step": 2200
    },
    {
      "epoch": 0.3678428761651132,
      "grad_norm": 17.875,
      "learning_rate": 1.2643142476697738e-05,
      "loss": 0.9887,
      "step": 2210
    },
    {
      "epoch": 0.36950732356857524,
      "grad_norm": 17.5,
      "learning_rate": 1.2609853528628498e-05,
      "loss": 0.9504,
      "step": 2220
    },
    {
      "epoch": 0.3711717709720373,
      "grad_norm": 7.21875,
      "learning_rate": 1.2576564580559256e-05,
      "loss": 0.959,
      "step": 2230
    },
    {
      "epoch": 0.37283621837549935,
      "grad_norm": 23.125,
      "learning_rate": 1.2543275632490016e-05,
      "loss": 1.2598,
      "step": 2240
    },
    {
      "epoch": 0.3745006657789614,
      "grad_norm": 13.3125,
      "learning_rate": 1.2509986684420774e-05,
      "loss": 0.875,
      "step": 2250
    },
    {
      "epoch": 0.37616511318242346,
      "grad_norm": 19.125,
      "learning_rate": 1.2476697736351534e-05,
      "loss": 0.9338,
      "step": 2260
    },
    {
      "epoch": 0.37782956058588546,
      "grad_norm": 48.0,
      "learning_rate": 1.2443408788282292e-05,
      "loss": 0.9168,
      "step": 2270
    },
    {
      "epoch": 0.3794940079893475,
      "grad_norm": 57.0,
      "learning_rate": 1.241011984021305e-05,
      "loss": 0.9695,
      "step": 2280
    },
    {
      "epoch": 0.38115845539280957,
      "grad_norm": 15.25,
      "learning_rate": 1.237683089214381e-05,
      "loss": 1.0037,
      "step": 2290
    },
    {
      "epoch": 0.3828229027962716,
      "grad_norm": 39.75,
      "learning_rate": 1.2343541944074568e-05,
      "loss": 0.9621,
      "step": 2300
    },
    {
      "epoch": 0.3844873501997337,
      "grad_norm": 41.5,
      "learning_rate": 1.2310252996005328e-05,
      "loss": 1.1707,
      "step": 2310
    },
    {
      "epoch": 0.38615179760319573,
      "grad_norm": 26.25,
      "learning_rate": 1.2276964047936086e-05,
      "loss": 1.0104,
      "step": 2320
    },
    {
      "epoch": 0.3878162450066578,
      "grad_norm": 11.6875,
      "learning_rate": 1.2243675099866846e-05,
      "loss": 0.9004,
      "step": 2330
    },
    {
      "epoch": 0.38948069241011984,
      "grad_norm": 29.875,
      "learning_rate": 1.2210386151797604e-05,
      "loss": 0.9703,
      "step": 2340
    },
    {
      "epoch": 0.3911451398135819,
      "grad_norm": 12.0,
      "learning_rate": 1.2177097203728364e-05,
      "loss": 1.0172,
      "step": 2350
    },
    {
      "epoch": 0.39280958721704395,
      "grad_norm": 7.59375,
      "learning_rate": 1.2143808255659122e-05,
      "loss": 1.1562,
      "step": 2360
    },
    {
      "epoch": 0.394474034620506,
      "grad_norm": 35.25,
      "learning_rate": 1.2110519307589882e-05,
      "loss": 1.066,
      "step": 2370
    },
    {
      "epoch": 0.39613848202396806,
      "grad_norm": 5.21875,
      "learning_rate": 1.207723035952064e-05,
      "loss": 0.823,
      "step": 2380
    },
    {
      "epoch": 0.3978029294274301,
      "grad_norm": 18.25,
      "learning_rate": 1.2043941411451398e-05,
      "loss": 0.7926,
      "step": 2390
    },
    {
      "epoch": 0.3994673768308921,
      "grad_norm": 54.75,
      "learning_rate": 1.2010652463382158e-05,
      "loss": 1.0908,
      "step": 2400
    },
    {
      "epoch": 0.4011318242343542,
      "grad_norm": 27.875,
      "learning_rate": 1.1977363515312916e-05,
      "loss": 1.1193,
      "step": 2410
    },
    {
      "epoch": 0.40279627163781623,
      "grad_norm": 11.875,
      "learning_rate": 1.1944074567243676e-05,
      "loss": 1.1012,
      "step": 2420
    },
    {
      "epoch": 0.4044607190412783,
      "grad_norm": 10.1875,
      "learning_rate": 1.1910785619174434e-05,
      "loss": 0.9855,
      "step": 2430
    },
    {
      "epoch": 0.40612516644474034,
      "grad_norm": 11.5625,
      "learning_rate": 1.1877496671105194e-05,
      "loss": 0.9449,
      "step": 2440
    },
    {
      "epoch": 0.4077896138482024,
      "grad_norm": 13.1875,
      "learning_rate": 1.1844207723035952e-05,
      "loss": 0.9373,
      "step": 2450
    },
    {
      "epoch": 0.40945406125166445,
      "grad_norm": 35.0,
      "learning_rate": 1.1810918774966711e-05,
      "loss": 0.9428,
      "step": 2460
    },
    {
      "epoch": 0.4111185086551265,
      "grad_norm": 36.25,
      "learning_rate": 1.1777629826897471e-05,
      "loss": 0.9428,
      "step": 2470
    },
    {
      "epoch": 0.41278295605858856,
      "grad_norm": 20.5,
      "learning_rate": 1.1744340878828231e-05,
      "loss": 0.9648,
      "step": 2480
    },
    {
      "epoch": 0.4144474034620506,
      "grad_norm": 6.09375,
      "learning_rate": 1.171105193075899e-05,
      "loss": 0.8176,
      "step": 2490
    },
    {
      "epoch": 0.41611185086551267,
      "grad_norm": 14.25,
      "learning_rate": 1.1677762982689749e-05,
      "loss": 0.9875,
      "step": 2500
    },
    {
      "epoch": 0.41611185086551267,
      "eval_accuracy": 0.5042724406835906,
      "eval_loss": 0.9875219464302063,
      "eval_runtime": 697.1252,
      "eval_samples_per_second": 34.582,
      "eval_steps_per_second": 17.291,
      "step": 2500
    },
    {
      "epoch": 0.4177762982689747,
      "grad_norm": 12.75,
      "learning_rate": 1.1644474034620507e-05,
      "loss": 0.8918,
      "step": 2510
    },
    {
      "epoch": 0.4194407456724368,
      "grad_norm": 23.5,
      "learning_rate": 1.1611185086551267e-05,
      "loss": 0.8955,
      "step": 2520
    },
    {
      "epoch": 0.4211051930758988,
      "grad_norm": 3.5625,
      "learning_rate": 1.1577896138482025e-05,
      "loss": 0.892,
      "step": 2530
    },
    {
      "epoch": 0.42276964047936083,
      "grad_norm": 16.125,
      "learning_rate": 1.1544607190412785e-05,
      "loss": 0.8959,
      "step": 2540
    },
    {
      "epoch": 0.4244340878828229,
      "grad_norm": 27.25,
      "learning_rate": 1.1511318242343543e-05,
      "loss": 0.9609,
      "step": 2550
    },
    {
      "epoch": 0.42609853528628494,
      "grad_norm": 14.0,
      "learning_rate": 1.1478029294274303e-05,
      "loss": 1.0055,
      "step": 2560
    },
    {
      "epoch": 0.427762982689747,
      "grad_norm": 5.34375,
      "learning_rate": 1.1444740346205061e-05,
      "loss": 0.9383,
      "step": 2570
    },
    {
      "epoch": 0.42942743009320905,
      "grad_norm": 38.5,
      "learning_rate": 1.141145139813582e-05,
      "loss": 0.957,
      "step": 2580
    },
    {
      "epoch": 0.4310918774966711,
      "grad_norm": 13.5,
      "learning_rate": 1.1378162450066579e-05,
      "loss": 1.1078,
      "step": 2590
    },
    {
      "epoch": 0.43275632490013316,
      "grad_norm": 18.75,
      "learning_rate": 1.1344873501997337e-05,
      "loss": 1.1398,
      "step": 2600
    },
    {
      "epoch": 0.4344207723035952,
      "grad_norm": 39.5,
      "learning_rate": 1.1311584553928097e-05,
      "loss": 0.8514,
      "step": 2610
    },
    {
      "epoch": 0.43608521970705727,
      "grad_norm": 20.0,
      "learning_rate": 1.1278295605858855e-05,
      "loss": 0.8447,
      "step": 2620
    },
    {
      "epoch": 0.4377496671105193,
      "grad_norm": 53.75,
      "learning_rate": 1.1245006657789615e-05,
      "loss": 1.1996,
      "step": 2630
    },
    {
      "epoch": 0.4394141145139814,
      "grad_norm": 35.25,
      "learning_rate": 1.1211717709720373e-05,
      "loss": 1.1145,
      "step": 2640
    },
    {
      "epoch": 0.44107856191744343,
      "grad_norm": 12.5625,
      "learning_rate": 1.1178428761651133e-05,
      "loss": 0.9936,
      "step": 2650
    },
    {
      "epoch": 0.44274300932090543,
      "grad_norm": 10.875,
      "learning_rate": 1.1145139813581891e-05,
      "loss": 0.9973,
      "step": 2660
    },
    {
      "epoch": 0.4444074567243675,
      "grad_norm": 34.75,
      "learning_rate": 1.111185086551265e-05,
      "loss": 1.0992,
      "step": 2670
    },
    {
      "epoch": 0.44607190412782954,
      "grad_norm": 12.75,
      "learning_rate": 1.1078561917443409e-05,
      "loss": 1.15,
      "step": 2680
    },
    {
      "epoch": 0.4477363515312916,
      "grad_norm": 14.0625,
      "learning_rate": 1.1045272969374167e-05,
      "loss": 0.902,
      "step": 2690
    },
    {
      "epoch": 0.44940079893475365,
      "grad_norm": 22.5,
      "learning_rate": 1.1011984021304927e-05,
      "loss": 0.8941,
      "step": 2700
    },
    {
      "epoch": 0.4510652463382157,
      "grad_norm": 21.75,
      "learning_rate": 1.0978695073235685e-05,
      "loss": 0.9879,
      "step": 2710
    },
    {
      "epoch": 0.45272969374167776,
      "grad_norm": 24.375,
      "learning_rate": 1.0945406125166447e-05,
      "loss": 1.1738,
      "step": 2720
    },
    {
      "epoch": 0.4543941411451398,
      "grad_norm": 16.125,
      "learning_rate": 1.0912117177097206e-05,
      "loss": 1.0461,
      "step": 2730
    },
    {
      "epoch": 0.4560585885486019,
      "grad_norm": 43.5,
      "learning_rate": 1.0878828229027965e-05,
      "loss": 0.9916,
      "step": 2740
    },
    {
      "epoch": 0.45772303595206393,
      "grad_norm": 10.125,
      "learning_rate": 1.0845539280958723e-05,
      "loss": 1.134,
      "step": 2750
    },
    {
      "epoch": 0.459387483355526,
      "grad_norm": 25.5,
      "learning_rate": 1.0812250332889482e-05,
      "loss": 1.1477,
      "step": 2760
    },
    {
      "epoch": 0.46105193075898804,
      "grad_norm": 25.375,
      "learning_rate": 1.077896138482024e-05,
      "loss": 1.0016,
      "step": 2770
    },
    {
      "epoch": 0.4627163781624501,
      "grad_norm": 8.6875,
      "learning_rate": 1.0745672436751e-05,
      "loss": 1.0977,
      "step": 2780
    },
    {
      "epoch": 0.4643808255659121,
      "grad_norm": 9.125,
      "learning_rate": 1.0712383488681759e-05,
      "loss": 0.9313,
      "step": 2790
    },
    {
      "epoch": 0.46604527296937415,
      "grad_norm": 26.875,
      "learning_rate": 1.0679094540612518e-05,
      "loss": 0.9242,
      "step": 2800
    },
    {
      "epoch": 0.4677097203728362,
      "grad_norm": 25.375,
      "learning_rate": 1.0645805592543277e-05,
      "loss": 1.0242,
      "step": 2810
    },
    {
      "epoch": 0.46937416777629826,
      "grad_norm": 56.0,
      "learning_rate": 1.0612516644474036e-05,
      "loss": 1.1664,
      "step": 2820
    },
    {
      "epoch": 0.4710386151797603,
      "grad_norm": 5.25,
      "learning_rate": 1.0579227696404794e-05,
      "loss": 0.9574,
      "step": 2830
    },
    {
      "epoch": 0.47270306258322237,
      "grad_norm": 37.25,
      "learning_rate": 1.0545938748335554e-05,
      "loss": 0.893,
      "step": 2840
    },
    {
      "epoch": 0.4743675099866844,
      "grad_norm": 8.125,
      "learning_rate": 1.0512649800266312e-05,
      "loss": 0.9797,
      "step": 2850
    },
    {
      "epoch": 0.4760319573901465,
      "grad_norm": 16.5,
      "learning_rate": 1.047936085219707e-05,
      "loss": 0.9355,
      "step": 2860
    },
    {
      "epoch": 0.47769640479360853,
      "grad_norm": 5.3125,
      "learning_rate": 1.044607190412783e-05,
      "loss": 1.0629,
      "step": 2870
    },
    {
      "epoch": 0.4793608521970706,
      "grad_norm": 33.5,
      "learning_rate": 1.0412782956058588e-05,
      "loss": 1.2402,
      "step": 2880
    },
    {
      "epoch": 0.48102529960053264,
      "grad_norm": 11.1875,
      "learning_rate": 1.0379494007989348e-05,
      "loss": 0.8658,
      "step": 2890
    },
    {
      "epoch": 0.4826897470039947,
      "grad_norm": 24.0,
      "learning_rate": 1.0346205059920106e-05,
      "loss": 0.8703,
      "step": 2900
    },
    {
      "epoch": 0.48435419440745675,
      "grad_norm": 12.125,
      "learning_rate": 1.0312916111850866e-05,
      "loss": 0.893,
      "step": 2910
    },
    {
      "epoch": 0.48601864181091875,
      "grad_norm": 6.15625,
      "learning_rate": 1.0279627163781624e-05,
      "loss": 1.0312,
      "step": 2920
    },
    {
      "epoch": 0.4876830892143808,
      "grad_norm": 7.03125,
      "learning_rate": 1.0246338215712384e-05,
      "loss": 1.0543,
      "step": 2930
    },
    {
      "epoch": 0.48934753661784286,
      "grad_norm": 38.75,
      "learning_rate": 1.0213049267643142e-05,
      "loss": 1.0314,
      "step": 2940
    },
    {
      "epoch": 0.4910119840213049,
      "grad_norm": 7.375,
      "learning_rate": 1.0179760319573902e-05,
      "loss": 1.0078,
      "step": 2950
    },
    {
      "epoch": 0.49267643142476697,
      "grad_norm": 11.625,
      "learning_rate": 1.014647137150466e-05,
      "loss": 0.9293,
      "step": 2960
    },
    {
      "epoch": 0.494340878828229,
      "grad_norm": 30.5,
      "learning_rate": 1.0113182423435418e-05,
      "loss": 1.1371,
      "step": 2970
    },
    {
      "epoch": 0.4960053262316911,
      "grad_norm": 14.4375,
      "learning_rate": 1.007989347536618e-05,
      "loss": 0.9699,
      "step": 2980
    },
    {
      "epoch": 0.49766977363515313,
      "grad_norm": 29.875,
      "learning_rate": 1.004660452729694e-05,
      "loss": 1.074,
      "step": 2990
    },
    {
      "epoch": 0.4993342210386152,
      "grad_norm": 18.5,
      "learning_rate": 1.0013315579227698e-05,
      "loss": 1.0883,
      "step": 3000
    },
    {
      "epoch": 0.4993342210386152,
      "eval_accuracy": 0.5047702007632321,
      "eval_loss": 0.9890363812446594,
      "eval_runtime": 697.2407,
      "eval_samples_per_second": 34.576,
      "eval_steps_per_second": 17.288,
      "step": 3000
    },
    {
      "epoch": 0.5009986684420772,
      "grad_norm": 9.5625,
      "learning_rate": 9.980026631158456e-06,
      "loss": 0.8793,
      "step": 3010
    },
    {
      "epoch": 0.5026631158455392,
      "grad_norm": 24.25,
      "learning_rate": 9.946737683089214e-06,
      "loss": 1.0369,
      "step": 3020
    },
    {
      "epoch": 0.5043275632490013,
      "grad_norm": 22.0,
      "learning_rate": 9.913448735019974e-06,
      "loss": 1.1176,
      "step": 3030
    },
    {
      "epoch": 0.5059920106524634,
      "grad_norm": 24.125,
      "learning_rate": 9.880159786950732e-06,
      "loss": 0.925,
      "step": 3040
    },
    {
      "epoch": 0.5076564580559254,
      "grad_norm": 17.75,
      "learning_rate": 9.846870838881492e-06,
      "loss": 0.9281,
      "step": 3050
    },
    {
      "epoch": 0.5093209054593875,
      "grad_norm": 19.75,
      "learning_rate": 9.813581890812252e-06,
      "loss": 1.2355,
      "step": 3060
    },
    {
      "epoch": 0.5109853528628495,
      "grad_norm": 24.625,
      "learning_rate": 9.78029294274301e-06,
      "loss": 0.9424,
      "step": 3070
    },
    {
      "epoch": 0.5126498002663116,
      "grad_norm": 19.375,
      "learning_rate": 9.74700399467377e-06,
      "loss": 0.983,
      "step": 3080
    },
    {
      "epoch": 0.5143142476697736,
      "grad_norm": 33.0,
      "learning_rate": 9.713715046604528e-06,
      "loss": 0.9512,
      "step": 3090
    },
    {
      "epoch": 0.5159786950732357,
      "grad_norm": 26.375,
      "learning_rate": 9.680426098535288e-06,
      "loss": 0.9906,
      "step": 3100
    },
    {
      "epoch": 0.5176431424766977,
      "grad_norm": 9.1875,
      "learning_rate": 9.647137150466046e-06,
      "loss": 1.1408,
      "step": 3110
    },
    {
      "epoch": 0.5193075898801598,
      "grad_norm": 13.5625,
      "learning_rate": 9.613848202396806e-06,
      "loss": 1.0984,
      "step": 3120
    },
    {
      "epoch": 0.5209720372836218,
      "grad_norm": 12.4375,
      "learning_rate": 9.580559254327564e-06,
      "loss": 0.8406,
      "step": 3130
    },
    {
      "epoch": 0.5226364846870839,
      "grad_norm": 8.625,
      "learning_rate": 9.547270306258324e-06,
      "loss": 1.1078,
      "step": 3140
    },
    {
      "epoch": 0.524300932090546,
      "grad_norm": 37.25,
      "learning_rate": 9.513981358189082e-06,
      "loss": 0.9203,
      "step": 3150
    },
    {
      "epoch": 0.525965379494008,
      "grad_norm": 53.0,
      "learning_rate": 9.48069241011984e-06,
      "loss": 1.0898,
      "step": 3160
    },
    {
      "epoch": 0.5276298268974701,
      "grad_norm": 11.375,
      "learning_rate": 9.4474034620506e-06,
      "loss": 1.0242,
      "step": 3170
    },
    {
      "epoch": 0.5292942743009321,
      "grad_norm": 23.875,
      "learning_rate": 9.41411451398136e-06,
      "loss": 1.1254,
      "step": 3180
    },
    {
      "epoch": 0.5309587217043942,
      "grad_norm": 30.875,
      "learning_rate": 9.380825565912118e-06,
      "loss": 0.8574,
      "step": 3190
    },
    {
      "epoch": 0.5326231691078562,
      "grad_norm": 5.4375,
      "learning_rate": 9.347536617842877e-06,
      "loss": 0.9289,
      "step": 3200
    },
    {
      "epoch": 0.5342876165113183,
      "grad_norm": 21.125,
      "learning_rate": 9.314247669773636e-06,
      "loss": 1.0715,
      "step": 3210
    },
    {
      "epoch": 0.5359520639147803,
      "grad_norm": 10.3125,
      "learning_rate": 9.280958721704395e-06,
      "loss": 0.8938,
      "step": 3220
    },
    {
      "epoch": 0.5376165113182424,
      "grad_norm": 8.0625,
      "learning_rate": 9.247669773635154e-06,
      "loss": 0.8883,
      "step": 3230
    },
    {
      "epoch": 0.5392809587217043,
      "grad_norm": 14.6875,
      "learning_rate": 9.214380825565913e-06,
      "loss": 1.066,
      "step": 3240
    },
    {
      "epoch": 0.5409454061251664,
      "grad_norm": 22.375,
      "learning_rate": 9.181091877496671e-06,
      "loss": 1.2336,
      "step": 3250
    },
    {
      "epoch": 0.5426098535286284,
      "grad_norm": 12.4375,
      "learning_rate": 9.147802929427431e-06,
      "loss": 0.8973,
      "step": 3260
    },
    {
      "epoch": 0.5442743009320905,
      "grad_norm": 44.0,
      "learning_rate": 9.11451398135819e-06,
      "loss": 0.9809,
      "step": 3270
    },
    {
      "epoch": 0.5459387483355526,
      "grad_norm": 14.75,
      "learning_rate": 9.08122503328895e-06,
      "loss": 0.85,
      "step": 3280
    },
    {
      "epoch": 0.5476031957390146,
      "grad_norm": 28.125,
      "learning_rate": 9.047936085219707e-06,
      "loss": 1.1055,
      "step": 3290
    },
    {
      "epoch": 0.5492676431424767,
      "grad_norm": 34.25,
      "learning_rate": 9.014647137150465e-06,
      "loss": 0.8617,
      "step": 3300
    },
    {
      "epoch": 0.5509320905459387,
      "grad_norm": 18.375,
      "learning_rate": 8.981358189081227e-06,
      "loss": 1.1469,
      "step": 3310
    },
    {
      "epoch": 0.5525965379494008,
      "grad_norm": 28.0,
      "learning_rate": 8.948069241011985e-06,
      "loss": 1.1527,
      "step": 3320
    },
    {
      "epoch": 0.5542609853528628,
      "grad_norm": 12.5625,
      "learning_rate": 8.914780292942743e-06,
      "loss": 0.9113,
      "step": 3330
    },
    {
      "epoch": 0.5559254327563249,
      "grad_norm": 18.375,
      "learning_rate": 8.881491344873503e-06,
      "loss": 0.9934,
      "step": 3340
    },
    {
      "epoch": 0.5575898801597869,
      "grad_norm": 33.0,
      "learning_rate": 8.848202396804261e-06,
      "loss": 0.9727,
      "step": 3350
    },
    {
      "epoch": 0.559254327563249,
      "grad_norm": 8.4375,
      "learning_rate": 8.814913448735021e-06,
      "loss": 1.0367,
      "step": 3360
    },
    {
      "epoch": 0.560918774966711,
      "grad_norm": 7.78125,
      "learning_rate": 8.78162450066578e-06,
      "loss": 0.8359,
      "step": 3370
    },
    {
      "epoch": 0.5625832223701731,
      "grad_norm": 9.5,
      "learning_rate": 8.748335552596539e-06,
      "loss": 1.1426,
      "step": 3380
    },
    {
      "epoch": 0.5642476697736352,
      "grad_norm": 47.25,
      "learning_rate": 8.715046604527297e-06,
      "loss": 0.8518,
      "step": 3390
    },
    {
      "epoch": 0.5659121171770972,
      "grad_norm": 15.9375,
      "learning_rate": 8.681757656458057e-06,
      "loss": 0.9812,
      "step": 3400
    },
    {
      "epoch": 0.5675765645805593,
      "grad_norm": 19.625,
      "learning_rate": 8.648468708388815e-06,
      "loss": 0.9111,
      "step": 3410
    },
    {
      "epoch": 0.5692410119840213,
      "grad_norm": 8.9375,
      "learning_rate": 8.615179760319575e-06,
      "loss": 0.943,
      "step": 3420
    },
    {
      "epoch": 0.5709054593874834,
      "grad_norm": 4.96875,
      "learning_rate": 8.581890812250333e-06,
      "loss": 0.9234,
      "step": 3430
    },
    {
      "epoch": 0.5725699067909454,
      "grad_norm": 38.25,
      "learning_rate": 8.548601864181093e-06,
      "loss": 0.89,
      "step": 3440
    },
    {
      "epoch": 0.5742343541944075,
      "grad_norm": 20.25,
      "learning_rate": 8.515312916111853e-06,
      "loss": 1.075,
      "step": 3450
    },
    {
      "epoch": 0.5758988015978695,
      "grad_norm": 34.5,
      "learning_rate": 8.48202396804261e-06,
      "loss": 1.0492,
      "step": 3460
    },
    {
      "epoch": 0.5775632490013316,
      "grad_norm": 7.0625,
      "learning_rate": 8.448735019973369e-06,
      "loss": 1.1105,
      "step": 3470
    },
    {
      "epoch": 0.5792276964047937,
      "grad_norm": 17.25,
      "learning_rate": 8.415446071904129e-06,
      "loss": 0.9797,
      "step": 3480
    },
    {
      "epoch": 0.5808921438082557,
      "grad_norm": 15.125,
      "learning_rate": 8.382157123834887e-06,
      "loss": 0.9418,
      "step": 3490
    },
    {
      "epoch": 0.5825565912117177,
      "grad_norm": 42.75,
      "learning_rate": 8.348868175765647e-06,
      "loss": 1.0469,
      "step": 3500
    },
    {
      "epoch": 0.5825565912117177,
      "eval_accuracy": 0.5041065206570433,
      "eval_loss": 0.9888820648193359,
      "eval_runtime": 697.4046,
      "eval_samples_per_second": 34.568,
      "eval_steps_per_second": 17.284,
      "step": 3500
    },
    {
      "epoch": 0.5842210386151797,
      "grad_norm": 22.375,
      "learning_rate": 8.315579227696405e-06,
      "loss": 1.1207,
      "step": 3510
    },
    {
      "epoch": 0.5858854860186418,
      "grad_norm": 9.0625,
      "learning_rate": 8.282290279627165e-06,
      "loss": 0.9707,
      "step": 3520
    },
    {
      "epoch": 0.5875499334221038,
      "grad_norm": 25.5,
      "learning_rate": 8.249001331557923e-06,
      "loss": 1.0732,
      "step": 3530
    },
    {
      "epoch": 0.5892143808255659,
      "grad_norm": 48.75,
      "learning_rate": 8.215712383488683e-06,
      "loss": 1.084,
      "step": 3540
    },
    {
      "epoch": 0.5908788282290279,
      "grad_norm": 10.1875,
      "learning_rate": 8.18242343541944e-06,
      "loss": 1.0012,
      "step": 3550
    },
    {
      "epoch": 0.59254327563249,
      "grad_norm": 8.125,
      "learning_rate": 8.1491344873502e-06,
      "loss": 1.027,
      "step": 3560
    },
    {
      "epoch": 0.594207723035952,
      "grad_norm": 33.0,
      "learning_rate": 8.11584553928096e-06,
      "loss": 1.1383,
      "step": 3570
    },
    {
      "epoch": 0.5958721704394141,
      "grad_norm": 6.1875,
      "learning_rate": 8.082556591211719e-06,
      "loss": 0.9121,
      "step": 3580
    },
    {
      "epoch": 0.5975366178428761,
      "grad_norm": 15.0,
      "learning_rate": 8.049267643142478e-06,
      "loss": 1.0898,
      "step": 3590
    },
    {
      "epoch": 0.5992010652463382,
      "grad_norm": 15.125,
      "learning_rate": 8.015978695073236e-06,
      "loss": 0.95,
      "step": 3600
    },
    {
      "epoch": 0.6008655126498003,
      "grad_norm": 14.8125,
      "learning_rate": 7.982689747003996e-06,
      "loss": 1.0324,
      "step": 3610
    },
    {
      "epoch": 0.6025299600532623,
      "grad_norm": 32.75,
      "learning_rate": 7.949400798934754e-06,
      "loss": 1.0848,
      "step": 3620
    },
    {
      "epoch": 0.6041944074567244,
      "grad_norm": 9.5625,
      "learning_rate": 7.916111850865513e-06,
      "loss": 0.966,
      "step": 3630
    },
    {
      "epoch": 0.6058588548601864,
      "grad_norm": 9.9375,
      "learning_rate": 7.882822902796272e-06,
      "loss": 1.1145,
      "step": 3640
    },
    {
      "epoch": 0.6075233022636485,
      "grad_norm": 8.375,
      "learning_rate": 7.84953395472703e-06,
      "loss": 1.0242,
      "step": 3650
    },
    {
      "epoch": 0.6091877496671105,
      "grad_norm": 8.25,
      "learning_rate": 7.81624500665779e-06,
      "loss": 0.9289,
      "step": 3660
    },
    {
      "epoch": 0.6108521970705726,
      "grad_norm": 5.6875,
      "learning_rate": 7.782956058588548e-06,
      "loss": 0.9043,
      "step": 3670
    },
    {
      "epoch": 0.6125166444740346,
      "grad_norm": 10.375,
      "learning_rate": 7.749667110519308e-06,
      "loss": 1.0156,
      "step": 3680
    },
    {
      "epoch": 0.6141810918774967,
      "grad_norm": 24.625,
      "learning_rate": 7.716378162450066e-06,
      "loss": 1.0547,
      "step": 3690
    },
    {
      "epoch": 0.6158455392809588,
      "grad_norm": 52.75,
      "learning_rate": 7.683089214380826e-06,
      "loss": 1.1445,
      "step": 3700
    },
    {
      "epoch": 0.6175099866844208,
      "grad_norm": 5.21875,
      "learning_rate": 7.649800266311586e-06,
      "loss": 0.9336,
      "step": 3710
    },
    {
      "epoch": 0.6191744340878829,
      "grad_norm": 29.75,
      "learning_rate": 7.616511318242344e-06,
      "loss": 0.8969,
      "step": 3720
    },
    {
      "epoch": 0.6208388814913449,
      "grad_norm": 16.5,
      "learning_rate": 7.583222370173103e-06,
      "loss": 0.775,
      "step": 3730
    },
    {
      "epoch": 0.622503328894807,
      "grad_norm": 12.0625,
      "learning_rate": 7.549933422103862e-06,
      "loss": 1.1008,
      "step": 3740
    },
    {
      "epoch": 0.624167776298269,
      "grad_norm": 5.4375,
      "learning_rate": 7.516644474034621e-06,
      "loss": 0.9297,
      "step": 3750
    },
    {
      "epoch": 0.625832223701731,
      "grad_norm": 32.5,
      "learning_rate": 7.48335552596538e-06,
      "loss": 1.2004,
      "step": 3760
    },
    {
      "epoch": 0.627496671105193,
      "grad_norm": 18.625,
      "learning_rate": 7.450066577896139e-06,
      "loss": 0.9311,
      "step": 3770
    },
    {
      "epoch": 0.6291611185086551,
      "grad_norm": 11.5625,
      "learning_rate": 7.416777629826898e-06,
      "loss": 1.0006,
      "step": 3780
    },
    {
      "epoch": 0.6308255659121171,
      "grad_norm": 22.375,
      "learning_rate": 7.383488681757657e-06,
      "loss": 0.984,
      "step": 3790
    },
    {
      "epoch": 0.6324900133155792,
      "grad_norm": 39.25,
      "learning_rate": 7.350199733688416e-06,
      "loss": 0.8734,
      "step": 3800
    },
    {
      "epoch": 0.6341544607190412,
      "grad_norm": 24.875,
      "learning_rate": 7.316910785619175e-06,
      "loss": 0.9082,
      "step": 3810
    },
    {
      "epoch": 0.6358189081225033,
      "grad_norm": 21.125,
      "learning_rate": 7.283621837549935e-06,
      "loss": 1.1617,
      "step": 3820
    },
    {
      "epoch": 0.6374833555259654,
      "grad_norm": 14.5,
      "learning_rate": 7.250332889480694e-06,
      "loss": 0.9125,
      "step": 3830
    },
    {
      "epoch": 0.6391478029294274,
      "grad_norm": 18.25,
      "learning_rate": 7.217043941411453e-06,
      "loss": 1.1711,
      "step": 3840
    },
    {
      "epoch": 0.6408122503328895,
      "grad_norm": 18.0,
      "learning_rate": 7.183754993342211e-06,
      "loss": 0.9348,
      "step": 3850
    },
    {
      "epoch": 0.6424766977363515,
      "grad_norm": 49.5,
      "learning_rate": 7.15046604527297e-06,
      "loss": 1.1301,
      "step": 3860
    },
    {
      "epoch": 0.6441411451398136,
      "grad_norm": 9.3125,
      "learning_rate": 7.117177097203729e-06,
      "loss": 0.8729,
      "step": 3870
    },
    {
      "epoch": 0.6458055925432756,
      "grad_norm": 12.375,
      "learning_rate": 7.083888149134488e-06,
      "loss": 0.8859,
      "step": 3880
    },
    {
      "epoch": 0.6474700399467377,
      "grad_norm": 37.25,
      "learning_rate": 7.050599201065247e-06,
      "loss": 1.0832,
      "step": 3890
    },
    {
      "epoch": 0.6491344873501997,
      "grad_norm": 19.5,
      "learning_rate": 7.017310252996006e-06,
      "loss": 1.0398,
      "step": 3900
    },
    {
      "epoch": 0.6507989347536618,
      "grad_norm": 8.4375,
      "learning_rate": 6.984021304926765e-06,
      "loss": 1.0,
      "step": 3910
    },
    {
      "epoch": 0.6524633821571239,
      "grad_norm": 11.4375,
      "learning_rate": 6.950732356857524e-06,
      "loss": 1.0377,
      "step": 3920
    },
    {
      "epoch": 0.6541278295605859,
      "grad_norm": 12.875,
      "learning_rate": 6.917443408788283e-06,
      "loss": 0.8529,
      "step": 3930
    },
    {
      "epoch": 0.655792276964048,
      "grad_norm": 22.625,
      "learning_rate": 6.884154460719042e-06,
      "loss": 0.9156,
      "step": 3940
    },
    {
      "epoch": 0.65745672436751,
      "grad_norm": 19.0,
      "learning_rate": 6.8508655126498015e-06,
      "loss": 1.1633,
      "step": 3950
    },
    {
      "epoch": 0.6591211717709721,
      "grad_norm": 11.6875,
      "learning_rate": 6.8175765645805605e-06,
      "loss": 0.8938,
      "step": 3960
    },
    {
      "epoch": 0.6607856191744341,
      "grad_norm": 28.875,
      "learning_rate": 6.7842876165113195e-06,
      "loss": 0.941,
      "step": 3970
    },
    {
      "epoch": 0.6624500665778962,
      "grad_norm": 18.5,
      "learning_rate": 6.7509986684420784e-06,
      "loss": 1.0004,
      "step": 3980
    },
    {
      "epoch": 0.6641145139813582,
      "grad_norm": 16.625,
      "learning_rate": 6.7177097203728366e-06,
      "loss": 1.1371,
      "step": 3990
    },
    {
      "epoch": 0.6657789613848203,
      "grad_norm": 18.625,
      "learning_rate": 6.6844207723035955e-06,
      "loss": 1.0613,
      "step": 4000
    },
    {
      "epoch": 0.6657789613848203,
      "eval_accuracy": 0.5035258005641281,
      "eval_loss": 0.988470196723938,
      "eval_runtime": 697.0811,
      "eval_samples_per_second": 34.584,
      "eval_steps_per_second": 17.292,
      "step": 4000
    }
  ],
  "logging_steps": 10,
  "max_steps": 6008,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "total_flos": 0.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
