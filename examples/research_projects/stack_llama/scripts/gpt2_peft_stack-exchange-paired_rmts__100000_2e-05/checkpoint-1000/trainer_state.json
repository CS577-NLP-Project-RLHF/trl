{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.0502815768302494,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.000502815768302494,
      "grad_norm": 17.25,
      "learning_rate": 1.9998994368463394e-05,
      "loss": 1.755,
      "step": 10
    },
    {
      "epoch": 0.001005631536604988,
      "grad_norm": 70.0,
      "learning_rate": 1.9997988736926793e-05,
      "loss": 2.3226,
      "step": 20
    },
    {
      "epoch": 0.0015084473049074819,
      "grad_norm": 196.0,
      "learning_rate": 1.9996983105390186e-05,
      "loss": 3.7719,
      "step": 30
    },
    {
      "epoch": 0.002011263073209976,
      "grad_norm": 40.0,
      "learning_rate": 1.9995977473853582e-05,
      "loss": 2.4239,
      "step": 40
    },
    {
      "epoch": 0.00251407884151247,
      "grad_norm": 31.125,
      "learning_rate": 1.9994971842316978e-05,
      "loss": 2.9258,
      "step": 50
    },
    {
      "epoch": 0.0030168946098149637,
      "grad_norm": 23.25,
      "learning_rate": 1.999396621078037e-05,
      "loss": 1.6977,
      "step": 60
    },
    {
      "epoch": 0.0035197103781174576,
      "grad_norm": 121.5,
      "learning_rate": 1.9992960579243766e-05,
      "loss": 1.8602,
      "step": 70
    },
    {
      "epoch": 0.004022526146419952,
      "grad_norm": 62.25,
      "learning_rate": 1.9991954947707162e-05,
      "loss": 1.9538,
      "step": 80
    },
    {
      "epoch": 0.004525341914722446,
      "grad_norm": 86.0,
      "learning_rate": 1.9990949316170554e-05,
      "loss": 1.708,
      "step": 90
    },
    {
      "epoch": 0.00502815768302494,
      "grad_norm": 20.5,
      "learning_rate": 1.9989943684633954e-05,
      "loss": 2.9422,
      "step": 100
    },
    {
      "epoch": 0.0055309734513274336,
      "grad_norm": 28.0,
      "learning_rate": 1.9988938053097346e-05,
      "loss": 2.1455,
      "step": 110
    },
    {
      "epoch": 0.006033789219629927,
      "grad_norm": 31.125,
      "learning_rate": 1.9987932421560742e-05,
      "loss": 2.0912,
      "step": 120
    },
    {
      "epoch": 0.006536604987932421,
      "grad_norm": 129.0,
      "learning_rate": 1.9986926790024138e-05,
      "loss": 2.2301,
      "step": 130
    },
    {
      "epoch": 0.007039420756234915,
      "grad_norm": 30.0,
      "learning_rate": 1.998592115848753e-05,
      "loss": 3.5905,
      "step": 140
    },
    {
      "epoch": 0.007542236524537409,
      "grad_norm": 48.5,
      "learning_rate": 1.9984915526950926e-05,
      "loss": 2.2544,
      "step": 150
    },
    {
      "epoch": 0.008045052292839904,
      "grad_norm": 26.375,
      "learning_rate": 1.9983909895414322e-05,
      "loss": 2.4787,
      "step": 160
    },
    {
      "epoch": 0.008547868061142397,
      "grad_norm": 44.5,
      "learning_rate": 1.9982904263877715e-05,
      "loss": 1.9704,
      "step": 170
    },
    {
      "epoch": 0.009050683829444892,
      "grad_norm": 92.5,
      "learning_rate": 1.9981898632341114e-05,
      "loss": 1.738,
      "step": 180
    },
    {
      "epoch": 0.009553499597747385,
      "grad_norm": 63.0,
      "learning_rate": 1.9980893000804506e-05,
      "loss": 2.3344,
      "step": 190
    },
    {
      "epoch": 0.01005631536604988,
      "grad_norm": 99.5,
      "learning_rate": 1.9979887369267902e-05,
      "loss": 1.3479,
      "step": 200
    },
    {
      "epoch": 0.010559131134352374,
      "grad_norm": 24.375,
      "learning_rate": 1.9978881737731298e-05,
      "loss": 1.9866,
      "step": 210
    },
    {
      "epoch": 0.011061946902654867,
      "grad_norm": 36.5,
      "learning_rate": 1.997787610619469e-05,
      "loss": 1.9526,
      "step": 220
    },
    {
      "epoch": 0.011564762670957362,
      "grad_norm": 68.0,
      "learning_rate": 1.9976870474658087e-05,
      "loss": 2.4033,
      "step": 230
    },
    {
      "epoch": 0.012067578439259855,
      "grad_norm": 96.0,
      "learning_rate": 1.9975864843121482e-05,
      "loss": 2.0509,
      "step": 240
    },
    {
      "epoch": 0.01257039420756235,
      "grad_norm": 1.796875,
      "learning_rate": 1.9974859211584875e-05,
      "loss": 2.1263,
      "step": 250
    },
    {
      "epoch": 0.013073209975864843,
      "grad_norm": 41.25,
      "learning_rate": 1.997385358004827e-05,
      "loss": 1.4645,
      "step": 260
    },
    {
      "epoch": 0.013576025744167337,
      "grad_norm": 4.25,
      "learning_rate": 1.9972847948511667e-05,
      "loss": 1.9332,
      "step": 270
    },
    {
      "epoch": 0.01407884151246983,
      "grad_norm": 53.0,
      "learning_rate": 1.9971842316975063e-05,
      "loss": 1.3064,
      "step": 280
    },
    {
      "epoch": 0.014581657280772325,
      "grad_norm": 25.0,
      "learning_rate": 1.997083668543846e-05,
      "loss": 1.4321,
      "step": 290
    },
    {
      "epoch": 0.015084473049074818,
      "grad_norm": 127.5,
      "learning_rate": 1.996983105390185e-05,
      "loss": 1.9563,
      "step": 300
    },
    {
      "epoch": 0.015587288817377313,
      "grad_norm": 12.625,
      "learning_rate": 1.9968825422365247e-05,
      "loss": 1.7906,
      "step": 310
    },
    {
      "epoch": 0.016090104585679808,
      "grad_norm": 150.0,
      "learning_rate": 1.9967819790828643e-05,
      "loss": 1.7745,
      "step": 320
    },
    {
      "epoch": 0.016592920353982302,
      "grad_norm": 86.5,
      "learning_rate": 1.9966814159292035e-05,
      "loss": 1.9699,
      "step": 330
    },
    {
      "epoch": 0.017095736122284794,
      "grad_norm": 17.5,
      "learning_rate": 1.996580852775543e-05,
      "loss": 1.6041,
      "step": 340
    },
    {
      "epoch": 0.01759855189058729,
      "grad_norm": 126.0,
      "learning_rate": 1.9964802896218827e-05,
      "loss": 1.3953,
      "step": 350
    },
    {
      "epoch": 0.018101367658889783,
      "grad_norm": 94.5,
      "learning_rate": 1.9963797264682223e-05,
      "loss": 1.5418,
      "step": 360
    },
    {
      "epoch": 0.018604183427192278,
      "grad_norm": 162.0,
      "learning_rate": 1.996279163314562e-05,
      "loss": 1.7346,
      "step": 370
    },
    {
      "epoch": 0.01910699919549477,
      "grad_norm": 11.625,
      "learning_rate": 1.996178600160901e-05,
      "loss": 1.8128,
      "step": 380
    },
    {
      "epoch": 0.019609814963797264,
      "grad_norm": 17.0,
      "learning_rate": 1.9960780370072407e-05,
      "loss": 1.4312,
      "step": 390
    },
    {
      "epoch": 0.02011263073209976,
      "grad_norm": 12.375,
      "learning_rate": 1.9959774738535803e-05,
      "loss": 1.3423,
      "step": 400
    },
    {
      "epoch": 0.020615446500402253,
      "grad_norm": 16.875,
      "learning_rate": 1.9958769106999195e-05,
      "loss": 1.0962,
      "step": 410
    },
    {
      "epoch": 0.021118262268704748,
      "grad_norm": 78.5,
      "learning_rate": 1.995776347546259e-05,
      "loss": 1.5727,
      "step": 420
    },
    {
      "epoch": 0.02162107803700724,
      "grad_norm": 21.375,
      "learning_rate": 1.9956757843925987e-05,
      "loss": 1.3668,
      "step": 430
    },
    {
      "epoch": 0.022123893805309734,
      "grad_norm": 25.875,
      "learning_rate": 1.9955752212389383e-05,
      "loss": 1.4074,
      "step": 440
    },
    {
      "epoch": 0.02262670957361223,
      "grad_norm": 16.875,
      "learning_rate": 1.995474658085278e-05,
      "loss": 1.1227,
      "step": 450
    },
    {
      "epoch": 0.023129525341914724,
      "grad_norm": 71.0,
      "learning_rate": 1.995374094931617e-05,
      "loss": 1.2776,
      "step": 460
    },
    {
      "epoch": 0.023632341110217215,
      "grad_norm": 24.875,
      "learning_rate": 1.9952735317779567e-05,
      "loss": 1.55,
      "step": 470
    },
    {
      "epoch": 0.02413515687851971,
      "grad_norm": 89.0,
      "learning_rate": 1.9951729686242963e-05,
      "loss": 1.364,
      "step": 480
    },
    {
      "epoch": 0.024637972646822204,
      "grad_norm": 17.625,
      "learning_rate": 1.9950724054706356e-05,
      "loss": 1.0853,
      "step": 490
    },
    {
      "epoch": 0.0251407884151247,
      "grad_norm": 39.25,
      "learning_rate": 1.994971842316975e-05,
      "loss": 1.1744,
      "step": 500
    },
    {
      "epoch": 0.0251407884151247,
      "eval_accuracy": 0.49266236985622214,
      "eval_loss": 2.2441346645355225,
      "eval_runtime": 463.561,
      "eval_samples_per_second": 87.022,
      "eval_steps_per_second": 87.022,
      "step": 500
    },
    {
      "epoch": 0.025643604183427194,
      "grad_norm": 32.75,
      "learning_rate": 1.9948712791633147e-05,
      "loss": 1.1669,
      "step": 510
    },
    {
      "epoch": 0.026146419951729685,
      "grad_norm": 27.375,
      "learning_rate": 1.9947707160096543e-05,
      "loss": 1.0588,
      "step": 520
    },
    {
      "epoch": 0.02664923572003218,
      "grad_norm": 6.875,
      "learning_rate": 1.9946701528559936e-05,
      "loss": 1.3489,
      "step": 530
    },
    {
      "epoch": 0.027152051488334675,
      "grad_norm": 18.5,
      "learning_rate": 1.994569589702333e-05,
      "loss": 1.0483,
      "step": 540
    },
    {
      "epoch": 0.02765486725663717,
      "grad_norm": 16.625,
      "learning_rate": 1.9944690265486728e-05,
      "loss": 1.063,
      "step": 550
    },
    {
      "epoch": 0.02815768302493966,
      "grad_norm": 138.0,
      "learning_rate": 1.9943684633950123e-05,
      "loss": 1.7311,
      "step": 560
    },
    {
      "epoch": 0.028660498793242156,
      "grad_norm": 26.5,
      "learning_rate": 1.9942679002413516e-05,
      "loss": 1.0805,
      "step": 570
    },
    {
      "epoch": 0.02916331456154465,
      "grad_norm": 50.0,
      "learning_rate": 1.9941673370876912e-05,
      "loss": 0.9571,
      "step": 580
    },
    {
      "epoch": 0.029666130329847145,
      "grad_norm": 41.25,
      "learning_rate": 1.9940667739340308e-05,
      "loss": 1.4236,
      "step": 590
    },
    {
      "epoch": 0.030168946098149636,
      "grad_norm": 65.0,
      "learning_rate": 1.9939662107803704e-05,
      "loss": 0.8414,
      "step": 600
    },
    {
      "epoch": 0.03067176186645213,
      "grad_norm": 7.1875,
      "learning_rate": 1.9938656476267096e-05,
      "loss": 0.7962,
      "step": 610
    },
    {
      "epoch": 0.031174577634754626,
      "grad_norm": 30.25,
      "learning_rate": 1.9937650844730492e-05,
      "loss": 1.4491,
      "step": 620
    },
    {
      "epoch": 0.03167739340305712,
      "grad_norm": 7.84375,
      "learning_rate": 1.9936645213193888e-05,
      "loss": 1.1464,
      "step": 630
    },
    {
      "epoch": 0.032180209171359615,
      "grad_norm": 9.875,
      "learning_rate": 1.9935639581657284e-05,
      "loss": 1.0437,
      "step": 640
    },
    {
      "epoch": 0.03268302493966211,
      "grad_norm": 21.0,
      "learning_rate": 1.9934633950120676e-05,
      "loss": 1.3236,
      "step": 650
    },
    {
      "epoch": 0.033185840707964605,
      "grad_norm": 15.8125,
      "learning_rate": 1.9933628318584072e-05,
      "loss": 1.1448,
      "step": 660
    },
    {
      "epoch": 0.03368865647626709,
      "grad_norm": 63.75,
      "learning_rate": 1.9932622687047468e-05,
      "loss": 1.1797,
      "step": 670
    },
    {
      "epoch": 0.03419147224456959,
      "grad_norm": 34.5,
      "learning_rate": 1.9931617055510864e-05,
      "loss": 1.8753,
      "step": 680
    },
    {
      "epoch": 0.03469428801287208,
      "grad_norm": 30.25,
      "learning_rate": 1.9930611423974256e-05,
      "loss": 1.5983,
      "step": 690
    },
    {
      "epoch": 0.03519710378117458,
      "grad_norm": 24.25,
      "learning_rate": 1.9929605792437652e-05,
      "loss": 1.2898,
      "step": 700
    },
    {
      "epoch": 0.03569991954947707,
      "grad_norm": 72.0,
      "learning_rate": 1.9928600160901048e-05,
      "loss": 1.5699,
      "step": 710
    },
    {
      "epoch": 0.036202735317779566,
      "grad_norm": 63.5,
      "learning_rate": 1.9927594529364444e-05,
      "loss": 1.2395,
      "step": 720
    },
    {
      "epoch": 0.03670555108608206,
      "grad_norm": 4.3125,
      "learning_rate": 1.9926588897827836e-05,
      "loss": 1.0974,
      "step": 730
    },
    {
      "epoch": 0.037208366854384556,
      "grad_norm": 6.46875,
      "learning_rate": 1.9925583266291232e-05,
      "loss": 1.0399,
      "step": 740
    },
    {
      "epoch": 0.03771118262268705,
      "grad_norm": 10.125,
      "learning_rate": 1.9924577634754628e-05,
      "loss": 1.2209,
      "step": 750
    },
    {
      "epoch": 0.03821399839098954,
      "grad_norm": 30.25,
      "learning_rate": 1.9923572003218024e-05,
      "loss": 1.2585,
      "step": 760
    },
    {
      "epoch": 0.03871681415929203,
      "grad_norm": 9.3125,
      "learning_rate": 1.9922566371681417e-05,
      "loss": 1.0356,
      "step": 770
    },
    {
      "epoch": 0.03921962992759453,
      "grad_norm": 87.0,
      "learning_rate": 1.9921560740144812e-05,
      "loss": 1.3323,
      "step": 780
    },
    {
      "epoch": 0.03972244569589702,
      "grad_norm": 5.21875,
      "learning_rate": 1.992055510860821e-05,
      "loss": 0.837,
      "step": 790
    },
    {
      "epoch": 0.04022526146419952,
      "grad_norm": 46.75,
      "learning_rate": 1.99195494770716e-05,
      "loss": 1.1189,
      "step": 800
    },
    {
      "epoch": 0.04072807723250201,
      "grad_norm": 19.625,
      "learning_rate": 1.9918543845534997e-05,
      "loss": 0.8339,
      "step": 810
    },
    {
      "epoch": 0.04123089300080451,
      "grad_norm": 22.875,
      "learning_rate": 1.9917538213998393e-05,
      "loss": 1.0547,
      "step": 820
    },
    {
      "epoch": 0.041733708769107,
      "grad_norm": 70.5,
      "learning_rate": 1.991653258246179e-05,
      "loss": 1.4902,
      "step": 830
    },
    {
      "epoch": 0.042236524537409496,
      "grad_norm": 27.375,
      "learning_rate": 1.9915526950925184e-05,
      "loss": 1.0908,
      "step": 840
    },
    {
      "epoch": 0.042739340305711984,
      "grad_norm": 41.75,
      "learning_rate": 1.9914521319388577e-05,
      "loss": 1.2615,
      "step": 850
    },
    {
      "epoch": 0.04324215607401448,
      "grad_norm": 10.0,
      "learning_rate": 1.9913515687851973e-05,
      "loss": 1.4291,
      "step": 860
    },
    {
      "epoch": 0.043744971842316974,
      "grad_norm": 33.5,
      "learning_rate": 1.991251005631537e-05,
      "loss": 1.3932,
      "step": 870
    },
    {
      "epoch": 0.04424778761061947,
      "grad_norm": 30.875,
      "learning_rate": 1.991150442477876e-05,
      "loss": 1.3297,
      "step": 880
    },
    {
      "epoch": 0.04475060337892196,
      "grad_norm": 27.75,
      "learning_rate": 1.9910498793242157e-05,
      "loss": 1.0875,
      "step": 890
    },
    {
      "epoch": 0.04525341914722446,
      "grad_norm": 43.75,
      "learning_rate": 1.9909493161705553e-05,
      "loss": 1.151,
      "step": 900
    },
    {
      "epoch": 0.04575623491552695,
      "grad_norm": 14.5,
      "learning_rate": 1.990848753016895e-05,
      "loss": 0.8733,
      "step": 910
    },
    {
      "epoch": 0.04625905068382945,
      "grad_norm": 43.5,
      "learning_rate": 1.9907481898632345e-05,
      "loss": 1.2638,
      "step": 920
    },
    {
      "epoch": 0.04676186645213194,
      "grad_norm": 52.75,
      "learning_rate": 1.9906476267095737e-05,
      "loss": 1.1483,
      "step": 930
    },
    {
      "epoch": 0.04726468222043443,
      "grad_norm": 52.75,
      "learning_rate": 1.9905470635559133e-05,
      "loss": 1.3098,
      "step": 940
    },
    {
      "epoch": 0.047767497988736925,
      "grad_norm": 40.5,
      "learning_rate": 1.990446500402253e-05,
      "loss": 1.3221,
      "step": 950
    },
    {
      "epoch": 0.04827031375703942,
      "grad_norm": 13.0,
      "learning_rate": 1.990345937248592e-05,
      "loss": 1.1198,
      "step": 960
    },
    {
      "epoch": 0.048773129525341914,
      "grad_norm": 58.0,
      "learning_rate": 1.9902453740949317e-05,
      "loss": 1.2282,
      "step": 970
    },
    {
      "epoch": 0.04927594529364441,
      "grad_norm": 61.5,
      "learning_rate": 1.9901448109412713e-05,
      "loss": 1.322,
      "step": 980
    },
    {
      "epoch": 0.049778761061946904,
      "grad_norm": 11.75,
      "learning_rate": 1.990044247787611e-05,
      "loss": 0.9185,
      "step": 990
    },
    {
      "epoch": 0.0502815768302494,
      "grad_norm": 13.25,
      "learning_rate": 1.9899436846339505e-05,
      "loss": 1.1724,
      "step": 1000
    },
    {
      "epoch": 0.0502815768302494,
      "eval_accuracy": 0.49848785324739714,
      "eval_loss": 1.5374782085418701,
      "eval_runtime": 463.8368,
      "eval_samples_per_second": 86.97,
      "eval_steps_per_second": 86.97,
      "step": 1000
    }
  ],
  "logging_steps": 10,
  "max_steps": 198880,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "total_flos": 0.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
