{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.0251407884151247,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.000502815768302494,
      "grad_norm": 17.25,
      "learning_rate": 1.9998994368463394e-05,
      "loss": 1.755,
      "step": 10
    },
    {
      "epoch": 0.001005631536604988,
      "grad_norm": 70.0,
      "learning_rate": 1.9997988736926793e-05,
      "loss": 2.3226,
      "step": 20
    },
    {
      "epoch": 0.0015084473049074819,
      "grad_norm": 196.0,
      "learning_rate": 1.9996983105390186e-05,
      "loss": 3.7719,
      "step": 30
    },
    {
      "epoch": 0.002011263073209976,
      "grad_norm": 40.0,
      "learning_rate": 1.9995977473853582e-05,
      "loss": 2.4239,
      "step": 40
    },
    {
      "epoch": 0.00251407884151247,
      "grad_norm": 31.125,
      "learning_rate": 1.9994971842316978e-05,
      "loss": 2.9258,
      "step": 50
    },
    {
      "epoch": 0.0030168946098149637,
      "grad_norm": 23.25,
      "learning_rate": 1.999396621078037e-05,
      "loss": 1.6977,
      "step": 60
    },
    {
      "epoch": 0.0035197103781174576,
      "grad_norm": 121.5,
      "learning_rate": 1.9992960579243766e-05,
      "loss": 1.8602,
      "step": 70
    },
    {
      "epoch": 0.004022526146419952,
      "grad_norm": 62.25,
      "learning_rate": 1.9991954947707162e-05,
      "loss": 1.9538,
      "step": 80
    },
    {
      "epoch": 0.004525341914722446,
      "grad_norm": 86.0,
      "learning_rate": 1.9990949316170554e-05,
      "loss": 1.708,
      "step": 90
    },
    {
      "epoch": 0.00502815768302494,
      "grad_norm": 20.5,
      "learning_rate": 1.9989943684633954e-05,
      "loss": 2.9422,
      "step": 100
    },
    {
      "epoch": 0.0055309734513274336,
      "grad_norm": 28.0,
      "learning_rate": 1.9988938053097346e-05,
      "loss": 2.1455,
      "step": 110
    },
    {
      "epoch": 0.006033789219629927,
      "grad_norm": 31.125,
      "learning_rate": 1.9987932421560742e-05,
      "loss": 2.0912,
      "step": 120
    },
    {
      "epoch": 0.006536604987932421,
      "grad_norm": 129.0,
      "learning_rate": 1.9986926790024138e-05,
      "loss": 2.2301,
      "step": 130
    },
    {
      "epoch": 0.007039420756234915,
      "grad_norm": 30.0,
      "learning_rate": 1.998592115848753e-05,
      "loss": 3.5905,
      "step": 140
    },
    {
      "epoch": 0.007542236524537409,
      "grad_norm": 48.5,
      "learning_rate": 1.9984915526950926e-05,
      "loss": 2.2544,
      "step": 150
    },
    {
      "epoch": 0.008045052292839904,
      "grad_norm": 26.375,
      "learning_rate": 1.9983909895414322e-05,
      "loss": 2.4787,
      "step": 160
    },
    {
      "epoch": 0.008547868061142397,
      "grad_norm": 44.5,
      "learning_rate": 1.9982904263877715e-05,
      "loss": 1.9704,
      "step": 170
    },
    {
      "epoch": 0.009050683829444892,
      "grad_norm": 92.5,
      "learning_rate": 1.9981898632341114e-05,
      "loss": 1.738,
      "step": 180
    },
    {
      "epoch": 0.009553499597747385,
      "grad_norm": 63.0,
      "learning_rate": 1.9980893000804506e-05,
      "loss": 2.3344,
      "step": 190
    },
    {
      "epoch": 0.01005631536604988,
      "grad_norm": 99.5,
      "learning_rate": 1.9979887369267902e-05,
      "loss": 1.3479,
      "step": 200
    },
    {
      "epoch": 0.010559131134352374,
      "grad_norm": 24.375,
      "learning_rate": 1.9978881737731298e-05,
      "loss": 1.9866,
      "step": 210
    },
    {
      "epoch": 0.011061946902654867,
      "grad_norm": 36.5,
      "learning_rate": 1.997787610619469e-05,
      "loss": 1.9526,
      "step": 220
    },
    {
      "epoch": 0.011564762670957362,
      "grad_norm": 68.0,
      "learning_rate": 1.9976870474658087e-05,
      "loss": 2.4033,
      "step": 230
    },
    {
      "epoch": 0.012067578439259855,
      "grad_norm": 96.0,
      "learning_rate": 1.9975864843121482e-05,
      "loss": 2.0509,
      "step": 240
    },
    {
      "epoch": 0.01257039420756235,
      "grad_norm": 1.796875,
      "learning_rate": 1.9974859211584875e-05,
      "loss": 2.1263,
      "step": 250
    },
    {
      "epoch": 0.013073209975864843,
      "grad_norm": 41.25,
      "learning_rate": 1.997385358004827e-05,
      "loss": 1.4645,
      "step": 260
    },
    {
      "epoch": 0.013576025744167337,
      "grad_norm": 4.25,
      "learning_rate": 1.9972847948511667e-05,
      "loss": 1.9332,
      "step": 270
    },
    {
      "epoch": 0.01407884151246983,
      "grad_norm": 53.0,
      "learning_rate": 1.9971842316975063e-05,
      "loss": 1.3064,
      "step": 280
    },
    {
      "epoch": 0.014581657280772325,
      "grad_norm": 25.0,
      "learning_rate": 1.997083668543846e-05,
      "loss": 1.4321,
      "step": 290
    },
    {
      "epoch": 0.015084473049074818,
      "grad_norm": 127.5,
      "learning_rate": 1.996983105390185e-05,
      "loss": 1.9563,
      "step": 300
    },
    {
      "epoch": 0.015587288817377313,
      "grad_norm": 12.625,
      "learning_rate": 1.9968825422365247e-05,
      "loss": 1.7906,
      "step": 310
    },
    {
      "epoch": 0.016090104585679808,
      "grad_norm": 150.0,
      "learning_rate": 1.9967819790828643e-05,
      "loss": 1.7745,
      "step": 320
    },
    {
      "epoch": 0.016592920353982302,
      "grad_norm": 86.5,
      "learning_rate": 1.9966814159292035e-05,
      "loss": 1.9699,
      "step": 330
    },
    {
      "epoch": 0.017095736122284794,
      "grad_norm": 17.5,
      "learning_rate": 1.996580852775543e-05,
      "loss": 1.6041,
      "step": 340
    },
    {
      "epoch": 0.01759855189058729,
      "grad_norm": 126.0,
      "learning_rate": 1.9964802896218827e-05,
      "loss": 1.3953,
      "step": 350
    },
    {
      "epoch": 0.018101367658889783,
      "grad_norm": 94.5,
      "learning_rate": 1.9963797264682223e-05,
      "loss": 1.5418,
      "step": 360
    },
    {
      "epoch": 0.018604183427192278,
      "grad_norm": 162.0,
      "learning_rate": 1.996279163314562e-05,
      "loss": 1.7346,
      "step": 370
    },
    {
      "epoch": 0.01910699919549477,
      "grad_norm": 11.625,
      "learning_rate": 1.996178600160901e-05,
      "loss": 1.8128,
      "step": 380
    },
    {
      "epoch": 0.019609814963797264,
      "grad_norm": 17.0,
      "learning_rate": 1.9960780370072407e-05,
      "loss": 1.4312,
      "step": 390
    },
    {
      "epoch": 0.02011263073209976,
      "grad_norm": 12.375,
      "learning_rate": 1.9959774738535803e-05,
      "loss": 1.3423,
      "step": 400
    },
    {
      "epoch": 0.020615446500402253,
      "grad_norm": 16.875,
      "learning_rate": 1.9958769106999195e-05,
      "loss": 1.0962,
      "step": 410
    },
    {
      "epoch": 0.021118262268704748,
      "grad_norm": 78.5,
      "learning_rate": 1.995776347546259e-05,
      "loss": 1.5727,
      "step": 420
    },
    {
      "epoch": 0.02162107803700724,
      "grad_norm": 21.375,
      "learning_rate": 1.9956757843925987e-05,
      "loss": 1.3668,
      "step": 430
    },
    {
      "epoch": 0.022123893805309734,
      "grad_norm": 25.875,
      "learning_rate": 1.9955752212389383e-05,
      "loss": 1.4074,
      "step": 440
    },
    {
      "epoch": 0.02262670957361223,
      "grad_norm": 16.875,
      "learning_rate": 1.995474658085278e-05,
      "loss": 1.1227,
      "step": 450
    },
    {
      "epoch": 0.023129525341914724,
      "grad_norm": 71.0,
      "learning_rate": 1.995374094931617e-05,
      "loss": 1.2776,
      "step": 460
    },
    {
      "epoch": 0.023632341110217215,
      "grad_norm": 24.875,
      "learning_rate": 1.9952735317779567e-05,
      "loss": 1.55,
      "step": 470
    },
    {
      "epoch": 0.02413515687851971,
      "grad_norm": 89.0,
      "learning_rate": 1.9951729686242963e-05,
      "loss": 1.364,
      "step": 480
    },
    {
      "epoch": 0.024637972646822204,
      "grad_norm": 17.625,
      "learning_rate": 1.9950724054706356e-05,
      "loss": 1.0853,
      "step": 490
    },
    {
      "epoch": 0.0251407884151247,
      "grad_norm": 39.25,
      "learning_rate": 1.994971842316975e-05,
      "loss": 1.1744,
      "step": 500
    },
    {
      "epoch": 0.0251407884151247,
      "eval_accuracy": 0.49266236985622214,
      "eval_loss": 2.2441346645355225,
      "eval_runtime": 463.561,
      "eval_samples_per_second": 87.022,
      "eval_steps_per_second": 87.022,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 198880,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "total_flos": 0.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
