{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.5530973451327433,
  "eval_steps": 500,
  "global_step": 11000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.000502815768302494,
      "grad_norm": 17.25,
      "learning_rate": 1.9998994368463394e-05,
      "loss": 1.755,
      "step": 10
    },
    {
      "epoch": 0.001005631536604988,
      "grad_norm": 70.0,
      "learning_rate": 1.9997988736926793e-05,
      "loss": 2.3226,
      "step": 20
    },
    {
      "epoch": 0.0015084473049074819,
      "grad_norm": 196.0,
      "learning_rate": 1.9996983105390186e-05,
      "loss": 3.7719,
      "step": 30
    },
    {
      "epoch": 0.002011263073209976,
      "grad_norm": 40.0,
      "learning_rate": 1.9995977473853582e-05,
      "loss": 2.4239,
      "step": 40
    },
    {
      "epoch": 0.00251407884151247,
      "grad_norm": 31.125,
      "learning_rate": 1.9994971842316978e-05,
      "loss": 2.9258,
      "step": 50
    },
    {
      "epoch": 0.0030168946098149637,
      "grad_norm": 23.25,
      "learning_rate": 1.999396621078037e-05,
      "loss": 1.6977,
      "step": 60
    },
    {
      "epoch": 0.0035197103781174576,
      "grad_norm": 121.5,
      "learning_rate": 1.9992960579243766e-05,
      "loss": 1.8602,
      "step": 70
    },
    {
      "epoch": 0.004022526146419952,
      "grad_norm": 62.25,
      "learning_rate": 1.9991954947707162e-05,
      "loss": 1.9538,
      "step": 80
    },
    {
      "epoch": 0.004525341914722446,
      "grad_norm": 86.0,
      "learning_rate": 1.9990949316170554e-05,
      "loss": 1.708,
      "step": 90
    },
    {
      "epoch": 0.00502815768302494,
      "grad_norm": 20.5,
      "learning_rate": 1.9989943684633954e-05,
      "loss": 2.9422,
      "step": 100
    },
    {
      "epoch": 0.0055309734513274336,
      "grad_norm": 28.0,
      "learning_rate": 1.9988938053097346e-05,
      "loss": 2.1455,
      "step": 110
    },
    {
      "epoch": 0.006033789219629927,
      "grad_norm": 31.125,
      "learning_rate": 1.9987932421560742e-05,
      "loss": 2.0912,
      "step": 120
    },
    {
      "epoch": 0.006536604987932421,
      "grad_norm": 129.0,
      "learning_rate": 1.9986926790024138e-05,
      "loss": 2.2301,
      "step": 130
    },
    {
      "epoch": 0.007039420756234915,
      "grad_norm": 30.0,
      "learning_rate": 1.998592115848753e-05,
      "loss": 3.5905,
      "step": 140
    },
    {
      "epoch": 0.007542236524537409,
      "grad_norm": 48.5,
      "learning_rate": 1.9984915526950926e-05,
      "loss": 2.2544,
      "step": 150
    },
    {
      "epoch": 0.008045052292839904,
      "grad_norm": 26.375,
      "learning_rate": 1.9983909895414322e-05,
      "loss": 2.4787,
      "step": 160
    },
    {
      "epoch": 0.008547868061142397,
      "grad_norm": 44.5,
      "learning_rate": 1.9982904263877715e-05,
      "loss": 1.9704,
      "step": 170
    },
    {
      "epoch": 0.009050683829444892,
      "grad_norm": 92.5,
      "learning_rate": 1.9981898632341114e-05,
      "loss": 1.738,
      "step": 180
    },
    {
      "epoch": 0.009553499597747385,
      "grad_norm": 63.0,
      "learning_rate": 1.9980893000804506e-05,
      "loss": 2.3344,
      "step": 190
    },
    {
      "epoch": 0.01005631536604988,
      "grad_norm": 99.5,
      "learning_rate": 1.9979887369267902e-05,
      "loss": 1.3479,
      "step": 200
    },
    {
      "epoch": 0.010559131134352374,
      "grad_norm": 24.375,
      "learning_rate": 1.9978881737731298e-05,
      "loss": 1.9866,
      "step": 210
    },
    {
      "epoch": 0.011061946902654867,
      "grad_norm": 36.5,
      "learning_rate": 1.997787610619469e-05,
      "loss": 1.9526,
      "step": 220
    },
    {
      "epoch": 0.011564762670957362,
      "grad_norm": 68.0,
      "learning_rate": 1.9976870474658087e-05,
      "loss": 2.4033,
      "step": 230
    },
    {
      "epoch": 0.012067578439259855,
      "grad_norm": 96.0,
      "learning_rate": 1.9975864843121482e-05,
      "loss": 2.0509,
      "step": 240
    },
    {
      "epoch": 0.01257039420756235,
      "grad_norm": 1.796875,
      "learning_rate": 1.9974859211584875e-05,
      "loss": 2.1263,
      "step": 250
    },
    {
      "epoch": 0.013073209975864843,
      "grad_norm": 41.25,
      "learning_rate": 1.997385358004827e-05,
      "loss": 1.4645,
      "step": 260
    },
    {
      "epoch": 0.013576025744167337,
      "grad_norm": 4.25,
      "learning_rate": 1.9972847948511667e-05,
      "loss": 1.9332,
      "step": 270
    },
    {
      "epoch": 0.01407884151246983,
      "grad_norm": 53.0,
      "learning_rate": 1.9971842316975063e-05,
      "loss": 1.3064,
      "step": 280
    },
    {
      "epoch": 0.014581657280772325,
      "grad_norm": 25.0,
      "learning_rate": 1.997083668543846e-05,
      "loss": 1.4321,
      "step": 290
    },
    {
      "epoch": 0.015084473049074818,
      "grad_norm": 127.5,
      "learning_rate": 1.996983105390185e-05,
      "loss": 1.9563,
      "step": 300
    },
    {
      "epoch": 0.015587288817377313,
      "grad_norm": 12.625,
      "learning_rate": 1.9968825422365247e-05,
      "loss": 1.7906,
      "step": 310
    },
    {
      "epoch": 0.016090104585679808,
      "grad_norm": 150.0,
      "learning_rate": 1.9967819790828643e-05,
      "loss": 1.7745,
      "step": 320
    },
    {
      "epoch": 0.016592920353982302,
      "grad_norm": 86.5,
      "learning_rate": 1.9966814159292035e-05,
      "loss": 1.9699,
      "step": 330
    },
    {
      "epoch": 0.017095736122284794,
      "grad_norm": 17.5,
      "learning_rate": 1.996580852775543e-05,
      "loss": 1.6041,
      "step": 340
    },
    {
      "epoch": 0.01759855189058729,
      "grad_norm": 126.0,
      "learning_rate": 1.9964802896218827e-05,
      "loss": 1.3953,
      "step": 350
    },
    {
      "epoch": 0.018101367658889783,
      "grad_norm": 94.5,
      "learning_rate": 1.9963797264682223e-05,
      "loss": 1.5418,
      "step": 360
    },
    {
      "epoch": 0.018604183427192278,
      "grad_norm": 162.0,
      "learning_rate": 1.996279163314562e-05,
      "loss": 1.7346,
      "step": 370
    },
    {
      "epoch": 0.01910699919549477,
      "grad_norm": 11.625,
      "learning_rate": 1.996178600160901e-05,
      "loss": 1.8128,
      "step": 380
    },
    {
      "epoch": 0.019609814963797264,
      "grad_norm": 17.0,
      "learning_rate": 1.9960780370072407e-05,
      "loss": 1.4312,
      "step": 390
    },
    {
      "epoch": 0.02011263073209976,
      "grad_norm": 12.375,
      "learning_rate": 1.9959774738535803e-05,
      "loss": 1.3423,
      "step": 400
    },
    {
      "epoch": 0.020615446500402253,
      "grad_norm": 16.875,
      "learning_rate": 1.9958769106999195e-05,
      "loss": 1.0962,
      "step": 410
    },
    {
      "epoch": 0.021118262268704748,
      "grad_norm": 78.5,
      "learning_rate": 1.995776347546259e-05,
      "loss": 1.5727,
      "step": 420
    },
    {
      "epoch": 0.02162107803700724,
      "grad_norm": 21.375,
      "learning_rate": 1.9956757843925987e-05,
      "loss": 1.3668,
      "step": 430
    },
    {
      "epoch": 0.022123893805309734,
      "grad_norm": 25.875,
      "learning_rate": 1.9955752212389383e-05,
      "loss": 1.4074,
      "step": 440
    },
    {
      "epoch": 0.02262670957361223,
      "grad_norm": 16.875,
      "learning_rate": 1.995474658085278e-05,
      "loss": 1.1227,
      "step": 450
    },
    {
      "epoch": 0.023129525341914724,
      "grad_norm": 71.0,
      "learning_rate": 1.995374094931617e-05,
      "loss": 1.2776,
      "step": 460
    },
    {
      "epoch": 0.023632341110217215,
      "grad_norm": 24.875,
      "learning_rate": 1.9952735317779567e-05,
      "loss": 1.55,
      "step": 470
    },
    {
      "epoch": 0.02413515687851971,
      "grad_norm": 89.0,
      "learning_rate": 1.9951729686242963e-05,
      "loss": 1.364,
      "step": 480
    },
    {
      "epoch": 0.024637972646822204,
      "grad_norm": 17.625,
      "learning_rate": 1.9950724054706356e-05,
      "loss": 1.0853,
      "step": 490
    },
    {
      "epoch": 0.0251407884151247,
      "grad_norm": 39.25,
      "learning_rate": 1.994971842316975e-05,
      "loss": 1.1744,
      "step": 500
    },
    {
      "epoch": 0.0251407884151247,
      "eval_accuracy": 0.49266236985622214,
      "eval_loss": 2.2441346645355225,
      "eval_runtime": 463.561,
      "eval_samples_per_second": 87.022,
      "eval_steps_per_second": 87.022,
      "step": 500
    },
    {
      "epoch": 0.025643604183427194,
      "grad_norm": 32.75,
      "learning_rate": 1.9948712791633147e-05,
      "loss": 1.1669,
      "step": 510
    },
    {
      "epoch": 0.026146419951729685,
      "grad_norm": 27.375,
      "learning_rate": 1.9947707160096543e-05,
      "loss": 1.0588,
      "step": 520
    },
    {
      "epoch": 0.02664923572003218,
      "grad_norm": 6.875,
      "learning_rate": 1.9946701528559936e-05,
      "loss": 1.3489,
      "step": 530
    },
    {
      "epoch": 0.027152051488334675,
      "grad_norm": 18.5,
      "learning_rate": 1.994569589702333e-05,
      "loss": 1.0483,
      "step": 540
    },
    {
      "epoch": 0.02765486725663717,
      "grad_norm": 16.625,
      "learning_rate": 1.9944690265486728e-05,
      "loss": 1.063,
      "step": 550
    },
    {
      "epoch": 0.02815768302493966,
      "grad_norm": 138.0,
      "learning_rate": 1.9943684633950123e-05,
      "loss": 1.7311,
      "step": 560
    },
    {
      "epoch": 0.028660498793242156,
      "grad_norm": 26.5,
      "learning_rate": 1.9942679002413516e-05,
      "loss": 1.0805,
      "step": 570
    },
    {
      "epoch": 0.02916331456154465,
      "grad_norm": 50.0,
      "learning_rate": 1.9941673370876912e-05,
      "loss": 0.9571,
      "step": 580
    },
    {
      "epoch": 0.029666130329847145,
      "grad_norm": 41.25,
      "learning_rate": 1.9940667739340308e-05,
      "loss": 1.4236,
      "step": 590
    },
    {
      "epoch": 0.030168946098149636,
      "grad_norm": 65.0,
      "learning_rate": 1.9939662107803704e-05,
      "loss": 0.8414,
      "step": 600
    },
    {
      "epoch": 0.03067176186645213,
      "grad_norm": 7.1875,
      "learning_rate": 1.9938656476267096e-05,
      "loss": 0.7962,
      "step": 610
    },
    {
      "epoch": 0.031174577634754626,
      "grad_norm": 30.25,
      "learning_rate": 1.9937650844730492e-05,
      "loss": 1.4491,
      "step": 620
    },
    {
      "epoch": 0.03167739340305712,
      "grad_norm": 7.84375,
      "learning_rate": 1.9936645213193888e-05,
      "loss": 1.1464,
      "step": 630
    },
    {
      "epoch": 0.032180209171359615,
      "grad_norm": 9.875,
      "learning_rate": 1.9935639581657284e-05,
      "loss": 1.0437,
      "step": 640
    },
    {
      "epoch": 0.03268302493966211,
      "grad_norm": 21.0,
      "learning_rate": 1.9934633950120676e-05,
      "loss": 1.3236,
      "step": 650
    },
    {
      "epoch": 0.033185840707964605,
      "grad_norm": 15.8125,
      "learning_rate": 1.9933628318584072e-05,
      "loss": 1.1448,
      "step": 660
    },
    {
      "epoch": 0.03368865647626709,
      "grad_norm": 63.75,
      "learning_rate": 1.9932622687047468e-05,
      "loss": 1.1797,
      "step": 670
    },
    {
      "epoch": 0.03419147224456959,
      "grad_norm": 34.5,
      "learning_rate": 1.9931617055510864e-05,
      "loss": 1.8753,
      "step": 680
    },
    {
      "epoch": 0.03469428801287208,
      "grad_norm": 30.25,
      "learning_rate": 1.9930611423974256e-05,
      "loss": 1.5983,
      "step": 690
    },
    {
      "epoch": 0.03519710378117458,
      "grad_norm": 24.25,
      "learning_rate": 1.9929605792437652e-05,
      "loss": 1.2898,
      "step": 700
    },
    {
      "epoch": 0.03569991954947707,
      "grad_norm": 72.0,
      "learning_rate": 1.9928600160901048e-05,
      "loss": 1.5699,
      "step": 710
    },
    {
      "epoch": 0.036202735317779566,
      "grad_norm": 63.5,
      "learning_rate": 1.9927594529364444e-05,
      "loss": 1.2395,
      "step": 720
    },
    {
      "epoch": 0.03670555108608206,
      "grad_norm": 4.3125,
      "learning_rate": 1.9926588897827836e-05,
      "loss": 1.0974,
      "step": 730
    },
    {
      "epoch": 0.037208366854384556,
      "grad_norm": 6.46875,
      "learning_rate": 1.9925583266291232e-05,
      "loss": 1.0399,
      "step": 740
    },
    {
      "epoch": 0.03771118262268705,
      "grad_norm": 10.125,
      "learning_rate": 1.9924577634754628e-05,
      "loss": 1.2209,
      "step": 750
    },
    {
      "epoch": 0.03821399839098954,
      "grad_norm": 30.25,
      "learning_rate": 1.9923572003218024e-05,
      "loss": 1.2585,
      "step": 760
    },
    {
      "epoch": 0.03871681415929203,
      "grad_norm": 9.3125,
      "learning_rate": 1.9922566371681417e-05,
      "loss": 1.0356,
      "step": 770
    },
    {
      "epoch": 0.03921962992759453,
      "grad_norm": 87.0,
      "learning_rate": 1.9921560740144812e-05,
      "loss": 1.3323,
      "step": 780
    },
    {
      "epoch": 0.03972244569589702,
      "grad_norm": 5.21875,
      "learning_rate": 1.992055510860821e-05,
      "loss": 0.837,
      "step": 790
    },
    {
      "epoch": 0.04022526146419952,
      "grad_norm": 46.75,
      "learning_rate": 1.99195494770716e-05,
      "loss": 1.1189,
      "step": 800
    },
    {
      "epoch": 0.04072807723250201,
      "grad_norm": 19.625,
      "learning_rate": 1.9918543845534997e-05,
      "loss": 0.8339,
      "step": 810
    },
    {
      "epoch": 0.04123089300080451,
      "grad_norm": 22.875,
      "learning_rate": 1.9917538213998393e-05,
      "loss": 1.0547,
      "step": 820
    },
    {
      "epoch": 0.041733708769107,
      "grad_norm": 70.5,
      "learning_rate": 1.991653258246179e-05,
      "loss": 1.4902,
      "step": 830
    },
    {
      "epoch": 0.042236524537409496,
      "grad_norm": 27.375,
      "learning_rate": 1.9915526950925184e-05,
      "loss": 1.0908,
      "step": 840
    },
    {
      "epoch": 0.042739340305711984,
      "grad_norm": 41.75,
      "learning_rate": 1.9914521319388577e-05,
      "loss": 1.2615,
      "step": 850
    },
    {
      "epoch": 0.04324215607401448,
      "grad_norm": 10.0,
      "learning_rate": 1.9913515687851973e-05,
      "loss": 1.4291,
      "step": 860
    },
    {
      "epoch": 0.043744971842316974,
      "grad_norm": 33.5,
      "learning_rate": 1.991251005631537e-05,
      "loss": 1.3932,
      "step": 870
    },
    {
      "epoch": 0.04424778761061947,
      "grad_norm": 30.875,
      "learning_rate": 1.991150442477876e-05,
      "loss": 1.3297,
      "step": 880
    },
    {
      "epoch": 0.04475060337892196,
      "grad_norm": 27.75,
      "learning_rate": 1.9910498793242157e-05,
      "loss": 1.0875,
      "step": 890
    },
    {
      "epoch": 0.04525341914722446,
      "grad_norm": 43.75,
      "learning_rate": 1.9909493161705553e-05,
      "loss": 1.151,
      "step": 900
    },
    {
      "epoch": 0.04575623491552695,
      "grad_norm": 14.5,
      "learning_rate": 1.990848753016895e-05,
      "loss": 0.8733,
      "step": 910
    },
    {
      "epoch": 0.04625905068382945,
      "grad_norm": 43.5,
      "learning_rate": 1.9907481898632345e-05,
      "loss": 1.2638,
      "step": 920
    },
    {
      "epoch": 0.04676186645213194,
      "grad_norm": 52.75,
      "learning_rate": 1.9906476267095737e-05,
      "loss": 1.1483,
      "step": 930
    },
    {
      "epoch": 0.04726468222043443,
      "grad_norm": 52.75,
      "learning_rate": 1.9905470635559133e-05,
      "loss": 1.3098,
      "step": 940
    },
    {
      "epoch": 0.047767497988736925,
      "grad_norm": 40.5,
      "learning_rate": 1.990446500402253e-05,
      "loss": 1.3221,
      "step": 950
    },
    {
      "epoch": 0.04827031375703942,
      "grad_norm": 13.0,
      "learning_rate": 1.990345937248592e-05,
      "loss": 1.1198,
      "step": 960
    },
    {
      "epoch": 0.048773129525341914,
      "grad_norm": 58.0,
      "learning_rate": 1.9902453740949317e-05,
      "loss": 1.2282,
      "step": 970
    },
    {
      "epoch": 0.04927594529364441,
      "grad_norm": 61.5,
      "learning_rate": 1.9901448109412713e-05,
      "loss": 1.322,
      "step": 980
    },
    {
      "epoch": 0.049778761061946904,
      "grad_norm": 11.75,
      "learning_rate": 1.990044247787611e-05,
      "loss": 0.9185,
      "step": 990
    },
    {
      "epoch": 0.0502815768302494,
      "grad_norm": 13.25,
      "learning_rate": 1.9899436846339505e-05,
      "loss": 1.1724,
      "step": 1000
    },
    {
      "epoch": 0.0502815768302494,
      "eval_accuracy": 0.49848785324739714,
      "eval_loss": 1.5374782085418701,
      "eval_runtime": 463.8368,
      "eval_samples_per_second": 86.97,
      "eval_steps_per_second": 86.97,
      "step": 1000
    },
    {
      "epoch": 0.05078439259855189,
      "grad_norm": 40.0,
      "learning_rate": 1.9898431214802897e-05,
      "loss": 1.4855,
      "step": 1010
    },
    {
      "epoch": 0.05128720836685439,
      "grad_norm": 40.5,
      "learning_rate": 1.9897425583266293e-05,
      "loss": 1.0843,
      "step": 1020
    },
    {
      "epoch": 0.051790024135156876,
      "grad_norm": 8.0,
      "learning_rate": 1.989641995172969e-05,
      "loss": 1.3188,
      "step": 1030
    },
    {
      "epoch": 0.05229283990345937,
      "grad_norm": 64.5,
      "learning_rate": 1.989541432019308e-05,
      "loss": 1.2116,
      "step": 1040
    },
    {
      "epoch": 0.052795655671761865,
      "grad_norm": 8.125,
      "learning_rate": 1.9894408688656477e-05,
      "loss": 0.8206,
      "step": 1050
    },
    {
      "epoch": 0.05329847144006436,
      "grad_norm": 23.125,
      "learning_rate": 1.9893403057119873e-05,
      "loss": 0.896,
      "step": 1060
    },
    {
      "epoch": 0.053801287208366855,
      "grad_norm": 11.0625,
      "learning_rate": 1.9892397425583266e-05,
      "loss": 1.1027,
      "step": 1070
    },
    {
      "epoch": 0.05430410297666935,
      "grad_norm": 57.25,
      "learning_rate": 1.9891391794046665e-05,
      "loss": 1.4035,
      "step": 1080
    },
    {
      "epoch": 0.054806918744971844,
      "grad_norm": 10.3125,
      "learning_rate": 1.9890386162510058e-05,
      "loss": 1.3311,
      "step": 1090
    },
    {
      "epoch": 0.05530973451327434,
      "grad_norm": 34.25,
      "learning_rate": 1.9889380530973453e-05,
      "loss": 1.6882,
      "step": 1100
    },
    {
      "epoch": 0.05581255028157683,
      "grad_norm": 36.0,
      "learning_rate": 1.988837489943685e-05,
      "loss": 0.9455,
      "step": 1110
    },
    {
      "epoch": 0.05631536604987932,
      "grad_norm": 56.5,
      "learning_rate": 1.9887369267900242e-05,
      "loss": 1.5086,
      "step": 1120
    },
    {
      "epoch": 0.056818181818181816,
      "grad_norm": 9.6875,
      "learning_rate": 1.9886363636363638e-05,
      "loss": 1.2461,
      "step": 1130
    },
    {
      "epoch": 0.05732099758648431,
      "grad_norm": 61.5,
      "learning_rate": 1.9885358004827034e-05,
      "loss": 1.1075,
      "step": 1140
    },
    {
      "epoch": 0.057823813354786806,
      "grad_norm": 35.25,
      "learning_rate": 1.9884352373290426e-05,
      "loss": 1.0538,
      "step": 1150
    },
    {
      "epoch": 0.0583266291230893,
      "grad_norm": 7.8125,
      "learning_rate": 1.9883346741753825e-05,
      "loss": 1.0417,
      "step": 1160
    },
    {
      "epoch": 0.058829444891391795,
      "grad_norm": 10.5,
      "learning_rate": 1.9882341110217218e-05,
      "loss": 1.1981,
      "step": 1170
    },
    {
      "epoch": 0.05933226065969429,
      "grad_norm": 35.75,
      "learning_rate": 1.9881335478680614e-05,
      "loss": 1.2672,
      "step": 1180
    },
    {
      "epoch": 0.059835076427996785,
      "grad_norm": 39.5,
      "learning_rate": 1.988032984714401e-05,
      "loss": 1.1306,
      "step": 1190
    },
    {
      "epoch": 0.06033789219629927,
      "grad_norm": 65.5,
      "learning_rate": 1.9879324215607402e-05,
      "loss": 1.3169,
      "step": 1200
    },
    {
      "epoch": 0.06084070796460177,
      "grad_norm": 29.625,
      "learning_rate": 1.9878318584070798e-05,
      "loss": 0.8346,
      "step": 1210
    },
    {
      "epoch": 0.06134352373290426,
      "grad_norm": 14.625,
      "learning_rate": 1.9877312952534194e-05,
      "loss": 0.8522,
      "step": 1220
    },
    {
      "epoch": 0.06184633950120676,
      "grad_norm": 18.5,
      "learning_rate": 1.9876307320997586e-05,
      "loss": 1.443,
      "step": 1230
    },
    {
      "epoch": 0.06234915526950925,
      "grad_norm": 67.0,
      "learning_rate": 1.9875301689460986e-05,
      "loss": 1.1026,
      "step": 1240
    },
    {
      "epoch": 0.06285197103781175,
      "grad_norm": 18.75,
      "learning_rate": 1.9874296057924378e-05,
      "loss": 0.8279,
      "step": 1250
    },
    {
      "epoch": 0.06335478680611424,
      "grad_norm": 22.625,
      "learning_rate": 1.9873290426387774e-05,
      "loss": 1.4913,
      "step": 1260
    },
    {
      "epoch": 0.06385760257441674,
      "grad_norm": 12.4375,
      "learning_rate": 1.987228479485117e-05,
      "loss": 0.9585,
      "step": 1270
    },
    {
      "epoch": 0.06436041834271923,
      "grad_norm": 27.25,
      "learning_rate": 1.9871279163314562e-05,
      "loss": 0.8827,
      "step": 1280
    },
    {
      "epoch": 0.06486323411102173,
      "grad_norm": 29.125,
      "learning_rate": 1.9870273531777958e-05,
      "loss": 1.0718,
      "step": 1290
    },
    {
      "epoch": 0.06536604987932422,
      "grad_norm": 11.4375,
      "learning_rate": 1.9869267900241354e-05,
      "loss": 0.8838,
      "step": 1300
    },
    {
      "epoch": 0.06586886564762671,
      "grad_norm": 26.0,
      "learning_rate": 1.9868262268704747e-05,
      "loss": 1.2334,
      "step": 1310
    },
    {
      "epoch": 0.06637168141592921,
      "grad_norm": 33.0,
      "learning_rate": 1.9867256637168142e-05,
      "loss": 1.2418,
      "step": 1320
    },
    {
      "epoch": 0.0668744971842317,
      "grad_norm": 23.125,
      "learning_rate": 1.986625100563154e-05,
      "loss": 1.353,
      "step": 1330
    },
    {
      "epoch": 0.06737731295253419,
      "grad_norm": 32.75,
      "learning_rate": 1.986524537409493e-05,
      "loss": 1.3633,
      "step": 1340
    },
    {
      "epoch": 0.06788012872083668,
      "grad_norm": 28.25,
      "learning_rate": 1.986423974255833e-05,
      "loss": 1.2437,
      "step": 1350
    },
    {
      "epoch": 0.06838294448913917,
      "grad_norm": 12.4375,
      "learning_rate": 1.9863234111021723e-05,
      "loss": 0.8242,
      "step": 1360
    },
    {
      "epoch": 0.06888576025744167,
      "grad_norm": 29.625,
      "learning_rate": 1.986222847948512e-05,
      "loss": 1.03,
      "step": 1370
    },
    {
      "epoch": 0.06938857602574416,
      "grad_norm": 20.75,
      "learning_rate": 1.9861222847948514e-05,
      "loss": 1.0067,
      "step": 1380
    },
    {
      "epoch": 0.06989139179404666,
      "grad_norm": 22.625,
      "learning_rate": 1.9860217216411907e-05,
      "loss": 1.2769,
      "step": 1390
    },
    {
      "epoch": 0.07039420756234915,
      "grad_norm": 27.875,
      "learning_rate": 1.9859211584875303e-05,
      "loss": 1.0452,
      "step": 1400
    },
    {
      "epoch": 0.07089702333065165,
      "grad_norm": 32.75,
      "learning_rate": 1.98582059533387e-05,
      "loss": 1.1272,
      "step": 1410
    },
    {
      "epoch": 0.07139983909895414,
      "grad_norm": 40.0,
      "learning_rate": 1.985720032180209e-05,
      "loss": 1.0697,
      "step": 1420
    },
    {
      "epoch": 0.07190265486725664,
      "grad_norm": 21.125,
      "learning_rate": 1.985619469026549e-05,
      "loss": 0.9728,
      "step": 1430
    },
    {
      "epoch": 0.07240547063555913,
      "grad_norm": 38.25,
      "learning_rate": 1.9855189058728883e-05,
      "loss": 1.0221,
      "step": 1440
    },
    {
      "epoch": 0.07290828640386163,
      "grad_norm": 13.5,
      "learning_rate": 1.985418342719228e-05,
      "loss": 0.9772,
      "step": 1450
    },
    {
      "epoch": 0.07341110217216412,
      "grad_norm": 66.0,
      "learning_rate": 1.9853177795655675e-05,
      "loss": 0.8205,
      "step": 1460
    },
    {
      "epoch": 0.07391391794046662,
      "grad_norm": 25.875,
      "learning_rate": 1.9852172164119067e-05,
      "loss": 0.9795,
      "step": 1470
    },
    {
      "epoch": 0.07441673370876911,
      "grad_norm": 15.4375,
      "learning_rate": 1.9851166532582463e-05,
      "loss": 1.1292,
      "step": 1480
    },
    {
      "epoch": 0.0749195494770716,
      "grad_norm": 11.8125,
      "learning_rate": 1.985016090104586e-05,
      "loss": 1.1356,
      "step": 1490
    },
    {
      "epoch": 0.0754223652453741,
      "grad_norm": 23.5,
      "learning_rate": 1.984915526950925e-05,
      "loss": 1.1094,
      "step": 1500
    },
    {
      "epoch": 0.0754223652453741,
      "eval_accuracy": 0.5020575111551809,
      "eval_loss": 1.2778980731964111,
      "eval_runtime": 464.4728,
      "eval_samples_per_second": 86.851,
      "eval_steps_per_second": 86.851,
      "step": 1500
    },
    {
      "epoch": 0.07592518101367658,
      "grad_norm": 20.625,
      "learning_rate": 1.984814963797265e-05,
      "loss": 1.2984,
      "step": 1510
    },
    {
      "epoch": 0.07642799678197908,
      "grad_norm": 16.5,
      "learning_rate": 1.9847144006436043e-05,
      "loss": 0.9923,
      "step": 1520
    },
    {
      "epoch": 0.07693081255028157,
      "grad_norm": 54.25,
      "learning_rate": 1.984613837489944e-05,
      "loss": 1.1829,
      "step": 1530
    },
    {
      "epoch": 0.07743362831858407,
      "grad_norm": 12.5625,
      "learning_rate": 1.9845132743362835e-05,
      "loss": 0.9829,
      "step": 1540
    },
    {
      "epoch": 0.07793644408688656,
      "grad_norm": 15.125,
      "learning_rate": 1.9844127111826227e-05,
      "loss": 0.9298,
      "step": 1550
    },
    {
      "epoch": 0.07843925985518906,
      "grad_norm": 14.3125,
      "learning_rate": 1.9843121480289623e-05,
      "loss": 0.948,
      "step": 1560
    },
    {
      "epoch": 0.07894207562349155,
      "grad_norm": 23.5,
      "learning_rate": 1.984211584875302e-05,
      "loss": 1.2381,
      "step": 1570
    },
    {
      "epoch": 0.07944489139179405,
      "grad_norm": 21.25,
      "learning_rate": 1.984111021721641e-05,
      "loss": 1.0238,
      "step": 1580
    },
    {
      "epoch": 0.07994770716009654,
      "grad_norm": 18.875,
      "learning_rate": 1.9840104585679807e-05,
      "loss": 0.7515,
      "step": 1590
    },
    {
      "epoch": 0.08045052292839903,
      "grad_norm": 45.5,
      "learning_rate": 1.9839098954143203e-05,
      "loss": 0.9784,
      "step": 1600
    },
    {
      "epoch": 0.08095333869670153,
      "grad_norm": 15.6875,
      "learning_rate": 1.9838093322606596e-05,
      "loss": 0.9643,
      "step": 1610
    },
    {
      "epoch": 0.08145615446500402,
      "grad_norm": 14.375,
      "learning_rate": 1.9837087691069995e-05,
      "loss": 0.6581,
      "step": 1620
    },
    {
      "epoch": 0.08195897023330652,
      "grad_norm": 8.6875,
      "learning_rate": 1.9836082059533388e-05,
      "loss": 1.0244,
      "step": 1630
    },
    {
      "epoch": 0.08246178600160901,
      "grad_norm": 20.0,
      "learning_rate": 1.9835076427996783e-05,
      "loss": 1.1502,
      "step": 1640
    },
    {
      "epoch": 0.08296460176991151,
      "grad_norm": 45.0,
      "learning_rate": 1.983407079646018e-05,
      "loss": 1.0626,
      "step": 1650
    },
    {
      "epoch": 0.083467417538214,
      "grad_norm": 45.75,
      "learning_rate": 1.9833065164923572e-05,
      "loss": 1.0124,
      "step": 1660
    },
    {
      "epoch": 0.0839702333065165,
      "grad_norm": 27.125,
      "learning_rate": 1.9832059533386968e-05,
      "loss": 1.2806,
      "step": 1670
    },
    {
      "epoch": 0.08447304907481899,
      "grad_norm": 58.5,
      "learning_rate": 1.9831053901850364e-05,
      "loss": 1.5004,
      "step": 1680
    },
    {
      "epoch": 0.08497586484312147,
      "grad_norm": 33.75,
      "learning_rate": 1.9830048270313756e-05,
      "loss": 1.586,
      "step": 1690
    },
    {
      "epoch": 0.08547868061142397,
      "grad_norm": 14.375,
      "learning_rate": 1.9829042638777155e-05,
      "loss": 0.9594,
      "step": 1700
    },
    {
      "epoch": 0.08598149637972646,
      "grad_norm": 28.875,
      "learning_rate": 1.9828037007240548e-05,
      "loss": 1.0504,
      "step": 1710
    },
    {
      "epoch": 0.08648431214802896,
      "grad_norm": 32.5,
      "learning_rate": 1.9827031375703944e-05,
      "loss": 0.8961,
      "step": 1720
    },
    {
      "epoch": 0.08698712791633145,
      "grad_norm": 30.75,
      "learning_rate": 1.982602574416734e-05,
      "loss": 1.0909,
      "step": 1730
    },
    {
      "epoch": 0.08748994368463395,
      "grad_norm": 18.125,
      "learning_rate": 1.9825020112630732e-05,
      "loss": 1.0049,
      "step": 1740
    },
    {
      "epoch": 0.08799275945293644,
      "grad_norm": 8.0,
      "learning_rate": 1.9824014481094128e-05,
      "loss": 0.9059,
      "step": 1750
    },
    {
      "epoch": 0.08849557522123894,
      "grad_norm": 44.5,
      "learning_rate": 1.9823008849557524e-05,
      "loss": 0.8509,
      "step": 1760
    },
    {
      "epoch": 0.08899839098954143,
      "grad_norm": 7.8125,
      "learning_rate": 1.9822003218020916e-05,
      "loss": 0.9924,
      "step": 1770
    },
    {
      "epoch": 0.08950120675784393,
      "grad_norm": 15.9375,
      "learning_rate": 1.9820997586484316e-05,
      "loss": 1.0462,
      "step": 1780
    },
    {
      "epoch": 0.09000402252614642,
      "grad_norm": 8.375,
      "learning_rate": 1.9819991954947708e-05,
      "loss": 0.863,
      "step": 1790
    },
    {
      "epoch": 0.09050683829444892,
      "grad_norm": 17.875,
      "learning_rate": 1.9818986323411104e-05,
      "loss": 1.0664,
      "step": 1800
    },
    {
      "epoch": 0.09100965406275141,
      "grad_norm": 21.625,
      "learning_rate": 1.98179806918745e-05,
      "loss": 1.023,
      "step": 1810
    },
    {
      "epoch": 0.0915124698310539,
      "grad_norm": 8.4375,
      "learning_rate": 1.9816975060337892e-05,
      "loss": 1.2834,
      "step": 1820
    },
    {
      "epoch": 0.0920152855993564,
      "grad_norm": 69.5,
      "learning_rate": 1.9815969428801288e-05,
      "loss": 1.231,
      "step": 1830
    },
    {
      "epoch": 0.0925181013676589,
      "grad_norm": 22.375,
      "learning_rate": 1.9814963797264684e-05,
      "loss": 1.0259,
      "step": 1840
    },
    {
      "epoch": 0.09302091713596139,
      "grad_norm": 7.0625,
      "learning_rate": 1.981395816572808e-05,
      "loss": 1.2927,
      "step": 1850
    },
    {
      "epoch": 0.09352373290426388,
      "grad_norm": 53.0,
      "learning_rate": 1.9812952534191472e-05,
      "loss": 0.8671,
      "step": 1860
    },
    {
      "epoch": 0.09402654867256637,
      "grad_norm": 13.8125,
      "learning_rate": 1.981194690265487e-05,
      "loss": 1.1904,
      "step": 1870
    },
    {
      "epoch": 0.09452936444086886,
      "grad_norm": 24.375,
      "learning_rate": 1.9810941271118264e-05,
      "loss": 1.4408,
      "step": 1880
    },
    {
      "epoch": 0.09503218020917135,
      "grad_norm": 9.25,
      "learning_rate": 1.980993563958166e-05,
      "loss": 1.2783,
      "step": 1890
    },
    {
      "epoch": 0.09553499597747385,
      "grad_norm": 47.5,
      "learning_rate": 1.9808930008045053e-05,
      "loss": 1.1093,
      "step": 1900
    },
    {
      "epoch": 0.09603781174577634,
      "grad_norm": 58.5,
      "learning_rate": 1.980792437650845e-05,
      "loss": 1.2751,
      "step": 1910
    },
    {
      "epoch": 0.09654062751407884,
      "grad_norm": 3.03125,
      "learning_rate": 1.9806918744971844e-05,
      "loss": 0.8366,
      "step": 1920
    },
    {
      "epoch": 0.09704344328238133,
      "grad_norm": 27.125,
      "learning_rate": 1.980591311343524e-05,
      "loss": 1.0107,
      "step": 1930
    },
    {
      "epoch": 0.09754625905068383,
      "grad_norm": 20.0,
      "learning_rate": 1.9804907481898633e-05,
      "loss": 0.9459,
      "step": 1940
    },
    {
      "epoch": 0.09804907481898632,
      "grad_norm": 13.0,
      "learning_rate": 1.980390185036203e-05,
      "loss": 0.9708,
      "step": 1950
    },
    {
      "epoch": 0.09855189058728882,
      "grad_norm": 8.5,
      "learning_rate": 1.9802896218825425e-05,
      "loss": 0.7031,
      "step": 1960
    },
    {
      "epoch": 0.09905470635559131,
      "grad_norm": 6.75,
      "learning_rate": 1.980189058728882e-05,
      "loss": 1.0424,
      "step": 1970
    },
    {
      "epoch": 0.09955752212389381,
      "grad_norm": 20.875,
      "learning_rate": 1.9800884955752213e-05,
      "loss": 1.4547,
      "step": 1980
    },
    {
      "epoch": 0.1000603378921963,
      "grad_norm": 19.125,
      "learning_rate": 1.979987932421561e-05,
      "loss": 1.0723,
      "step": 1990
    },
    {
      "epoch": 0.1005631536604988,
      "grad_norm": 25.625,
      "learning_rate": 1.9798873692679005e-05,
      "loss": 0.7404,
      "step": 2000
    },
    {
      "epoch": 0.1005631536604988,
      "eval_accuracy": 0.5057759048091225,
      "eval_loss": 1.196290373802185,
      "eval_runtime": 463.4626,
      "eval_samples_per_second": 87.04,
      "eval_steps_per_second": 87.04,
      "step": 2000
    },
    {
      "epoch": 0.10106596942880129,
      "grad_norm": 6.09375,
      "learning_rate": 1.97978680611424e-05,
      "loss": 0.7338,
      "step": 2010
    },
    {
      "epoch": 0.10156878519710379,
      "grad_norm": 11.4375,
      "learning_rate": 1.9796862429605793e-05,
      "loss": 1.273,
      "step": 2020
    },
    {
      "epoch": 0.10207160096540628,
      "grad_norm": 17.75,
      "learning_rate": 1.979585679806919e-05,
      "loss": 0.9983,
      "step": 2030
    },
    {
      "epoch": 0.10257441673370878,
      "grad_norm": 20.375,
      "learning_rate": 1.9794851166532585e-05,
      "loss": 1.306,
      "step": 2040
    },
    {
      "epoch": 0.10307723250201126,
      "grad_norm": 5.21875,
      "learning_rate": 1.979384553499598e-05,
      "loss": 0.8712,
      "step": 2050
    },
    {
      "epoch": 0.10358004827031375,
      "grad_norm": 14.125,
      "learning_rate": 1.9792839903459373e-05,
      "loss": 0.9737,
      "step": 2060
    },
    {
      "epoch": 0.10408286403861625,
      "grad_norm": 10.6875,
      "learning_rate": 1.979183427192277e-05,
      "loss": 0.835,
      "step": 2070
    },
    {
      "epoch": 0.10458567980691874,
      "grad_norm": 15.5,
      "learning_rate": 1.9790828640386165e-05,
      "loss": 1.0255,
      "step": 2080
    },
    {
      "epoch": 0.10508849557522124,
      "grad_norm": 12.125,
      "learning_rate": 1.978982300884956e-05,
      "loss": 0.9322,
      "step": 2090
    },
    {
      "epoch": 0.10559131134352373,
      "grad_norm": 66.0,
      "learning_rate": 1.9788817377312953e-05,
      "loss": 1.3371,
      "step": 2100
    },
    {
      "epoch": 0.10609412711182623,
      "grad_norm": 15.3125,
      "learning_rate": 1.978781174577635e-05,
      "loss": 1.0585,
      "step": 2110
    },
    {
      "epoch": 0.10659694288012872,
      "grad_norm": 35.0,
      "learning_rate": 1.9786806114239745e-05,
      "loss": 1.0711,
      "step": 2120
    },
    {
      "epoch": 0.10709975864843121,
      "grad_norm": 24.75,
      "learning_rate": 1.9785800482703138e-05,
      "loss": 1.3138,
      "step": 2130
    },
    {
      "epoch": 0.10760257441673371,
      "grad_norm": 41.75,
      "learning_rate": 1.9784794851166533e-05,
      "loss": 1.34,
      "step": 2140
    },
    {
      "epoch": 0.1081053901850362,
      "grad_norm": 7.34375,
      "learning_rate": 1.978378921962993e-05,
      "loss": 0.9177,
      "step": 2150
    },
    {
      "epoch": 0.1086082059533387,
      "grad_norm": 37.75,
      "learning_rate": 1.9782783588093325e-05,
      "loss": 1.1133,
      "step": 2160
    },
    {
      "epoch": 0.1091110217216412,
      "grad_norm": 63.75,
      "learning_rate": 1.978177795655672e-05,
      "loss": 1.0031,
      "step": 2170
    },
    {
      "epoch": 0.10961383748994369,
      "grad_norm": 5.875,
      "learning_rate": 1.9780772325020114e-05,
      "loss": 0.898,
      "step": 2180
    },
    {
      "epoch": 0.11011665325824618,
      "grad_norm": 12.5,
      "learning_rate": 1.977976669348351e-05,
      "loss": 1.0838,
      "step": 2190
    },
    {
      "epoch": 0.11061946902654868,
      "grad_norm": 20.25,
      "learning_rate": 1.9778761061946905e-05,
      "loss": 1.614,
      "step": 2200
    },
    {
      "epoch": 0.11112228479485117,
      "grad_norm": 29.375,
      "learning_rate": 1.9777755430410298e-05,
      "loss": 1.0045,
      "step": 2210
    },
    {
      "epoch": 0.11162510056315365,
      "grad_norm": 29.625,
      "learning_rate": 1.9776749798873694e-05,
      "loss": 1.08,
      "step": 2220
    },
    {
      "epoch": 0.11212791633145615,
      "grad_norm": 8.9375,
      "learning_rate": 1.977574416733709e-05,
      "loss": 0.9126,
      "step": 2230
    },
    {
      "epoch": 0.11263073209975864,
      "grad_norm": 20.5,
      "learning_rate": 1.9774738535800485e-05,
      "loss": 0.868,
      "step": 2240
    },
    {
      "epoch": 0.11313354786806114,
      "grad_norm": 25.375,
      "learning_rate": 1.977373290426388e-05,
      "loss": 0.7441,
      "step": 2250
    },
    {
      "epoch": 0.11363636363636363,
      "grad_norm": 30.25,
      "learning_rate": 1.9772727272727274e-05,
      "loss": 1.2848,
      "step": 2260
    },
    {
      "epoch": 0.11413917940466613,
      "grad_norm": 5.625,
      "learning_rate": 1.977172164119067e-05,
      "loss": 1.0578,
      "step": 2270
    },
    {
      "epoch": 0.11464199517296862,
      "grad_norm": 22.625,
      "learning_rate": 1.9770716009654066e-05,
      "loss": 1.399,
      "step": 2280
    },
    {
      "epoch": 0.11514481094127112,
      "grad_norm": 7.96875,
      "learning_rate": 1.9769710378117458e-05,
      "loss": 0.9063,
      "step": 2290
    },
    {
      "epoch": 0.11564762670957361,
      "grad_norm": 6.5625,
      "learning_rate": 1.9768704746580854e-05,
      "loss": 1.0792,
      "step": 2300
    },
    {
      "epoch": 0.1161504424778761,
      "grad_norm": 9.9375,
      "learning_rate": 1.976769911504425e-05,
      "loss": 0.8213,
      "step": 2310
    },
    {
      "epoch": 0.1166532582461786,
      "grad_norm": 17.0,
      "learning_rate": 1.9766693483507646e-05,
      "loss": 1.2637,
      "step": 2320
    },
    {
      "epoch": 0.1171560740144811,
      "grad_norm": 23.875,
      "learning_rate": 1.976568785197104e-05,
      "loss": 0.8917,
      "step": 2330
    },
    {
      "epoch": 0.11765888978278359,
      "grad_norm": 18.0,
      "learning_rate": 1.9764682220434434e-05,
      "loss": 0.849,
      "step": 2340
    },
    {
      "epoch": 0.11816170555108609,
      "grad_norm": 9.5625,
      "learning_rate": 1.976367658889783e-05,
      "loss": 0.9853,
      "step": 2350
    },
    {
      "epoch": 0.11866452131938858,
      "grad_norm": 12.5625,
      "learning_rate": 1.9762670957361226e-05,
      "loss": 1.1028,
      "step": 2360
    },
    {
      "epoch": 0.11916733708769107,
      "grad_norm": 7.375,
      "learning_rate": 1.9761665325824618e-05,
      "loss": 1.2908,
      "step": 2370
    },
    {
      "epoch": 0.11967015285599357,
      "grad_norm": 70.0,
      "learning_rate": 1.9760659694288014e-05,
      "loss": 1.004,
      "step": 2380
    },
    {
      "epoch": 0.12017296862429606,
      "grad_norm": 6.25,
      "learning_rate": 1.975965406275141e-05,
      "loss": 1.0106,
      "step": 2390
    },
    {
      "epoch": 0.12067578439259855,
      "grad_norm": 30.125,
      "learning_rate": 1.9758648431214803e-05,
      "loss": 1.4111,
      "step": 2400
    },
    {
      "epoch": 0.12117860016090104,
      "grad_norm": 5.625,
      "learning_rate": 1.9757642799678202e-05,
      "loss": 1.2037,
      "step": 2410
    },
    {
      "epoch": 0.12168141592920353,
      "grad_norm": 37.0,
      "learning_rate": 1.9756637168141594e-05,
      "loss": 1.2363,
      "step": 2420
    },
    {
      "epoch": 0.12218423169750603,
      "grad_norm": 11.75,
      "learning_rate": 1.975563153660499e-05,
      "loss": 1.027,
      "step": 2430
    },
    {
      "epoch": 0.12268704746580852,
      "grad_norm": 24.5,
      "learning_rate": 1.9754625905068386e-05,
      "loss": 1.0427,
      "step": 2440
    },
    {
      "epoch": 0.12318986323411102,
      "grad_norm": 21.125,
      "learning_rate": 1.975362027353178e-05,
      "loss": 0.6839,
      "step": 2450
    },
    {
      "epoch": 0.12369267900241351,
      "grad_norm": 20.75,
      "learning_rate": 1.9752614641995174e-05,
      "loss": 1.0212,
      "step": 2460
    },
    {
      "epoch": 0.12419549477071601,
      "grad_norm": 4.625,
      "learning_rate": 1.975160901045857e-05,
      "loss": 0.7714,
      "step": 2470
    },
    {
      "epoch": 0.1246983105390185,
      "grad_norm": 24.125,
      "learning_rate": 1.9750603378921963e-05,
      "loss": 1.0904,
      "step": 2480
    },
    {
      "epoch": 0.125201126307321,
      "grad_norm": 29.0,
      "learning_rate": 1.9749597747385362e-05,
      "loss": 0.9094,
      "step": 2490
    },
    {
      "epoch": 0.1257039420756235,
      "grad_norm": 10.75,
      "learning_rate": 1.9748592115848755e-05,
      "loss": 0.9452,
      "step": 2500
    },
    {
      "epoch": 0.1257039420756235,
      "eval_accuracy": 0.5054784333168071,
      "eval_loss": 1.1597926616668701,
      "eval_runtime": 462.8178,
      "eval_samples_per_second": 87.162,
      "eval_steps_per_second": 87.162,
      "step": 2500
    },
    {
      "epoch": 0.126206757843926,
      "grad_norm": 51.5,
      "learning_rate": 1.974758648431215e-05,
      "loss": 1.0503,
      "step": 2510
    },
    {
      "epoch": 0.12670957361222848,
      "grad_norm": 38.75,
      "learning_rate": 1.9746580852775546e-05,
      "loss": 1.1281,
      "step": 2520
    },
    {
      "epoch": 0.12721238938053098,
      "grad_norm": 40.5,
      "learning_rate": 1.974557522123894e-05,
      "loss": 1.3772,
      "step": 2530
    },
    {
      "epoch": 0.12771520514883347,
      "grad_norm": 28.125,
      "learning_rate": 1.9744569589702335e-05,
      "loss": 1.1235,
      "step": 2540
    },
    {
      "epoch": 0.12821802091713597,
      "grad_norm": 14.4375,
      "learning_rate": 1.974356395816573e-05,
      "loss": 1.1356,
      "step": 2550
    },
    {
      "epoch": 0.12872083668543846,
      "grad_norm": 6.875,
      "learning_rate": 1.9742558326629123e-05,
      "loss": 0.6989,
      "step": 2560
    },
    {
      "epoch": 0.12922365245374096,
      "grad_norm": 24.375,
      "learning_rate": 1.9741552695092522e-05,
      "loss": 0.9068,
      "step": 2570
    },
    {
      "epoch": 0.12972646822204345,
      "grad_norm": 33.0,
      "learning_rate": 1.9740547063555915e-05,
      "loss": 0.6883,
      "step": 2580
    },
    {
      "epoch": 0.13022928399034595,
      "grad_norm": 9.5,
      "learning_rate": 1.973954143201931e-05,
      "loss": 0.8915,
      "step": 2590
    },
    {
      "epoch": 0.13073209975864844,
      "grad_norm": 10.6875,
      "learning_rate": 1.9738535800482707e-05,
      "loss": 1.1406,
      "step": 2600
    },
    {
      "epoch": 0.13123491552695093,
      "grad_norm": 9.5625,
      "learning_rate": 1.97375301689461e-05,
      "loss": 1.1171,
      "step": 2610
    },
    {
      "epoch": 0.13173773129525343,
      "grad_norm": 8.6875,
      "learning_rate": 1.9736524537409495e-05,
      "loss": 0.8735,
      "step": 2620
    },
    {
      "epoch": 0.13224054706355592,
      "grad_norm": 20.5,
      "learning_rate": 1.973551890587289e-05,
      "loss": 1.0478,
      "step": 2630
    },
    {
      "epoch": 0.13274336283185842,
      "grad_norm": 16.625,
      "learning_rate": 1.9734513274336283e-05,
      "loss": 0.9281,
      "step": 2640
    },
    {
      "epoch": 0.1332461786001609,
      "grad_norm": 25.75,
      "learning_rate": 1.973350764279968e-05,
      "loss": 1.0036,
      "step": 2650
    },
    {
      "epoch": 0.1337489943684634,
      "grad_norm": 42.25,
      "learning_rate": 1.9732502011263075e-05,
      "loss": 1.0214,
      "step": 2660
    },
    {
      "epoch": 0.13425181013676588,
      "grad_norm": 55.75,
      "learning_rate": 1.9731496379726468e-05,
      "loss": 1.173,
      "step": 2670
    },
    {
      "epoch": 0.13475462590506837,
      "grad_norm": 36.75,
      "learning_rate": 1.9730490748189867e-05,
      "loss": 1.1137,
      "step": 2680
    },
    {
      "epoch": 0.13525744167337087,
      "grad_norm": 19.375,
      "learning_rate": 1.972948511665326e-05,
      "loss": 0.8623,
      "step": 2690
    },
    {
      "epoch": 0.13576025744167336,
      "grad_norm": 11.4375,
      "learning_rate": 1.9728479485116655e-05,
      "loss": 0.8267,
      "step": 2700
    },
    {
      "epoch": 0.13626307320997585,
      "grad_norm": 8.25,
      "learning_rate": 1.972747385358005e-05,
      "loss": 1.0373,
      "step": 2710
    },
    {
      "epoch": 0.13676588897827835,
      "grad_norm": 47.25,
      "learning_rate": 1.9726468222043444e-05,
      "loss": 1.0575,
      "step": 2720
    },
    {
      "epoch": 0.13726870474658084,
      "grad_norm": 24.75,
      "learning_rate": 1.972546259050684e-05,
      "loss": 1.1627,
      "step": 2730
    },
    {
      "epoch": 0.13777152051488334,
      "grad_norm": 18.875,
      "learning_rate": 1.9724456958970235e-05,
      "loss": 1.1038,
      "step": 2740
    },
    {
      "epoch": 0.13827433628318583,
      "grad_norm": 58.5,
      "learning_rate": 1.9723451327433628e-05,
      "loss": 1.2842,
      "step": 2750
    },
    {
      "epoch": 0.13877715205148833,
      "grad_norm": 33.0,
      "learning_rate": 1.9722445695897027e-05,
      "loss": 1.2195,
      "step": 2760
    },
    {
      "epoch": 0.13927996781979082,
      "grad_norm": 39.0,
      "learning_rate": 1.972144006436042e-05,
      "loss": 1.0509,
      "step": 2770
    },
    {
      "epoch": 0.13978278358809332,
      "grad_norm": 4.90625,
      "learning_rate": 1.9720434432823815e-05,
      "loss": 0.9176,
      "step": 2780
    },
    {
      "epoch": 0.1402855993563958,
      "grad_norm": 43.75,
      "learning_rate": 1.971942880128721e-05,
      "loss": 1.0877,
      "step": 2790
    },
    {
      "epoch": 0.1407884151246983,
      "grad_norm": 15.75,
      "learning_rate": 1.9718423169750604e-05,
      "loss": 1.0382,
      "step": 2800
    },
    {
      "epoch": 0.1412912308930008,
      "grad_norm": 29.75,
      "learning_rate": 1.9717417538214e-05,
      "loss": 0.9011,
      "step": 2810
    },
    {
      "epoch": 0.1417940466613033,
      "grad_norm": 8.5,
      "learning_rate": 1.9716411906677396e-05,
      "loss": 0.8672,
      "step": 2820
    },
    {
      "epoch": 0.1422968624296058,
      "grad_norm": 17.375,
      "learning_rate": 1.9715406275140788e-05,
      "loss": 0.9634,
      "step": 2830
    },
    {
      "epoch": 0.1427996781979083,
      "grad_norm": 43.0,
      "learning_rate": 1.9714400643604187e-05,
      "loss": 1.1591,
      "step": 2840
    },
    {
      "epoch": 0.14330249396621078,
      "grad_norm": 11.5625,
      "learning_rate": 1.971339501206758e-05,
      "loss": 0.8279,
      "step": 2850
    },
    {
      "epoch": 0.14380530973451328,
      "grad_norm": 16.75,
      "learning_rate": 1.9712389380530976e-05,
      "loss": 1.342,
      "step": 2860
    },
    {
      "epoch": 0.14430812550281577,
      "grad_norm": 43.75,
      "learning_rate": 1.971138374899437e-05,
      "loss": 0.9795,
      "step": 2870
    },
    {
      "epoch": 0.14481094127111827,
      "grad_norm": 19.875,
      "learning_rate": 1.9710378117457764e-05,
      "loss": 1.1341,
      "step": 2880
    },
    {
      "epoch": 0.14531375703942076,
      "grad_norm": 12.3125,
      "learning_rate": 1.970937248592116e-05,
      "loss": 1.4276,
      "step": 2890
    },
    {
      "epoch": 0.14581657280772325,
      "grad_norm": 14.9375,
      "learning_rate": 1.9708366854384556e-05,
      "loss": 1.3269,
      "step": 2900
    },
    {
      "epoch": 0.14631938857602575,
      "grad_norm": 42.0,
      "learning_rate": 1.9707361222847948e-05,
      "loss": 1.1609,
      "step": 2910
    },
    {
      "epoch": 0.14682220434432824,
      "grad_norm": 4.59375,
      "learning_rate": 1.9706355591311344e-05,
      "loss": 0.7524,
      "step": 2920
    },
    {
      "epoch": 0.14732502011263074,
      "grad_norm": 10.6875,
      "learning_rate": 1.970534995977474e-05,
      "loss": 0.9016,
      "step": 2930
    },
    {
      "epoch": 0.14782783588093323,
      "grad_norm": 24.0,
      "learning_rate": 1.9704344328238133e-05,
      "loss": 0.8496,
      "step": 2940
    },
    {
      "epoch": 0.14833065164923573,
      "grad_norm": 5.28125,
      "learning_rate": 1.9703338696701532e-05,
      "loss": 1.0099,
      "step": 2950
    },
    {
      "epoch": 0.14883346741753822,
      "grad_norm": 23.75,
      "learning_rate": 1.9702333065164924e-05,
      "loss": 1.2633,
      "step": 2960
    },
    {
      "epoch": 0.14933628318584072,
      "grad_norm": 6.21875,
      "learning_rate": 1.970132743362832e-05,
      "loss": 1.1463,
      "step": 2970
    },
    {
      "epoch": 0.1498390989541432,
      "grad_norm": 20.375,
      "learning_rate": 1.9700321802091716e-05,
      "loss": 1.2526,
      "step": 2980
    },
    {
      "epoch": 0.1503419147224457,
      "grad_norm": 7.40625,
      "learning_rate": 1.969931617055511e-05,
      "loss": 1.258,
      "step": 2990
    },
    {
      "epoch": 0.1508447304907482,
      "grad_norm": 65.5,
      "learning_rate": 1.9698310539018504e-05,
      "loss": 1.0141,
      "step": 3000
    },
    {
      "epoch": 0.1508447304907482,
      "eval_accuracy": 0.5075359444719881,
      "eval_loss": 1.1231328248977661,
      "eval_runtime": 463.832,
      "eval_samples_per_second": 86.971,
      "eval_steps_per_second": 86.971,
      "step": 3000
    },
    {
      "epoch": 0.1513475462590507,
      "grad_norm": 31.875,
      "learning_rate": 1.96973049074819e-05,
      "loss": 1.0824,
      "step": 3010
    },
    {
      "epoch": 0.15185036202735316,
      "grad_norm": 16.75,
      "learning_rate": 1.9696299275945293e-05,
      "loss": 1.2176,
      "step": 3020
    },
    {
      "epoch": 0.15235317779565566,
      "grad_norm": 21.875,
      "learning_rate": 1.9695293644408692e-05,
      "loss": 0.918,
      "step": 3030
    },
    {
      "epoch": 0.15285599356395815,
      "grad_norm": 18.875,
      "learning_rate": 1.9694288012872085e-05,
      "loss": 0.9132,
      "step": 3040
    },
    {
      "epoch": 0.15335880933226065,
      "grad_norm": 19.375,
      "learning_rate": 1.969328238133548e-05,
      "loss": 1.0541,
      "step": 3050
    },
    {
      "epoch": 0.15386162510056314,
      "grad_norm": 31.0,
      "learning_rate": 1.9692276749798876e-05,
      "loss": 1.023,
      "step": 3060
    },
    {
      "epoch": 0.15436444086886564,
      "grad_norm": 24.625,
      "learning_rate": 1.969127111826227e-05,
      "loss": 1.2168,
      "step": 3070
    },
    {
      "epoch": 0.15486725663716813,
      "grad_norm": 19.5,
      "learning_rate": 1.9690265486725665e-05,
      "loss": 0.968,
      "step": 3080
    },
    {
      "epoch": 0.15537007240547063,
      "grad_norm": 64.5,
      "learning_rate": 1.968925985518906e-05,
      "loss": 1.3459,
      "step": 3090
    },
    {
      "epoch": 0.15587288817377312,
      "grad_norm": 9.0,
      "learning_rate": 1.9688254223652453e-05,
      "loss": 0.8097,
      "step": 3100
    },
    {
      "epoch": 0.15637570394207562,
      "grad_norm": 16.375,
      "learning_rate": 1.9687248592115852e-05,
      "loss": 0.6782,
      "step": 3110
    },
    {
      "epoch": 0.1568785197103781,
      "grad_norm": 9.375,
      "learning_rate": 1.9686242960579245e-05,
      "loss": 1.1597,
      "step": 3120
    },
    {
      "epoch": 0.1573813354786806,
      "grad_norm": 19.875,
      "learning_rate": 1.968523732904264e-05,
      "loss": 1.2039,
      "step": 3130
    },
    {
      "epoch": 0.1578841512469831,
      "grad_norm": 13.875,
      "learning_rate": 1.9684231697506037e-05,
      "loss": 0.9437,
      "step": 3140
    },
    {
      "epoch": 0.1583869670152856,
      "grad_norm": 125.5,
      "learning_rate": 1.968322606596943e-05,
      "loss": 1.0803,
      "step": 3150
    },
    {
      "epoch": 0.1588897827835881,
      "grad_norm": 11.875,
      "learning_rate": 1.9682220434432825e-05,
      "loss": 1.1613,
      "step": 3160
    },
    {
      "epoch": 0.15939259855189059,
      "grad_norm": 17.5,
      "learning_rate": 1.968121480289622e-05,
      "loss": 1.1287,
      "step": 3170
    },
    {
      "epoch": 0.15989541432019308,
      "grad_norm": 27.125,
      "learning_rate": 1.9680209171359613e-05,
      "loss": 1.0549,
      "step": 3180
    },
    {
      "epoch": 0.16039823008849557,
      "grad_norm": 16.0,
      "learning_rate": 1.967920353982301e-05,
      "loss": 1.2829,
      "step": 3190
    },
    {
      "epoch": 0.16090104585679807,
      "grad_norm": 33.5,
      "learning_rate": 1.9678197908286405e-05,
      "loss": 0.6152,
      "step": 3200
    },
    {
      "epoch": 0.16140386162510056,
      "grad_norm": 44.5,
      "learning_rate": 1.96771922767498e-05,
      "loss": 1.0514,
      "step": 3210
    },
    {
      "epoch": 0.16190667739340306,
      "grad_norm": 80.5,
      "learning_rate": 1.9676186645213197e-05,
      "loss": 1.0487,
      "step": 3220
    },
    {
      "epoch": 0.16240949316170555,
      "grad_norm": 48.25,
      "learning_rate": 1.967518101367659e-05,
      "loss": 1.0744,
      "step": 3230
    },
    {
      "epoch": 0.16291230893000805,
      "grad_norm": 24.875,
      "learning_rate": 1.9674175382139985e-05,
      "loss": 1.1655,
      "step": 3240
    },
    {
      "epoch": 0.16341512469831054,
      "grad_norm": 37.0,
      "learning_rate": 1.967316975060338e-05,
      "loss": 1.0573,
      "step": 3250
    },
    {
      "epoch": 0.16391794046661304,
      "grad_norm": 9.0,
      "learning_rate": 1.9672164119066774e-05,
      "loss": 1.0104,
      "step": 3260
    },
    {
      "epoch": 0.16442075623491553,
      "grad_norm": 3.90625,
      "learning_rate": 1.967115848753017e-05,
      "loss": 0.8098,
      "step": 3270
    },
    {
      "epoch": 0.16492357200321803,
      "grad_norm": 15.375,
      "learning_rate": 1.9670152855993565e-05,
      "loss": 0.8626,
      "step": 3280
    },
    {
      "epoch": 0.16542638777152052,
      "grad_norm": 40.5,
      "learning_rate": 1.966914722445696e-05,
      "loss": 0.9948,
      "step": 3290
    },
    {
      "epoch": 0.16592920353982302,
      "grad_norm": 22.375,
      "learning_rate": 1.9668141592920357e-05,
      "loss": 0.9389,
      "step": 3300
    },
    {
      "epoch": 0.1664320193081255,
      "grad_norm": 19.375,
      "learning_rate": 1.966713596138375e-05,
      "loss": 1.3179,
      "step": 3310
    },
    {
      "epoch": 0.166934835076428,
      "grad_norm": 8.9375,
      "learning_rate": 1.9666130329847145e-05,
      "loss": 0.8864,
      "step": 3320
    },
    {
      "epoch": 0.1674376508447305,
      "grad_norm": 17.5,
      "learning_rate": 1.966512469831054e-05,
      "loss": 1.1146,
      "step": 3330
    },
    {
      "epoch": 0.167940466613033,
      "grad_norm": 29.5,
      "learning_rate": 1.9664119066773934e-05,
      "loss": 1.1229,
      "step": 3340
    },
    {
      "epoch": 0.1684432823813355,
      "grad_norm": 54.25,
      "learning_rate": 1.966311343523733e-05,
      "loss": 1.0238,
      "step": 3350
    },
    {
      "epoch": 0.16894609814963799,
      "grad_norm": 33.0,
      "learning_rate": 1.9662107803700726e-05,
      "loss": 1.0284,
      "step": 3360
    },
    {
      "epoch": 0.16944891391794048,
      "grad_norm": 26.375,
      "learning_rate": 1.966110217216412e-05,
      "loss": 1.0578,
      "step": 3370
    },
    {
      "epoch": 0.16995172968624295,
      "grad_norm": 66.5,
      "learning_rate": 1.9660096540627517e-05,
      "loss": 1.3476,
      "step": 3380
    },
    {
      "epoch": 0.17045454545454544,
      "grad_norm": 20.625,
      "learning_rate": 1.965909090909091e-05,
      "loss": 1.038,
      "step": 3390
    },
    {
      "epoch": 0.17095736122284794,
      "grad_norm": 23.625,
      "learning_rate": 1.9658085277554306e-05,
      "loss": 0.8734,
      "step": 3400
    },
    {
      "epoch": 0.17146017699115043,
      "grad_norm": 25.75,
      "learning_rate": 1.96570796460177e-05,
      "loss": 0.9469,
      "step": 3410
    },
    {
      "epoch": 0.17196299275945293,
      "grad_norm": 39.0,
      "learning_rate": 1.9656074014481094e-05,
      "loss": 1.0126,
      "step": 3420
    },
    {
      "epoch": 0.17246580852775542,
      "grad_norm": 11.125,
      "learning_rate": 1.965506838294449e-05,
      "loss": 1.171,
      "step": 3430
    },
    {
      "epoch": 0.17296862429605792,
      "grad_norm": 14.9375,
      "learning_rate": 1.9654062751407886e-05,
      "loss": 0.8855,
      "step": 3440
    },
    {
      "epoch": 0.1734714400643604,
      "grad_norm": 18.375,
      "learning_rate": 1.9653057119871282e-05,
      "loss": 0.826,
      "step": 3450
    },
    {
      "epoch": 0.1739742558326629,
      "grad_norm": 34.25,
      "learning_rate": 1.9652051488334674e-05,
      "loss": 1.0488,
      "step": 3460
    },
    {
      "epoch": 0.1744770716009654,
      "grad_norm": 25.5,
      "learning_rate": 1.965104585679807e-05,
      "loss": 1.3076,
      "step": 3470
    },
    {
      "epoch": 0.1749798873692679,
      "grad_norm": 48.25,
      "learning_rate": 1.9650040225261466e-05,
      "loss": 1.0111,
      "step": 3480
    },
    {
      "epoch": 0.1754827031375704,
      "grad_norm": 12.625,
      "learning_rate": 1.9649034593724862e-05,
      "loss": 0.8922,
      "step": 3490
    },
    {
      "epoch": 0.17598551890587288,
      "grad_norm": 9.375,
      "learning_rate": 1.9648028962188254e-05,
      "loss": 0.8531,
      "step": 3500
    },
    {
      "epoch": 0.17598551890587288,
      "eval_accuracy": 0.5079573624194348,
      "eval_loss": 1.1100460290908813,
      "eval_runtime": 464.6001,
      "eval_samples_per_second": 86.827,
      "eval_steps_per_second": 86.827,
      "step": 3500
    },
    {
      "epoch": 0.17648833467417538,
      "grad_norm": 8.75,
      "learning_rate": 1.964702333065165e-05,
      "loss": 0.9134,
      "step": 3510
    },
    {
      "epoch": 0.17699115044247787,
      "grad_norm": 28.375,
      "learning_rate": 1.9646017699115046e-05,
      "loss": 0.8783,
      "step": 3520
    },
    {
      "epoch": 0.17749396621078037,
      "grad_norm": 50.75,
      "learning_rate": 1.9645012067578442e-05,
      "loss": 1.157,
      "step": 3530
    },
    {
      "epoch": 0.17799678197908286,
      "grad_norm": 7.1875,
      "learning_rate": 1.9644006436041834e-05,
      "loss": 0.9487,
      "step": 3540
    },
    {
      "epoch": 0.17849959774738536,
      "grad_norm": 20.625,
      "learning_rate": 1.964300080450523e-05,
      "loss": 1.0309,
      "step": 3550
    },
    {
      "epoch": 0.17900241351568785,
      "grad_norm": 11.125,
      "learning_rate": 1.9641995172968626e-05,
      "loss": 1.1905,
      "step": 3560
    },
    {
      "epoch": 0.17950522928399035,
      "grad_norm": 48.75,
      "learning_rate": 1.9640989541432022e-05,
      "loss": 1.1218,
      "step": 3570
    },
    {
      "epoch": 0.18000804505229284,
      "grad_norm": 19.0,
      "learning_rate": 1.9639983909895418e-05,
      "loss": 0.6753,
      "step": 3580
    },
    {
      "epoch": 0.18051086082059534,
      "grad_norm": 77.5,
      "learning_rate": 1.963897827835881e-05,
      "loss": 1.2511,
      "step": 3590
    },
    {
      "epoch": 0.18101367658889783,
      "grad_norm": 5.40625,
      "learning_rate": 1.9637972646822206e-05,
      "loss": 0.9225,
      "step": 3600
    },
    {
      "epoch": 0.18151649235720033,
      "grad_norm": 19.625,
      "learning_rate": 1.9636967015285602e-05,
      "loss": 0.8115,
      "step": 3610
    },
    {
      "epoch": 0.18201930812550282,
      "grad_norm": 32.0,
      "learning_rate": 1.9635961383748995e-05,
      "loss": 1.2921,
      "step": 3620
    },
    {
      "epoch": 0.18252212389380532,
      "grad_norm": 8.375,
      "learning_rate": 1.963495575221239e-05,
      "loss": 1.0419,
      "step": 3630
    },
    {
      "epoch": 0.1830249396621078,
      "grad_norm": 20.875,
      "learning_rate": 1.9633950120675786e-05,
      "loss": 0.98,
      "step": 3640
    },
    {
      "epoch": 0.1835277554304103,
      "grad_norm": 9.1875,
      "learning_rate": 1.9632944489139182e-05,
      "loss": 0.9442,
      "step": 3650
    },
    {
      "epoch": 0.1840305711987128,
      "grad_norm": 45.75,
      "learning_rate": 1.9631938857602578e-05,
      "loss": 1.0846,
      "step": 3660
    },
    {
      "epoch": 0.1845333869670153,
      "grad_norm": 22.125,
      "learning_rate": 1.963093322606597e-05,
      "loss": 1.0126,
      "step": 3670
    },
    {
      "epoch": 0.1850362027353178,
      "grad_norm": 43.75,
      "learning_rate": 1.9629927594529367e-05,
      "loss": 1.1099,
      "step": 3680
    },
    {
      "epoch": 0.18553901850362028,
      "grad_norm": 46.75,
      "learning_rate": 1.9628921962992762e-05,
      "loss": 1.1183,
      "step": 3690
    },
    {
      "epoch": 0.18604183427192278,
      "grad_norm": 13.75,
      "learning_rate": 1.9627916331456155e-05,
      "loss": 0.9883,
      "step": 3700
    },
    {
      "epoch": 0.18654465004022527,
      "grad_norm": 25.875,
      "learning_rate": 1.962691069991955e-05,
      "loss": 1.2724,
      "step": 3710
    },
    {
      "epoch": 0.18704746580852777,
      "grad_norm": 24.625,
      "learning_rate": 1.9625905068382947e-05,
      "loss": 1.1897,
      "step": 3720
    },
    {
      "epoch": 0.18755028157683024,
      "grad_norm": 6.1875,
      "learning_rate": 1.962489943684634e-05,
      "loss": 1.0065,
      "step": 3730
    },
    {
      "epoch": 0.18805309734513273,
      "grad_norm": 31.75,
      "learning_rate": 1.962389380530974e-05,
      "loss": 0.7861,
      "step": 3740
    },
    {
      "epoch": 0.18855591311343523,
      "grad_norm": 10.375,
      "learning_rate": 1.962288817377313e-05,
      "loss": 1.023,
      "step": 3750
    },
    {
      "epoch": 0.18905872888173772,
      "grad_norm": 44.75,
      "learning_rate": 1.9621882542236527e-05,
      "loss": 1.2087,
      "step": 3760
    },
    {
      "epoch": 0.18956154465004021,
      "grad_norm": 35.75,
      "learning_rate": 1.9620876910699923e-05,
      "loss": 1.0604,
      "step": 3770
    },
    {
      "epoch": 0.1900643604183427,
      "grad_norm": 12.75,
      "learning_rate": 1.9619871279163315e-05,
      "loss": 1.0656,
      "step": 3780
    },
    {
      "epoch": 0.1905671761866452,
      "grad_norm": 12.375,
      "learning_rate": 1.961886564762671e-05,
      "loss": 0.9752,
      "step": 3790
    },
    {
      "epoch": 0.1910699919549477,
      "grad_norm": 17.0,
      "learning_rate": 1.9617860016090107e-05,
      "loss": 1.2524,
      "step": 3800
    },
    {
      "epoch": 0.1915728077232502,
      "grad_norm": 19.375,
      "learning_rate": 1.96168543845535e-05,
      "loss": 0.7638,
      "step": 3810
    },
    {
      "epoch": 0.1920756234915527,
      "grad_norm": 26.75,
      "learning_rate": 1.96158487530169e-05,
      "loss": 1.0806,
      "step": 3820
    },
    {
      "epoch": 0.19257843925985518,
      "grad_norm": 17.125,
      "learning_rate": 1.961484312148029e-05,
      "loss": 0.9267,
      "step": 3830
    },
    {
      "epoch": 0.19308125502815768,
      "grad_norm": 6.09375,
      "learning_rate": 1.9613837489943687e-05,
      "loss": 1.0405,
      "step": 3840
    },
    {
      "epoch": 0.19358407079646017,
      "grad_norm": 10.5,
      "learning_rate": 1.9612831858407083e-05,
      "loss": 0.968,
      "step": 3850
    },
    {
      "epoch": 0.19408688656476267,
      "grad_norm": 52.25,
      "learning_rate": 1.9611826226870475e-05,
      "loss": 1.0611,
      "step": 3860
    },
    {
      "epoch": 0.19458970233306516,
      "grad_norm": 16.875,
      "learning_rate": 1.961082059533387e-05,
      "loss": 1.0277,
      "step": 3870
    },
    {
      "epoch": 0.19509251810136766,
      "grad_norm": 29.125,
      "learning_rate": 1.9609814963797267e-05,
      "loss": 1.0115,
      "step": 3880
    },
    {
      "epoch": 0.19559533386967015,
      "grad_norm": 17.125,
      "learning_rate": 1.960880933226066e-05,
      "loss": 0.7579,
      "step": 3890
    },
    {
      "epoch": 0.19609814963797265,
      "grad_norm": 12.3125,
      "learning_rate": 1.960780370072406e-05,
      "loss": 0.9264,
      "step": 3900
    },
    {
      "epoch": 0.19660096540627514,
      "grad_norm": 10.25,
      "learning_rate": 1.960679806918745e-05,
      "loss": 0.982,
      "step": 3910
    },
    {
      "epoch": 0.19710378117457764,
      "grad_norm": 17.375,
      "learning_rate": 1.9605792437650847e-05,
      "loss": 1.0946,
      "step": 3920
    },
    {
      "epoch": 0.19760659694288013,
      "grad_norm": 8.3125,
      "learning_rate": 1.9604786806114243e-05,
      "loss": 0.8287,
      "step": 3930
    },
    {
      "epoch": 0.19810941271118263,
      "grad_norm": 60.25,
      "learning_rate": 1.9603781174577636e-05,
      "loss": 0.6994,
      "step": 3940
    },
    {
      "epoch": 0.19861222847948512,
      "grad_norm": 25.375,
      "learning_rate": 1.960277554304103e-05,
      "loss": 1.2245,
      "step": 3950
    },
    {
      "epoch": 0.19911504424778761,
      "grad_norm": 8.5625,
      "learning_rate": 1.9601769911504427e-05,
      "loss": 0.9013,
      "step": 3960
    },
    {
      "epoch": 0.1996178600160901,
      "grad_norm": 27.5,
      "learning_rate": 1.960076427996782e-05,
      "loss": 1.1515,
      "step": 3970
    },
    {
      "epoch": 0.2001206757843926,
      "grad_norm": 10.25,
      "learning_rate": 1.9599758648431216e-05,
      "loss": 1.1107,
      "step": 3980
    },
    {
      "epoch": 0.2006234915526951,
      "grad_norm": 28.75,
      "learning_rate": 1.9598753016894612e-05,
      "loss": 1.2571,
      "step": 3990
    },
    {
      "epoch": 0.2011263073209976,
      "grad_norm": 33.5,
      "learning_rate": 1.9597747385358004e-05,
      "loss": 1.0971,
      "step": 4000
    },
    {
      "epoch": 0.2011263073209976,
      "eval_accuracy": 0.5077590480912246,
      "eval_loss": 1.097894310951233,
      "eval_runtime": 464.6177,
      "eval_samples_per_second": 86.824,
      "eval_steps_per_second": 86.824,
      "step": 4000
    },
    {
      "epoch": 0.2016291230893001,
      "grad_norm": 3.84375,
      "learning_rate": 1.9596741753821404e-05,
      "loss": 1.1303,
      "step": 4010
    },
    {
      "epoch": 0.20213193885760258,
      "grad_norm": 22.375,
      "learning_rate": 1.9595736122284796e-05,
      "loss": 1.0239,
      "step": 4020
    },
    {
      "epoch": 0.20263475462590508,
      "grad_norm": 16.625,
      "learning_rate": 1.9594730490748192e-05,
      "loss": 1.1429,
      "step": 4030
    },
    {
      "epoch": 0.20313757039420757,
      "grad_norm": 36.0,
      "learning_rate": 1.9593724859211588e-05,
      "loss": 0.7378,
      "step": 4040
    },
    {
      "epoch": 0.20364038616251007,
      "grad_norm": 28.375,
      "learning_rate": 1.959271922767498e-05,
      "loss": 0.969,
      "step": 4050
    },
    {
      "epoch": 0.20414320193081256,
      "grad_norm": 14.75,
      "learning_rate": 1.9591713596138376e-05,
      "loss": 0.9995,
      "step": 4060
    },
    {
      "epoch": 0.20464601769911506,
      "grad_norm": 20.125,
      "learning_rate": 1.9590707964601772e-05,
      "loss": 1.1259,
      "step": 4070
    },
    {
      "epoch": 0.20514883346741755,
      "grad_norm": 51.0,
      "learning_rate": 1.9589702333065164e-05,
      "loss": 1.1447,
      "step": 4080
    },
    {
      "epoch": 0.20565164923572002,
      "grad_norm": 23.875,
      "learning_rate": 1.9588696701528564e-05,
      "loss": 0.8061,
      "step": 4090
    },
    {
      "epoch": 0.2061544650040225,
      "grad_norm": 8.6875,
      "learning_rate": 1.9587691069991956e-05,
      "loss": 1.1893,
      "step": 4100
    },
    {
      "epoch": 0.206657280772325,
      "grad_norm": 22.375,
      "learning_rate": 1.9586685438455352e-05,
      "loss": 0.7757,
      "step": 4110
    },
    {
      "epoch": 0.2071600965406275,
      "grad_norm": 22.75,
      "learning_rate": 1.9585679806918748e-05,
      "loss": 1.3131,
      "step": 4120
    },
    {
      "epoch": 0.20766291230893,
      "grad_norm": 9.4375,
      "learning_rate": 1.958467417538214e-05,
      "loss": 0.9484,
      "step": 4130
    },
    {
      "epoch": 0.2081657280772325,
      "grad_norm": 19.875,
      "learning_rate": 1.9583668543845536e-05,
      "loss": 1.1217,
      "step": 4140
    },
    {
      "epoch": 0.208668543845535,
      "grad_norm": 21.25,
      "learning_rate": 1.9582662912308932e-05,
      "loss": 0.8891,
      "step": 4150
    },
    {
      "epoch": 0.20917135961383748,
      "grad_norm": 29.875,
      "learning_rate": 1.9581657280772325e-05,
      "loss": 1.356,
      "step": 4160
    },
    {
      "epoch": 0.20967417538213998,
      "grad_norm": 27.5,
      "learning_rate": 1.9580651649235724e-05,
      "loss": 0.953,
      "step": 4170
    },
    {
      "epoch": 0.21017699115044247,
      "grad_norm": 16.375,
      "learning_rate": 1.9579646017699117e-05,
      "loss": 1.2229,
      "step": 4180
    },
    {
      "epoch": 0.21067980691874497,
      "grad_norm": 10.8125,
      "learning_rate": 1.9578640386162512e-05,
      "loss": 0.8228,
      "step": 4190
    },
    {
      "epoch": 0.21118262268704746,
      "grad_norm": 38.0,
      "learning_rate": 1.9577634754625908e-05,
      "loss": 1.3557,
      "step": 4200
    },
    {
      "epoch": 0.21168543845534996,
      "grad_norm": 39.5,
      "learning_rate": 1.95766291230893e-05,
      "loss": 1.24,
      "step": 4210
    },
    {
      "epoch": 0.21218825422365245,
      "grad_norm": 35.0,
      "learning_rate": 1.9575623491552697e-05,
      "loss": 1.0844,
      "step": 4220
    },
    {
      "epoch": 0.21269106999195495,
      "grad_norm": 28.375,
      "learning_rate": 1.9574617860016093e-05,
      "loss": 1.1495,
      "step": 4230
    },
    {
      "epoch": 0.21319388576025744,
      "grad_norm": 18.75,
      "learning_rate": 1.9573612228479485e-05,
      "loss": 0.9143,
      "step": 4240
    },
    {
      "epoch": 0.21369670152855993,
      "grad_norm": 25.375,
      "learning_rate": 1.957260659694288e-05,
      "loss": 1.1959,
      "step": 4250
    },
    {
      "epoch": 0.21419951729686243,
      "grad_norm": 17.875,
      "learning_rate": 1.9571600965406277e-05,
      "loss": 1.0442,
      "step": 4260
    },
    {
      "epoch": 0.21470233306516492,
      "grad_norm": 13.25,
      "learning_rate": 1.957059533386967e-05,
      "loss": 1.0244,
      "step": 4270
    },
    {
      "epoch": 0.21520514883346742,
      "grad_norm": 21.0,
      "learning_rate": 1.956958970233307e-05,
      "loss": 1.0442,
      "step": 4280
    },
    {
      "epoch": 0.2157079646017699,
      "grad_norm": 15.375,
      "learning_rate": 1.956858407079646e-05,
      "loss": 0.861,
      "step": 4290
    },
    {
      "epoch": 0.2162107803700724,
      "grad_norm": 65.5,
      "learning_rate": 1.9567578439259857e-05,
      "loss": 1.4535,
      "step": 4300
    },
    {
      "epoch": 0.2167135961383749,
      "grad_norm": 23.25,
      "learning_rate": 1.9566572807723253e-05,
      "loss": 1.0114,
      "step": 4310
    },
    {
      "epoch": 0.2172164119066774,
      "grad_norm": 14.1875,
      "learning_rate": 1.9565567176186645e-05,
      "loss": 1.2991,
      "step": 4320
    },
    {
      "epoch": 0.2177192276749799,
      "grad_norm": 48.75,
      "learning_rate": 1.956456154465004e-05,
      "loss": 1.323,
      "step": 4330
    },
    {
      "epoch": 0.2182220434432824,
      "grad_norm": 25.75,
      "learning_rate": 1.9563555913113437e-05,
      "loss": 1.0964,
      "step": 4340
    },
    {
      "epoch": 0.21872485921158488,
      "grad_norm": 12.3125,
      "learning_rate": 1.956255028157683e-05,
      "loss": 1.1695,
      "step": 4350
    },
    {
      "epoch": 0.21922767497988738,
      "grad_norm": 28.625,
      "learning_rate": 1.956154465004023e-05,
      "loss": 1.1963,
      "step": 4360
    },
    {
      "epoch": 0.21973049074818987,
      "grad_norm": 11.9375,
      "learning_rate": 1.956053901850362e-05,
      "loss": 0.8997,
      "step": 4370
    },
    {
      "epoch": 0.22023330651649237,
      "grad_norm": 18.5,
      "learning_rate": 1.9559533386967017e-05,
      "loss": 1.2917,
      "step": 4380
    },
    {
      "epoch": 0.22073612228479486,
      "grad_norm": 6.96875,
      "learning_rate": 1.9558527755430413e-05,
      "loss": 0.684,
      "step": 4390
    },
    {
      "epoch": 0.22123893805309736,
      "grad_norm": 22.25,
      "learning_rate": 1.9557522123893806e-05,
      "loss": 0.9889,
      "step": 4400
    },
    {
      "epoch": 0.22174175382139985,
      "grad_norm": 39.25,
      "learning_rate": 1.95565164923572e-05,
      "loss": 0.9339,
      "step": 4410
    },
    {
      "epoch": 0.22224456958970235,
      "grad_norm": 46.25,
      "learning_rate": 1.9555510860820597e-05,
      "loss": 0.9435,
      "step": 4420
    },
    {
      "epoch": 0.22274738535800484,
      "grad_norm": 36.75,
      "learning_rate": 1.955450522928399e-05,
      "loss": 1.0856,
      "step": 4430
    },
    {
      "epoch": 0.2232502011263073,
      "grad_norm": 15.625,
      "learning_rate": 1.955349959774739e-05,
      "loss": 0.9348,
      "step": 4440
    },
    {
      "epoch": 0.2237530168946098,
      "grad_norm": 27.25,
      "learning_rate": 1.955249396621078e-05,
      "loss": 0.9071,
      "step": 4450
    },
    {
      "epoch": 0.2242558326629123,
      "grad_norm": 25.75,
      "learning_rate": 1.9551488334674177e-05,
      "loss": 0.9518,
      "step": 4460
    },
    {
      "epoch": 0.2247586484312148,
      "grad_norm": 38.25,
      "learning_rate": 1.9550482703137573e-05,
      "loss": 1.0416,
      "step": 4470
    },
    {
      "epoch": 0.2252614641995173,
      "grad_norm": 7.625,
      "learning_rate": 1.9549477071600966e-05,
      "loss": 1.0962,
      "step": 4480
    },
    {
      "epoch": 0.22576427996781978,
      "grad_norm": 47.5,
      "learning_rate": 1.954847144006436e-05,
      "loss": 1.1588,
      "step": 4490
    },
    {
      "epoch": 0.22626709573612228,
      "grad_norm": 31.25,
      "learning_rate": 1.9547465808527758e-05,
      "loss": 1.0928,
      "step": 4500
    },
    {
      "epoch": 0.22626709573612228,
      "eval_accuracy": 0.5092464055528012,
      "eval_loss": 1.0858546495437622,
      "eval_runtime": 465.0066,
      "eval_samples_per_second": 86.751,
      "eval_steps_per_second": 86.751,
      "step": 4500
    },
    {
      "epoch": 0.22676991150442477,
      "grad_norm": 42.75,
      "learning_rate": 1.954646017699115e-05,
      "loss": 0.8462,
      "step": 4510
    },
    {
      "epoch": 0.22727272727272727,
      "grad_norm": 10.625,
      "learning_rate": 1.9545454545454546e-05,
      "loss": 1.0109,
      "step": 4520
    },
    {
      "epoch": 0.22777554304102976,
      "grad_norm": 16.375,
      "learning_rate": 1.9544448913917942e-05,
      "loss": 0.9981,
      "step": 4530
    },
    {
      "epoch": 0.22827835880933225,
      "grad_norm": 23.5,
      "learning_rate": 1.9543443282381338e-05,
      "loss": 0.9579,
      "step": 4540
    },
    {
      "epoch": 0.22878117457763475,
      "grad_norm": 6.0625,
      "learning_rate": 1.9542437650844734e-05,
      "loss": 1.1276,
      "step": 4550
    },
    {
      "epoch": 0.22928399034593724,
      "grad_norm": 29.375,
      "learning_rate": 1.9541432019308126e-05,
      "loss": 1.0457,
      "step": 4560
    },
    {
      "epoch": 0.22978680611423974,
      "grad_norm": 39.5,
      "learning_rate": 1.9540426387771522e-05,
      "loss": 1.1814,
      "step": 4570
    },
    {
      "epoch": 0.23028962188254223,
      "grad_norm": 11.0625,
      "learning_rate": 1.9539420756234918e-05,
      "loss": 1.5126,
      "step": 4580
    },
    {
      "epoch": 0.23079243765084473,
      "grad_norm": 26.0,
      "learning_rate": 1.953841512469831e-05,
      "loss": 0.8664,
      "step": 4590
    },
    {
      "epoch": 0.23129525341914722,
      "grad_norm": 14.4375,
      "learning_rate": 1.9537409493161706e-05,
      "loss": 1.2398,
      "step": 4600
    },
    {
      "epoch": 0.23179806918744972,
      "grad_norm": 25.25,
      "learning_rate": 1.9536403861625102e-05,
      "loss": 1.1701,
      "step": 4610
    },
    {
      "epoch": 0.2323008849557522,
      "grad_norm": 14.125,
      "learning_rate": 1.9535398230088498e-05,
      "loss": 1.1474,
      "step": 4620
    },
    {
      "epoch": 0.2328037007240547,
      "grad_norm": 38.0,
      "learning_rate": 1.9534392598551894e-05,
      "loss": 0.9085,
      "step": 4630
    },
    {
      "epoch": 0.2333065164923572,
      "grad_norm": 63.0,
      "learning_rate": 1.9533386967015286e-05,
      "loss": 0.9802,
      "step": 4640
    },
    {
      "epoch": 0.2338093322606597,
      "grad_norm": 10.6875,
      "learning_rate": 1.9532381335478682e-05,
      "loss": 0.9867,
      "step": 4650
    },
    {
      "epoch": 0.2343121480289622,
      "grad_norm": 7.9375,
      "learning_rate": 1.9531375703942078e-05,
      "loss": 0.8567,
      "step": 4660
    },
    {
      "epoch": 0.2348149637972647,
      "grad_norm": 14.3125,
      "learning_rate": 1.953037007240547e-05,
      "loss": 0.9659,
      "step": 4670
    },
    {
      "epoch": 0.23531777956556718,
      "grad_norm": 22.125,
      "learning_rate": 1.9529364440868866e-05,
      "loss": 0.9663,
      "step": 4680
    },
    {
      "epoch": 0.23582059533386968,
      "grad_norm": 12.3125,
      "learning_rate": 1.9528358809332262e-05,
      "loss": 1.0533,
      "step": 4690
    },
    {
      "epoch": 0.23632341110217217,
      "grad_norm": 41.75,
      "learning_rate": 1.9527353177795658e-05,
      "loss": 1.3924,
      "step": 4700
    },
    {
      "epoch": 0.23682622687047467,
      "grad_norm": 20.25,
      "learning_rate": 1.9526347546259054e-05,
      "loss": 0.8891,
      "step": 4710
    },
    {
      "epoch": 0.23732904263877716,
      "grad_norm": 7.84375,
      "learning_rate": 1.9525341914722447e-05,
      "loss": 1.4057,
      "step": 4720
    },
    {
      "epoch": 0.23783185840707965,
      "grad_norm": 24.25,
      "learning_rate": 1.9524336283185842e-05,
      "loss": 0.9,
      "step": 4730
    },
    {
      "epoch": 0.23833467417538215,
      "grad_norm": 16.0,
      "learning_rate": 1.9523330651649238e-05,
      "loss": 0.7198,
      "step": 4740
    },
    {
      "epoch": 0.23883748994368464,
      "grad_norm": 52.25,
      "learning_rate": 1.952232502011263e-05,
      "loss": 1.1407,
      "step": 4750
    },
    {
      "epoch": 0.23934030571198714,
      "grad_norm": 24.25,
      "learning_rate": 1.9521319388576027e-05,
      "loss": 0.9783,
      "step": 4760
    },
    {
      "epoch": 0.23984312148028963,
      "grad_norm": 16.625,
      "learning_rate": 1.9520313757039423e-05,
      "loss": 0.7954,
      "step": 4770
    },
    {
      "epoch": 0.24034593724859213,
      "grad_norm": 36.0,
      "learning_rate": 1.951930812550282e-05,
      "loss": 0.7206,
      "step": 4780
    },
    {
      "epoch": 0.24084875301689462,
      "grad_norm": 47.0,
      "learning_rate": 1.951830249396621e-05,
      "loss": 1.1326,
      "step": 4790
    },
    {
      "epoch": 0.2413515687851971,
      "grad_norm": 11.25,
      "learning_rate": 1.9517296862429607e-05,
      "loss": 1.0167,
      "step": 4800
    },
    {
      "epoch": 0.24185438455349959,
      "grad_norm": 24.875,
      "learning_rate": 1.9516291230893003e-05,
      "loss": 0.9624,
      "step": 4810
    },
    {
      "epoch": 0.24235720032180208,
      "grad_norm": 20.125,
      "learning_rate": 1.95152855993564e-05,
      "loss": 1.3877,
      "step": 4820
    },
    {
      "epoch": 0.24286001609010457,
      "grad_norm": 8.8125,
      "learning_rate": 1.951427996781979e-05,
      "loss": 1.1241,
      "step": 4830
    },
    {
      "epoch": 0.24336283185840707,
      "grad_norm": 11.4375,
      "learning_rate": 1.9513274336283187e-05,
      "loss": 1.27,
      "step": 4840
    },
    {
      "epoch": 0.24386564762670956,
      "grad_norm": 31.625,
      "learning_rate": 1.9512268704746583e-05,
      "loss": 1.2343,
      "step": 4850
    },
    {
      "epoch": 0.24436846339501206,
      "grad_norm": 34.5,
      "learning_rate": 1.951126307320998e-05,
      "loss": 1.0984,
      "step": 4860
    },
    {
      "epoch": 0.24487127916331455,
      "grad_norm": 15.875,
      "learning_rate": 1.951025744167337e-05,
      "loss": 1.3032,
      "step": 4870
    },
    {
      "epoch": 0.24537409493161705,
      "grad_norm": 59.75,
      "learning_rate": 1.9509251810136767e-05,
      "loss": 1.1212,
      "step": 4880
    },
    {
      "epoch": 0.24587691069991954,
      "grad_norm": 60.0,
      "learning_rate": 1.9508246178600163e-05,
      "loss": 1.2908,
      "step": 4890
    },
    {
      "epoch": 0.24637972646822204,
      "grad_norm": 23.125,
      "learning_rate": 1.950724054706356e-05,
      "loss": 0.9796,
      "step": 4900
    },
    {
      "epoch": 0.24688254223652453,
      "grad_norm": 6.875,
      "learning_rate": 1.950623491552695e-05,
      "loss": 0.8464,
      "step": 4910
    },
    {
      "epoch": 0.24738535800482703,
      "grad_norm": 31.25,
      "learning_rate": 1.9505229283990347e-05,
      "loss": 1.0916,
      "step": 4920
    },
    {
      "epoch": 0.24788817377312952,
      "grad_norm": 8.8125,
      "learning_rate": 1.9504223652453743e-05,
      "loss": 0.9614,
      "step": 4930
    },
    {
      "epoch": 0.24839098954143202,
      "grad_norm": 17.0,
      "learning_rate": 1.950321802091714e-05,
      "loss": 0.9078,
      "step": 4940
    },
    {
      "epoch": 0.2488938053097345,
      "grad_norm": 26.0,
      "learning_rate": 1.950221238938053e-05,
      "loss": 1.055,
      "step": 4950
    },
    {
      "epoch": 0.249396621078037,
      "grad_norm": 35.75,
      "learning_rate": 1.9501206757843927e-05,
      "loss": 1.2193,
      "step": 4960
    },
    {
      "epoch": 0.2498994368463395,
      "grad_norm": 55.75,
      "learning_rate": 1.9500201126307323e-05,
      "loss": 1.2054,
      "step": 4970
    },
    {
      "epoch": 0.250402252614642,
      "grad_norm": 28.0,
      "learning_rate": 1.949919549477072e-05,
      "loss": 1.0101,
      "step": 4980
    },
    {
      "epoch": 0.25090506838294446,
      "grad_norm": 32.75,
      "learning_rate": 1.949818986323411e-05,
      "loss": 1.0498,
      "step": 4990
    },
    {
      "epoch": 0.251407884151247,
      "grad_norm": 19.0,
      "learning_rate": 1.9497184231697507e-05,
      "loss": 1.1074,
      "step": 5000
    },
    {
      "epoch": 0.251407884151247,
      "eval_accuracy": 0.5091224590976698,
      "eval_loss": 1.0767416954040527,
      "eval_runtime": 464.9769,
      "eval_samples_per_second": 86.757,
      "eval_steps_per_second": 86.757,
      "step": 5000
    },
    {
      "epoch": 0.25191069991954945,
      "grad_norm": 30.0,
      "learning_rate": 1.9496178600160903e-05,
      "loss": 0.7497,
      "step": 5010
    },
    {
      "epoch": 0.252413515687852,
      "grad_norm": 33.25,
      "learning_rate": 1.94951729686243e-05,
      "loss": 0.9702,
      "step": 5020
    },
    {
      "epoch": 0.25291633145615444,
      "grad_norm": 6.59375,
      "learning_rate": 1.949416733708769e-05,
      "loss": 1.0224,
      "step": 5030
    },
    {
      "epoch": 0.25341914722445696,
      "grad_norm": 121.0,
      "learning_rate": 1.9493161705551088e-05,
      "loss": 1.2505,
      "step": 5040
    },
    {
      "epoch": 0.25392196299275943,
      "grad_norm": 20.75,
      "learning_rate": 1.9492156074014483e-05,
      "loss": 0.9511,
      "step": 5050
    },
    {
      "epoch": 0.25442477876106195,
      "grad_norm": 9.5625,
      "learning_rate": 1.9491150442477876e-05,
      "loss": 1.1465,
      "step": 5060
    },
    {
      "epoch": 0.2549275945293644,
      "grad_norm": 41.25,
      "learning_rate": 1.9490144810941272e-05,
      "loss": 1.0936,
      "step": 5070
    },
    {
      "epoch": 0.25543041029766694,
      "grad_norm": 24.75,
      "learning_rate": 1.9489139179404668e-05,
      "loss": 1.0785,
      "step": 5080
    },
    {
      "epoch": 0.2559332260659694,
      "grad_norm": 13.6875,
      "learning_rate": 1.9488133547868064e-05,
      "loss": 1.1495,
      "step": 5090
    },
    {
      "epoch": 0.25643604183427193,
      "grad_norm": 34.25,
      "learning_rate": 1.948712791633146e-05,
      "loss": 0.8534,
      "step": 5100
    },
    {
      "epoch": 0.2569388576025744,
      "grad_norm": 27.625,
      "learning_rate": 1.9486122284794852e-05,
      "loss": 1.2319,
      "step": 5110
    },
    {
      "epoch": 0.2574416733708769,
      "grad_norm": 24.5,
      "learning_rate": 1.9485116653258248e-05,
      "loss": 1.2113,
      "step": 5120
    },
    {
      "epoch": 0.2579444891391794,
      "grad_norm": 53.0,
      "learning_rate": 1.9484111021721644e-05,
      "loss": 0.9822,
      "step": 5130
    },
    {
      "epoch": 0.2584473049074819,
      "grad_norm": 43.0,
      "learning_rate": 1.9483105390185036e-05,
      "loss": 1.168,
      "step": 5140
    },
    {
      "epoch": 0.2589501206757844,
      "grad_norm": 12.1875,
      "learning_rate": 1.9482099758648432e-05,
      "loss": 1.1717,
      "step": 5150
    },
    {
      "epoch": 0.2594529364440869,
      "grad_norm": 52.0,
      "learning_rate": 1.9481094127111828e-05,
      "loss": 1.0938,
      "step": 5160
    },
    {
      "epoch": 0.25995575221238937,
      "grad_norm": 26.875,
      "learning_rate": 1.9480088495575224e-05,
      "loss": 0.9132,
      "step": 5170
    },
    {
      "epoch": 0.2604585679806919,
      "grad_norm": 78.5,
      "learning_rate": 1.947908286403862e-05,
      "loss": 1.2098,
      "step": 5180
    },
    {
      "epoch": 0.26096138374899436,
      "grad_norm": 36.75,
      "learning_rate": 1.9478077232502012e-05,
      "loss": 1.2515,
      "step": 5190
    },
    {
      "epoch": 0.2614641995172969,
      "grad_norm": 24.5,
      "learning_rate": 1.9477071600965408e-05,
      "loss": 0.9122,
      "step": 5200
    },
    {
      "epoch": 0.26196701528559935,
      "grad_norm": 7.53125,
      "learning_rate": 1.9476065969428804e-05,
      "loss": 1.2771,
      "step": 5210
    },
    {
      "epoch": 0.26246983105390187,
      "grad_norm": 13.25,
      "learning_rate": 1.9475060337892196e-05,
      "loss": 1.1985,
      "step": 5220
    },
    {
      "epoch": 0.26297264682220434,
      "grad_norm": 43.0,
      "learning_rate": 1.9474054706355592e-05,
      "loss": 1.1263,
      "step": 5230
    },
    {
      "epoch": 0.26347546259050686,
      "grad_norm": 11.4375,
      "learning_rate": 1.9473049074818988e-05,
      "loss": 1.2956,
      "step": 5240
    },
    {
      "epoch": 0.2639782783588093,
      "grad_norm": 53.5,
      "learning_rate": 1.9472043443282384e-05,
      "loss": 1.0463,
      "step": 5250
    },
    {
      "epoch": 0.26448109412711185,
      "grad_norm": 17.375,
      "learning_rate": 1.947103781174578e-05,
      "loss": 0.8553,
      "step": 5260
    },
    {
      "epoch": 0.2649839098954143,
      "grad_norm": 7.1875,
      "learning_rate": 1.9470032180209172e-05,
      "loss": 1.4328,
      "step": 5270
    },
    {
      "epoch": 0.26548672566371684,
      "grad_norm": 13.875,
      "learning_rate": 1.946902654867257e-05,
      "loss": 0.9863,
      "step": 5280
    },
    {
      "epoch": 0.2659895414320193,
      "grad_norm": 26.625,
      "learning_rate": 1.9468020917135964e-05,
      "loss": 1.0275,
      "step": 5290
    },
    {
      "epoch": 0.2664923572003218,
      "grad_norm": 18.25,
      "learning_rate": 1.9467015285599357e-05,
      "loss": 1.0513,
      "step": 5300
    },
    {
      "epoch": 0.2669951729686243,
      "grad_norm": 23.25,
      "learning_rate": 1.9466009654062753e-05,
      "loss": 0.8166,
      "step": 5310
    },
    {
      "epoch": 0.2674979887369268,
      "grad_norm": 50.0,
      "learning_rate": 1.946500402252615e-05,
      "loss": 0.9392,
      "step": 5320
    },
    {
      "epoch": 0.2680008045052293,
      "grad_norm": 64.5,
      "learning_rate": 1.946399839098954e-05,
      "loss": 0.8568,
      "step": 5330
    },
    {
      "epoch": 0.26850362027353175,
      "grad_norm": 19.375,
      "learning_rate": 1.946299275945294e-05,
      "loss": 0.9158,
      "step": 5340
    },
    {
      "epoch": 0.2690064360418343,
      "grad_norm": 12.3125,
      "learning_rate": 1.9461987127916333e-05,
      "loss": 1.0967,
      "step": 5350
    },
    {
      "epoch": 0.26950925181013674,
      "grad_norm": 51.75,
      "learning_rate": 1.946098149637973e-05,
      "loss": 1.1054,
      "step": 5360
    },
    {
      "epoch": 0.27001206757843926,
      "grad_norm": 6.40625,
      "learning_rate": 1.9459975864843124e-05,
      "loss": 1.2348,
      "step": 5370
    },
    {
      "epoch": 0.27051488334674173,
      "grad_norm": 14.9375,
      "learning_rate": 1.9458970233306517e-05,
      "loss": 0.613,
      "step": 5380
    },
    {
      "epoch": 0.27101769911504425,
      "grad_norm": 40.5,
      "learning_rate": 1.9457964601769913e-05,
      "loss": 0.9572,
      "step": 5390
    },
    {
      "epoch": 0.2715205148833467,
      "grad_norm": 56.75,
      "learning_rate": 1.945695897023331e-05,
      "loss": 0.7692,
      "step": 5400
    },
    {
      "epoch": 0.27202333065164924,
      "grad_norm": 25.75,
      "learning_rate": 1.94559533386967e-05,
      "loss": 0.8777,
      "step": 5410
    },
    {
      "epoch": 0.2725261464199517,
      "grad_norm": 16.625,
      "learning_rate": 1.94549477071601e-05,
      "loss": 0.9062,
      "step": 5420
    },
    {
      "epoch": 0.27302896218825423,
      "grad_norm": 50.5,
      "learning_rate": 1.9453942075623493e-05,
      "loss": 1.1149,
      "step": 5430
    },
    {
      "epoch": 0.2735317779565567,
      "grad_norm": 24.625,
      "learning_rate": 1.945293644408689e-05,
      "loss": 0.9286,
      "step": 5440
    },
    {
      "epoch": 0.2740345937248592,
      "grad_norm": 14.5,
      "learning_rate": 1.9451930812550285e-05,
      "loss": 1.0962,
      "step": 5450
    },
    {
      "epoch": 0.2745374094931617,
      "grad_norm": 16.75,
      "learning_rate": 1.9450925181013677e-05,
      "loss": 1.1608,
      "step": 5460
    },
    {
      "epoch": 0.2750402252614642,
      "grad_norm": 51.75,
      "learning_rate": 1.9449919549477073e-05,
      "loss": 1.1965,
      "step": 5470
    },
    {
      "epoch": 0.2755430410297667,
      "grad_norm": 6.3125,
      "learning_rate": 1.944891391794047e-05,
      "loss": 1.126,
      "step": 5480
    },
    {
      "epoch": 0.2760458567980692,
      "grad_norm": 43.25,
      "learning_rate": 1.944790828640386e-05,
      "loss": 0.8564,
      "step": 5490
    },
    {
      "epoch": 0.27654867256637167,
      "grad_norm": 28.5,
      "learning_rate": 1.944690265486726e-05,
      "loss": 1.4304,
      "step": 5500
    },
    {
      "epoch": 0.27654867256637167,
      "eval_accuracy": 0.5097421913733268,
      "eval_loss": 1.0700719356536865,
      "eval_runtime": 464.6496,
      "eval_samples_per_second": 86.818,
      "eval_steps_per_second": 86.818,
      "step": 5500
    },
    {
      "epoch": 0.2770514883346742,
      "grad_norm": 47.25,
      "learning_rate": 1.9445897023330653e-05,
      "loss": 0.8632,
      "step": 5510
    },
    {
      "epoch": 0.27755430410297666,
      "grad_norm": 6.96875,
      "learning_rate": 1.9444891391794046e-05,
      "loss": 0.9396,
      "step": 5520
    },
    {
      "epoch": 0.2780571198712792,
      "grad_norm": 35.0,
      "learning_rate": 1.9443885760257445e-05,
      "loss": 0.9021,
      "step": 5530
    },
    {
      "epoch": 0.27855993563958165,
      "grad_norm": 13.5,
      "learning_rate": 1.9442880128720837e-05,
      "loss": 0.9664,
      "step": 5540
    },
    {
      "epoch": 0.27906275140788417,
      "grad_norm": 31.25,
      "learning_rate": 1.9441874497184233e-05,
      "loss": 1.5082,
      "step": 5550
    },
    {
      "epoch": 0.27956556717618664,
      "grad_norm": 39.75,
      "learning_rate": 1.944086886564763e-05,
      "loss": 1.3065,
      "step": 5560
    },
    {
      "epoch": 0.28006838294448916,
      "grad_norm": 22.125,
      "learning_rate": 1.9439863234111022e-05,
      "loss": 1.3688,
      "step": 5570
    },
    {
      "epoch": 0.2805711987127916,
      "grad_norm": 37.75,
      "learning_rate": 1.9438857602574418e-05,
      "loss": 0.8464,
      "step": 5580
    },
    {
      "epoch": 0.28107401448109415,
      "grad_norm": 19.625,
      "learning_rate": 1.9437851971037813e-05,
      "loss": 1.3876,
      "step": 5590
    },
    {
      "epoch": 0.2815768302493966,
      "grad_norm": 8.5,
      "learning_rate": 1.9436846339501206e-05,
      "loss": 0.9045,
      "step": 5600
    },
    {
      "epoch": 0.28207964601769914,
      "grad_norm": 5.28125,
      "learning_rate": 1.9435840707964605e-05,
      "loss": 0.9288,
      "step": 5610
    },
    {
      "epoch": 0.2825824617860016,
      "grad_norm": 36.0,
      "learning_rate": 1.9434835076427998e-05,
      "loss": 0.8522,
      "step": 5620
    },
    {
      "epoch": 0.2830852775543041,
      "grad_norm": 12.3125,
      "learning_rate": 1.9433829444891394e-05,
      "loss": 0.9965,
      "step": 5630
    },
    {
      "epoch": 0.2835880933226066,
      "grad_norm": 7.71875,
      "learning_rate": 1.943282381335479e-05,
      "loss": 0.8793,
      "step": 5640
    },
    {
      "epoch": 0.2840909090909091,
      "grad_norm": 3.859375,
      "learning_rate": 1.9431818181818182e-05,
      "loss": 0.8295,
      "step": 5650
    },
    {
      "epoch": 0.2845937248592116,
      "grad_norm": 17.875,
      "learning_rate": 1.9430812550281578e-05,
      "loss": 1.0257,
      "step": 5660
    },
    {
      "epoch": 0.2850965406275141,
      "grad_norm": 23.625,
      "learning_rate": 1.9429806918744974e-05,
      "loss": 1.0378,
      "step": 5670
    },
    {
      "epoch": 0.2855993563958166,
      "grad_norm": 23.125,
      "learning_rate": 1.9428801287208366e-05,
      "loss": 0.9957,
      "step": 5680
    },
    {
      "epoch": 0.28610217216411904,
      "grad_norm": 27.625,
      "learning_rate": 1.9427795655671765e-05,
      "loss": 0.9428,
      "step": 5690
    },
    {
      "epoch": 0.28660498793242156,
      "grad_norm": 14.8125,
      "learning_rate": 1.9426790024135158e-05,
      "loss": 0.8269,
      "step": 5700
    },
    {
      "epoch": 0.28710780370072403,
      "grad_norm": 10.3125,
      "learning_rate": 1.9425784392598554e-05,
      "loss": 1.0813,
      "step": 5710
    },
    {
      "epoch": 0.28761061946902655,
      "grad_norm": 62.0,
      "learning_rate": 1.942477876106195e-05,
      "loss": 0.9799,
      "step": 5720
    },
    {
      "epoch": 0.288113435237329,
      "grad_norm": 51.25,
      "learning_rate": 1.9423773129525342e-05,
      "loss": 0.9181,
      "step": 5730
    },
    {
      "epoch": 0.28861625100563154,
      "grad_norm": 9.5,
      "learning_rate": 1.9422767497988738e-05,
      "loss": 0.9958,
      "step": 5740
    },
    {
      "epoch": 0.289119066773934,
      "grad_norm": 59.0,
      "learning_rate": 1.9421761866452134e-05,
      "loss": 1.1421,
      "step": 5750
    },
    {
      "epoch": 0.28962188254223653,
      "grad_norm": 52.5,
      "learning_rate": 1.9420756234915526e-05,
      "loss": 1.0733,
      "step": 5760
    },
    {
      "epoch": 0.290124698310539,
      "grad_norm": 25.625,
      "learning_rate": 1.9419750603378922e-05,
      "loss": 1.0999,
      "step": 5770
    },
    {
      "epoch": 0.2906275140788415,
      "grad_norm": 20.625,
      "learning_rate": 1.9418744971842318e-05,
      "loss": 1.2945,
      "step": 5780
    },
    {
      "epoch": 0.291130329847144,
      "grad_norm": 29.125,
      "learning_rate": 1.9417739340305714e-05,
      "loss": 1.2831,
      "step": 5790
    },
    {
      "epoch": 0.2916331456154465,
      "grad_norm": 35.0,
      "learning_rate": 1.941673370876911e-05,
      "loss": 0.8187,
      "step": 5800
    },
    {
      "epoch": 0.292135961383749,
      "grad_norm": 7.09375,
      "learning_rate": 1.9415728077232502e-05,
      "loss": 0.9297,
      "step": 5810
    },
    {
      "epoch": 0.2926387771520515,
      "grad_norm": 18.5,
      "learning_rate": 1.94147224456959e-05,
      "loss": 1.0773,
      "step": 5820
    },
    {
      "epoch": 0.29314159292035397,
      "grad_norm": 30.75,
      "learning_rate": 1.9413716814159294e-05,
      "loss": 1.1129,
      "step": 5830
    },
    {
      "epoch": 0.2936444086886565,
      "grad_norm": 14.5,
      "learning_rate": 1.9412711182622687e-05,
      "loss": 1.1675,
      "step": 5840
    },
    {
      "epoch": 0.29414722445695896,
      "grad_norm": 40.25,
      "learning_rate": 1.9411705551086083e-05,
      "loss": 0.9529,
      "step": 5850
    },
    {
      "epoch": 0.2946500402252615,
      "grad_norm": 23.375,
      "learning_rate": 1.941069991954948e-05,
      "loss": 1.122,
      "step": 5860
    },
    {
      "epoch": 0.29515285599356395,
      "grad_norm": 25.5,
      "learning_rate": 1.9409694288012874e-05,
      "loss": 0.8783,
      "step": 5870
    },
    {
      "epoch": 0.29565567176186647,
      "grad_norm": 18.125,
      "learning_rate": 1.940868865647627e-05,
      "loss": 1.1482,
      "step": 5880
    },
    {
      "epoch": 0.29615848753016893,
      "grad_norm": 9.6875,
      "learning_rate": 1.9407683024939663e-05,
      "loss": 1.1647,
      "step": 5890
    },
    {
      "epoch": 0.29666130329847146,
      "grad_norm": 18.875,
      "learning_rate": 1.940667739340306e-05,
      "loss": 1.0886,
      "step": 5900
    },
    {
      "epoch": 0.2971641190667739,
      "grad_norm": 27.375,
      "learning_rate": 1.9405671761866454e-05,
      "loss": 0.9522,
      "step": 5910
    },
    {
      "epoch": 0.29766693483507645,
      "grad_norm": 27.75,
      "learning_rate": 1.9404666130329847e-05,
      "loss": 1.321,
      "step": 5920
    },
    {
      "epoch": 0.2981697506033789,
      "grad_norm": 38.75,
      "learning_rate": 1.9403660498793243e-05,
      "loss": 0.8669,
      "step": 5930
    },
    {
      "epoch": 0.29867256637168144,
      "grad_norm": 56.0,
      "learning_rate": 1.940265486725664e-05,
      "loss": 1.1234,
      "step": 5940
    },
    {
      "epoch": 0.2991753821399839,
      "grad_norm": 15.5,
      "learning_rate": 1.9401649235720035e-05,
      "loss": 1.1081,
      "step": 5950
    },
    {
      "epoch": 0.2996781979082864,
      "grad_norm": 30.25,
      "learning_rate": 1.940064360418343e-05,
      "loss": 0.8737,
      "step": 5960
    },
    {
      "epoch": 0.3001810136765889,
      "grad_norm": 17.5,
      "learning_rate": 1.9399637972646823e-05,
      "loss": 0.9869,
      "step": 5970
    },
    {
      "epoch": 0.3006838294448914,
      "grad_norm": 33.0,
      "learning_rate": 1.939863234111022e-05,
      "loss": 1.0905,
      "step": 5980
    },
    {
      "epoch": 0.3011866452131939,
      "grad_norm": 11.5625,
      "learning_rate": 1.9397626709573615e-05,
      "loss": 0.9725,
      "step": 5990
    },
    {
      "epoch": 0.3016894609814964,
      "grad_norm": 57.0,
      "learning_rate": 1.9396621078037007e-05,
      "loss": 1.0491,
      "step": 6000
    },
    {
      "epoch": 0.3016894609814964,
      "eval_accuracy": 0.5098909271194844,
      "eval_loss": 1.0633625984191895,
      "eval_runtime": 465.0206,
      "eval_samples_per_second": 86.749,
      "eval_steps_per_second": 86.749,
      "step": 6000
    },
    {
      "epoch": 0.30219227674979887,
      "grad_norm": 28.25,
      "learning_rate": 1.9395615446500403e-05,
      "loss": 0.9322,
      "step": 6010
    },
    {
      "epoch": 0.3026950925181014,
      "grad_norm": 12.3125,
      "learning_rate": 1.93946098149638e-05,
      "loss": 0.8184,
      "step": 6020
    },
    {
      "epoch": 0.30319790828640386,
      "grad_norm": 19.625,
      "learning_rate": 1.9393604183427195e-05,
      "loss": 1.1346,
      "step": 6030
    },
    {
      "epoch": 0.30370072405470633,
      "grad_norm": 6.53125,
      "learning_rate": 1.9392598551890587e-05,
      "loss": 0.8971,
      "step": 6040
    },
    {
      "epoch": 0.30420353982300885,
      "grad_norm": 16.875,
      "learning_rate": 1.9391592920353983e-05,
      "loss": 0.8224,
      "step": 6050
    },
    {
      "epoch": 0.3047063555913113,
      "grad_norm": 9.6875,
      "learning_rate": 1.939058728881738e-05,
      "loss": 0.9422,
      "step": 6060
    },
    {
      "epoch": 0.30520917135961384,
      "grad_norm": 8.5625,
      "learning_rate": 1.9389581657280775e-05,
      "loss": 1.1874,
      "step": 6070
    },
    {
      "epoch": 0.3057119871279163,
      "grad_norm": 6.71875,
      "learning_rate": 1.9388576025744167e-05,
      "loss": 0.9917,
      "step": 6080
    },
    {
      "epoch": 0.30621480289621883,
      "grad_norm": 23.125,
      "learning_rate": 1.9387570394207563e-05,
      "loss": 0.8756,
      "step": 6090
    },
    {
      "epoch": 0.3067176186645213,
      "grad_norm": 7.21875,
      "learning_rate": 1.938656476267096e-05,
      "loss": 0.9201,
      "step": 6100
    },
    {
      "epoch": 0.3072204344328238,
      "grad_norm": 47.0,
      "learning_rate": 1.9385559131134355e-05,
      "loss": 0.9502,
      "step": 6110
    },
    {
      "epoch": 0.3077232502011263,
      "grad_norm": 4.625,
      "learning_rate": 1.9384553499597748e-05,
      "loss": 0.9943,
      "step": 6120
    },
    {
      "epoch": 0.3082260659694288,
      "grad_norm": 18.5,
      "learning_rate": 1.9383547868061143e-05,
      "loss": 1.2862,
      "step": 6130
    },
    {
      "epoch": 0.3087288817377313,
      "grad_norm": 40.5,
      "learning_rate": 1.938254223652454e-05,
      "loss": 1.1277,
      "step": 6140
    },
    {
      "epoch": 0.3092316975060338,
      "grad_norm": 57.5,
      "learning_rate": 1.9381536604987935e-05,
      "loss": 1.1259,
      "step": 6150
    },
    {
      "epoch": 0.30973451327433627,
      "grad_norm": 21.5,
      "learning_rate": 1.9380530973451328e-05,
      "loss": 0.8125,
      "step": 6160
    },
    {
      "epoch": 0.3102373290426388,
      "grad_norm": 5.03125,
      "learning_rate": 1.9379525341914724e-05,
      "loss": 0.6966,
      "step": 6170
    },
    {
      "epoch": 0.31074014481094125,
      "grad_norm": 4.8125,
      "learning_rate": 1.937851971037812e-05,
      "loss": 0.847,
      "step": 6180
    },
    {
      "epoch": 0.3112429605792438,
      "grad_norm": 9.5625,
      "learning_rate": 1.9377514078841515e-05,
      "loss": 1.0952,
      "step": 6190
    },
    {
      "epoch": 0.31174577634754624,
      "grad_norm": 18.875,
      "learning_rate": 1.9376508447304908e-05,
      "loss": 0.9307,
      "step": 6200
    },
    {
      "epoch": 0.31224859211584877,
      "grad_norm": 6.625,
      "learning_rate": 1.9375502815768304e-05,
      "loss": 0.9254,
      "step": 6210
    },
    {
      "epoch": 0.31275140788415123,
      "grad_norm": 23.875,
      "learning_rate": 1.93744971842317e-05,
      "loss": 1.2069,
      "step": 6220
    },
    {
      "epoch": 0.31325422365245376,
      "grad_norm": 65.0,
      "learning_rate": 1.9373491552695096e-05,
      "loss": 1.0764,
      "step": 6230
    },
    {
      "epoch": 0.3137570394207562,
      "grad_norm": 29.875,
      "learning_rate": 1.9372485921158488e-05,
      "loss": 1.1759,
      "step": 6240
    },
    {
      "epoch": 0.31425985518905875,
      "grad_norm": 32.75,
      "learning_rate": 1.9371480289621884e-05,
      "loss": 1.2464,
      "step": 6250
    },
    {
      "epoch": 0.3147626709573612,
      "grad_norm": 25.75,
      "learning_rate": 1.937047465808528e-05,
      "loss": 1.1105,
      "step": 6260
    },
    {
      "epoch": 0.31526548672566373,
      "grad_norm": 10.5,
      "learning_rate": 1.9369469026548676e-05,
      "loss": 1.0945,
      "step": 6270
    },
    {
      "epoch": 0.3157683024939662,
      "grad_norm": 15.0,
      "learning_rate": 1.9368463395012068e-05,
      "loss": 0.8642,
      "step": 6280
    },
    {
      "epoch": 0.3162711182622687,
      "grad_norm": 16.125,
      "learning_rate": 1.9367457763475464e-05,
      "loss": 1.229,
      "step": 6290
    },
    {
      "epoch": 0.3167739340305712,
      "grad_norm": 65.5,
      "learning_rate": 1.936645213193886e-05,
      "loss": 1.4241,
      "step": 6300
    },
    {
      "epoch": 0.3172767497988737,
      "grad_norm": 9.0625,
      "learning_rate": 1.9365446500402252e-05,
      "loss": 0.9,
      "step": 6310
    },
    {
      "epoch": 0.3177795655671762,
      "grad_norm": 16.875,
      "learning_rate": 1.9364440868865648e-05,
      "loss": 1.0545,
      "step": 6320
    },
    {
      "epoch": 0.3182823813354787,
      "grad_norm": 12.8125,
      "learning_rate": 1.9363435237329044e-05,
      "loss": 0.6815,
      "step": 6330
    },
    {
      "epoch": 0.31878519710378117,
      "grad_norm": 32.5,
      "learning_rate": 1.936242960579244e-05,
      "loss": 1.2467,
      "step": 6340
    },
    {
      "epoch": 0.3192880128720837,
      "grad_norm": 34.5,
      "learning_rate": 1.9361423974255836e-05,
      "loss": 1.2204,
      "step": 6350
    },
    {
      "epoch": 0.31979082864038616,
      "grad_norm": 54.0,
      "learning_rate": 1.936041834271923e-05,
      "loss": 1.23,
      "step": 6360
    },
    {
      "epoch": 0.3202936444086887,
      "grad_norm": 25.625,
      "learning_rate": 1.9359412711182624e-05,
      "loss": 1.0943,
      "step": 6370
    },
    {
      "epoch": 0.32079646017699115,
      "grad_norm": 19.5,
      "learning_rate": 1.935840707964602e-05,
      "loss": 1.0874,
      "step": 6380
    },
    {
      "epoch": 0.32129927594529367,
      "grad_norm": 35.75,
      "learning_rate": 1.9357401448109413e-05,
      "loss": 1.1238,
      "step": 6390
    },
    {
      "epoch": 0.32180209171359614,
      "grad_norm": 7.3125,
      "learning_rate": 1.935639581657281e-05,
      "loss": 0.7692,
      "step": 6400
    },
    {
      "epoch": 0.3223049074818986,
      "grad_norm": 16.125,
      "learning_rate": 1.9355390185036204e-05,
      "loss": 0.8467,
      "step": 6410
    },
    {
      "epoch": 0.32280772325020113,
      "grad_norm": 47.75,
      "learning_rate": 1.93543845534996e-05,
      "loss": 1.0626,
      "step": 6420
    },
    {
      "epoch": 0.3233105390185036,
      "grad_norm": 21.375,
      "learning_rate": 1.9353378921962996e-05,
      "loss": 0.8573,
      "step": 6430
    },
    {
      "epoch": 0.3238133547868061,
      "grad_norm": 16.625,
      "learning_rate": 1.935237329042639e-05,
      "loss": 0.9439,
      "step": 6440
    },
    {
      "epoch": 0.3243161705551086,
      "grad_norm": 21.25,
      "learning_rate": 1.9351367658889785e-05,
      "loss": 0.9823,
      "step": 6450
    },
    {
      "epoch": 0.3248189863234111,
      "grad_norm": 10.75,
      "learning_rate": 1.935036202735318e-05,
      "loss": 1.2026,
      "step": 6460
    },
    {
      "epoch": 0.3253218020917136,
      "grad_norm": 21.625,
      "learning_rate": 1.9349356395816573e-05,
      "loss": 0.8784,
      "step": 6470
    },
    {
      "epoch": 0.3258246178600161,
      "grad_norm": 18.375,
      "learning_rate": 1.934835076427997e-05,
      "loss": 0.8289,
      "step": 6480
    },
    {
      "epoch": 0.32632743362831856,
      "grad_norm": 9.4375,
      "learning_rate": 1.9347345132743365e-05,
      "loss": 0.7673,
      "step": 6490
    },
    {
      "epoch": 0.3268302493966211,
      "grad_norm": 8.25,
      "learning_rate": 1.934633950120676e-05,
      "loss": 1.2352,
      "step": 6500
    },
    {
      "epoch": 0.3268302493966211,
      "eval_accuracy": 0.5103123450669311,
      "eval_loss": 1.0592018365859985,
      "eval_runtime": 465.1263,
      "eval_samples_per_second": 86.729,
      "eval_steps_per_second": 86.729,
      "step": 6500
    },
    {
      "epoch": 0.32733306516492355,
      "grad_norm": 29.25,
      "learning_rate": 1.9345333869670156e-05,
      "loss": 1.6512,
      "step": 6510
    },
    {
      "epoch": 0.3278358809332261,
      "grad_norm": 20.5,
      "learning_rate": 1.934432823813355e-05,
      "loss": 1.0621,
      "step": 6520
    },
    {
      "epoch": 0.32833869670152854,
      "grad_norm": 52.0,
      "learning_rate": 1.9343322606596945e-05,
      "loss": 1.0706,
      "step": 6530
    },
    {
      "epoch": 0.32884151246983107,
      "grad_norm": 61.5,
      "learning_rate": 1.934231697506034e-05,
      "loss": 1.037,
      "step": 6540
    },
    {
      "epoch": 0.32934432823813353,
      "grad_norm": 6.65625,
      "learning_rate": 1.9341311343523733e-05,
      "loss": 1.4612,
      "step": 6550
    },
    {
      "epoch": 0.32984714400643605,
      "grad_norm": 4.28125,
      "learning_rate": 1.934030571198713e-05,
      "loss": 1.2114,
      "step": 6560
    },
    {
      "epoch": 0.3303499597747385,
      "grad_norm": 51.25,
      "learning_rate": 1.9339300080450525e-05,
      "loss": 1.1068,
      "step": 6570
    },
    {
      "epoch": 0.33085277554304104,
      "grad_norm": 44.0,
      "learning_rate": 1.9338294448913917e-05,
      "loss": 1.0055,
      "step": 6580
    },
    {
      "epoch": 0.3313555913113435,
      "grad_norm": 22.125,
      "learning_rate": 1.9337288817377317e-05,
      "loss": 1.1777,
      "step": 6590
    },
    {
      "epoch": 0.33185840707964603,
      "grad_norm": 18.125,
      "learning_rate": 1.933628318584071e-05,
      "loss": 1.0778,
      "step": 6600
    },
    {
      "epoch": 0.3323612228479485,
      "grad_norm": 30.375,
      "learning_rate": 1.9335277554304105e-05,
      "loss": 1.153,
      "step": 6610
    },
    {
      "epoch": 0.332864038616251,
      "grad_norm": 11.0,
      "learning_rate": 1.93342719227675e-05,
      "loss": 0.6577,
      "step": 6620
    },
    {
      "epoch": 0.3333668543845535,
      "grad_norm": 34.0,
      "learning_rate": 1.9333266291230893e-05,
      "loss": 1.2735,
      "step": 6630
    },
    {
      "epoch": 0.333869670152856,
      "grad_norm": 32.5,
      "learning_rate": 1.933226065969429e-05,
      "loss": 1.0711,
      "step": 6640
    },
    {
      "epoch": 0.3343724859211585,
      "grad_norm": 37.25,
      "learning_rate": 1.9331255028157685e-05,
      "loss": 0.8636,
      "step": 6650
    },
    {
      "epoch": 0.334875301689461,
      "grad_norm": 26.125,
      "learning_rate": 1.9330249396621078e-05,
      "loss": 0.9447,
      "step": 6660
    },
    {
      "epoch": 0.33537811745776347,
      "grad_norm": 90.5,
      "learning_rate": 1.9329243765084477e-05,
      "loss": 1.0429,
      "step": 6670
    },
    {
      "epoch": 0.335880933226066,
      "grad_norm": 30.875,
      "learning_rate": 1.932823813354787e-05,
      "loss": 0.9965,
      "step": 6680
    },
    {
      "epoch": 0.33638374899436846,
      "grad_norm": 17.375,
      "learning_rate": 1.9327232502011265e-05,
      "loss": 1.1872,
      "step": 6690
    },
    {
      "epoch": 0.336886564762671,
      "grad_norm": 83.0,
      "learning_rate": 1.932622687047466e-05,
      "loss": 1.1232,
      "step": 6700
    },
    {
      "epoch": 0.33738938053097345,
      "grad_norm": 27.5,
      "learning_rate": 1.9325221238938054e-05,
      "loss": 0.7805,
      "step": 6710
    },
    {
      "epoch": 0.33789219629927597,
      "grad_norm": 12.125,
      "learning_rate": 1.932421560740145e-05,
      "loss": 1.1476,
      "step": 6720
    },
    {
      "epoch": 0.33839501206757844,
      "grad_norm": 53.0,
      "learning_rate": 1.9323209975864845e-05,
      "loss": 0.8124,
      "step": 6730
    },
    {
      "epoch": 0.33889782783588096,
      "grad_norm": 8.25,
      "learning_rate": 1.9322204344328238e-05,
      "loss": 0.7595,
      "step": 6740
    },
    {
      "epoch": 0.3394006436041834,
      "grad_norm": 12.5,
      "learning_rate": 1.9321198712791637e-05,
      "loss": 1.0598,
      "step": 6750
    },
    {
      "epoch": 0.3399034593724859,
      "grad_norm": 49.0,
      "learning_rate": 1.932019308125503e-05,
      "loss": 1.1691,
      "step": 6760
    },
    {
      "epoch": 0.3404062751407884,
      "grad_norm": 38.75,
      "learning_rate": 1.9319187449718426e-05,
      "loss": 0.9699,
      "step": 6770
    },
    {
      "epoch": 0.3409090909090909,
      "grad_norm": 31.875,
      "learning_rate": 1.931818181818182e-05,
      "loss": 1.1171,
      "step": 6780
    },
    {
      "epoch": 0.3414119066773934,
      "grad_norm": 25.125,
      "learning_rate": 1.9317176186645214e-05,
      "loss": 0.5776,
      "step": 6790
    },
    {
      "epoch": 0.3419147224456959,
      "grad_norm": 17.375,
      "learning_rate": 1.931617055510861e-05,
      "loss": 0.9779,
      "step": 6800
    },
    {
      "epoch": 0.3424175382139984,
      "grad_norm": 14.3125,
      "learning_rate": 1.9315164923572006e-05,
      "loss": 1.0571,
      "step": 6810
    },
    {
      "epoch": 0.34292035398230086,
      "grad_norm": 24.75,
      "learning_rate": 1.9314159292035398e-05,
      "loss": 0.9465,
      "step": 6820
    },
    {
      "epoch": 0.3434231697506034,
      "grad_norm": 7.15625,
      "learning_rate": 1.9313153660498794e-05,
      "loss": 0.9995,
      "step": 6830
    },
    {
      "epoch": 0.34392598551890585,
      "grad_norm": 26.875,
      "learning_rate": 1.931214802896219e-05,
      "loss": 1.1786,
      "step": 6840
    },
    {
      "epoch": 0.3444288012872084,
      "grad_norm": 6.09375,
      "learning_rate": 1.9311142397425582e-05,
      "loss": 0.754,
      "step": 6850
    },
    {
      "epoch": 0.34493161705551084,
      "grad_norm": 9.0,
      "learning_rate": 1.931013676588898e-05,
      "loss": 0.8876,
      "step": 6860
    },
    {
      "epoch": 0.34543443282381336,
      "grad_norm": 30.5,
      "learning_rate": 1.9309131134352374e-05,
      "loss": 1.1487,
      "step": 6870
    },
    {
      "epoch": 0.34593724859211583,
      "grad_norm": 43.5,
      "learning_rate": 1.930812550281577e-05,
      "loss": 1.1542,
      "step": 6880
    },
    {
      "epoch": 0.34644006436041835,
      "grad_norm": 26.5,
      "learning_rate": 1.9307119871279166e-05,
      "loss": 0.9956,
      "step": 6890
    },
    {
      "epoch": 0.3469428801287208,
      "grad_norm": 8.25,
      "learning_rate": 1.930611423974256e-05,
      "loss": 0.6942,
      "step": 6900
    },
    {
      "epoch": 0.34744569589702334,
      "grad_norm": 53.0,
      "learning_rate": 1.9305108608205954e-05,
      "loss": 1.3938,
      "step": 6910
    },
    {
      "epoch": 0.3479485116653258,
      "grad_norm": 22.25,
      "learning_rate": 1.930410297666935e-05,
      "loss": 0.9943,
      "step": 6920
    },
    {
      "epoch": 0.34845132743362833,
      "grad_norm": 21.0,
      "learning_rate": 1.9303097345132743e-05,
      "loss": 0.8032,
      "step": 6930
    },
    {
      "epoch": 0.3489541432019308,
      "grad_norm": 8.8125,
      "learning_rate": 1.9302091713596142e-05,
      "loss": 1.0394,
      "step": 6940
    },
    {
      "epoch": 0.3494569589702333,
      "grad_norm": 62.0,
      "learning_rate": 1.9301086082059534e-05,
      "loss": 0.9424,
      "step": 6950
    },
    {
      "epoch": 0.3499597747385358,
      "grad_norm": 31.375,
      "learning_rate": 1.930008045052293e-05,
      "loss": 1.0775,
      "step": 6960
    },
    {
      "epoch": 0.3504625905068383,
      "grad_norm": 10.4375,
      "learning_rate": 1.9299074818986326e-05,
      "loss": 0.6933,
      "step": 6970
    },
    {
      "epoch": 0.3509654062751408,
      "grad_norm": 9.625,
      "learning_rate": 1.929806918744972e-05,
      "loss": 0.8061,
      "step": 6980
    },
    {
      "epoch": 0.3514682220434433,
      "grad_norm": 20.125,
      "learning_rate": 1.9297063555913115e-05,
      "loss": 1.1225,
      "step": 6990
    },
    {
      "epoch": 0.35197103781174577,
      "grad_norm": 23.5,
      "learning_rate": 1.929605792437651e-05,
      "loss": 0.9743,
      "step": 7000
    },
    {
      "epoch": 0.35197103781174577,
      "eval_accuracy": 0.5102379771938522,
      "eval_loss": 1.0577977895736694,
      "eval_runtime": 464.4627,
      "eval_samples_per_second": 86.853,
      "eval_steps_per_second": 86.853,
      "step": 7000
    },
    {
      "epoch": 0.3524738535800483,
      "grad_norm": 47.75,
      "learning_rate": 1.9295052292839903e-05,
      "loss": 1.0009,
      "step": 7010
    },
    {
      "epoch": 0.35297666934835076,
      "grad_norm": 49.25,
      "learning_rate": 1.9294046661303302e-05,
      "loss": 0.9239,
      "step": 7020
    },
    {
      "epoch": 0.3534794851166533,
      "grad_norm": 22.875,
      "learning_rate": 1.9293041029766695e-05,
      "loss": 1.0584,
      "step": 7030
    },
    {
      "epoch": 0.35398230088495575,
      "grad_norm": 9.75,
      "learning_rate": 1.929203539823009e-05,
      "loss": 1.0942,
      "step": 7040
    },
    {
      "epoch": 0.35448511665325827,
      "grad_norm": 16.625,
      "learning_rate": 1.9291029766693486e-05,
      "loss": 0.8516,
      "step": 7050
    },
    {
      "epoch": 0.35498793242156074,
      "grad_norm": 33.5,
      "learning_rate": 1.929002413515688e-05,
      "loss": 1.2032,
      "step": 7060
    },
    {
      "epoch": 0.35549074818986326,
      "grad_norm": 54.5,
      "learning_rate": 1.9289018503620275e-05,
      "loss": 0.899,
      "step": 7070
    },
    {
      "epoch": 0.3559935639581657,
      "grad_norm": 8.375,
      "learning_rate": 1.928801287208367e-05,
      "loss": 1.1606,
      "step": 7080
    },
    {
      "epoch": 0.35649637972646825,
      "grad_norm": 12.6875,
      "learning_rate": 1.9287007240547063e-05,
      "loss": 1.0961,
      "step": 7090
    },
    {
      "epoch": 0.3569991954947707,
      "grad_norm": 24.5,
      "learning_rate": 1.928600160901046e-05,
      "loss": 0.9918,
      "step": 7100
    },
    {
      "epoch": 0.3575020112630732,
      "grad_norm": 18.75,
      "learning_rate": 1.9284995977473855e-05,
      "loss": 1.0949,
      "step": 7110
    },
    {
      "epoch": 0.3580048270313757,
      "grad_norm": 8.4375,
      "learning_rate": 1.928399034593725e-05,
      "loss": 1.0329,
      "step": 7120
    },
    {
      "epoch": 0.3585076427996782,
      "grad_norm": 16.25,
      "learning_rate": 1.9282984714400647e-05,
      "loss": 1.004,
      "step": 7130
    },
    {
      "epoch": 0.3590104585679807,
      "grad_norm": 21.0,
      "learning_rate": 1.928197908286404e-05,
      "loss": 0.9468,
      "step": 7140
    },
    {
      "epoch": 0.35951327433628316,
      "grad_norm": 30.75,
      "learning_rate": 1.9280973451327435e-05,
      "loss": 1.0689,
      "step": 7150
    },
    {
      "epoch": 0.3600160901045857,
      "grad_norm": 10.375,
      "learning_rate": 1.927996781979083e-05,
      "loss": 0.9706,
      "step": 7160
    },
    {
      "epoch": 0.36051890587288815,
      "grad_norm": 14.8125,
      "learning_rate": 1.9278962188254223e-05,
      "loss": 1.1856,
      "step": 7170
    },
    {
      "epoch": 0.3610217216411907,
      "grad_norm": 10.75,
      "learning_rate": 1.927795655671762e-05,
      "loss": 1.1321,
      "step": 7180
    },
    {
      "epoch": 0.36152453740949314,
      "grad_norm": 9.5,
      "learning_rate": 1.9276950925181015e-05,
      "loss": 0.8051,
      "step": 7190
    },
    {
      "epoch": 0.36202735317779566,
      "grad_norm": 10.9375,
      "learning_rate": 1.927594529364441e-05,
      "loss": 1.1006,
      "step": 7200
    },
    {
      "epoch": 0.36253016894609813,
      "grad_norm": 10.125,
      "learning_rate": 1.9274939662107807e-05,
      "loss": 1.0675,
      "step": 7210
    },
    {
      "epoch": 0.36303298471440065,
      "grad_norm": 51.5,
      "learning_rate": 1.92739340305712e-05,
      "loss": 0.897,
      "step": 7220
    },
    {
      "epoch": 0.3635358004827031,
      "grad_norm": 13.6875,
      "learning_rate": 1.9272928399034595e-05,
      "loss": 0.9654,
      "step": 7230
    },
    {
      "epoch": 0.36403861625100564,
      "grad_norm": 20.0,
      "learning_rate": 1.927192276749799e-05,
      "loss": 0.7575,
      "step": 7240
    },
    {
      "epoch": 0.3645414320193081,
      "grad_norm": 6.4375,
      "learning_rate": 1.9270917135961384e-05,
      "loss": 1.1458,
      "step": 7250
    },
    {
      "epoch": 0.36504424778761063,
      "grad_norm": 21.625,
      "learning_rate": 1.926991150442478e-05,
      "loss": 1.418,
      "step": 7260
    },
    {
      "epoch": 0.3655470635559131,
      "grad_norm": 27.75,
      "learning_rate": 1.9268905872888175e-05,
      "loss": 1.0138,
      "step": 7270
    },
    {
      "epoch": 0.3660498793242156,
      "grad_norm": 24.375,
      "learning_rate": 1.926790024135157e-05,
      "loss": 1.2269,
      "step": 7280
    },
    {
      "epoch": 0.3665526950925181,
      "grad_norm": 10.3125,
      "learning_rate": 1.9266894609814967e-05,
      "loss": 0.933,
      "step": 7290
    },
    {
      "epoch": 0.3670555108608206,
      "grad_norm": 22.0,
      "learning_rate": 1.926588897827836e-05,
      "loss": 1.0832,
      "step": 7300
    },
    {
      "epoch": 0.3675583266291231,
      "grad_norm": 7.8125,
      "learning_rate": 1.9264883346741756e-05,
      "loss": 0.9513,
      "step": 7310
    },
    {
      "epoch": 0.3680611423974256,
      "grad_norm": 24.5,
      "learning_rate": 1.926387771520515e-05,
      "loss": 1.1514,
      "step": 7320
    },
    {
      "epoch": 0.36856395816572807,
      "grad_norm": 89.0,
      "learning_rate": 1.9262872083668544e-05,
      "loss": 1.2868,
      "step": 7330
    },
    {
      "epoch": 0.3690667739340306,
      "grad_norm": 16.25,
      "learning_rate": 1.926186645213194e-05,
      "loss": 1.0162,
      "step": 7340
    },
    {
      "epoch": 0.36956958970233306,
      "grad_norm": 22.5,
      "learning_rate": 1.9260860820595336e-05,
      "loss": 0.9011,
      "step": 7350
    },
    {
      "epoch": 0.3700724054706356,
      "grad_norm": 40.0,
      "learning_rate": 1.925985518905873e-05,
      "loss": 0.9481,
      "step": 7360
    },
    {
      "epoch": 0.37057522123893805,
      "grad_norm": 86.0,
      "learning_rate": 1.9258849557522124e-05,
      "loss": 1.1046,
      "step": 7370
    },
    {
      "epoch": 0.37107803700724057,
      "grad_norm": 14.6875,
      "learning_rate": 1.925784392598552e-05,
      "loss": 0.8537,
      "step": 7380
    },
    {
      "epoch": 0.37158085277554304,
      "grad_norm": 11.6875,
      "learning_rate": 1.9256838294448916e-05,
      "loss": 1.0178,
      "step": 7390
    },
    {
      "epoch": 0.37208366854384556,
      "grad_norm": 11.9375,
      "learning_rate": 1.9255832662912312e-05,
      "loss": 1.2512,
      "step": 7400
    },
    {
      "epoch": 0.372586484312148,
      "grad_norm": 9.1875,
      "learning_rate": 1.9254827031375704e-05,
      "loss": 0.8969,
      "step": 7410
    },
    {
      "epoch": 0.37308930008045055,
      "grad_norm": 7.625,
      "learning_rate": 1.92538213998391e-05,
      "loss": 0.7851,
      "step": 7420
    },
    {
      "epoch": 0.373592115848753,
      "grad_norm": 22.0,
      "learning_rate": 1.9252815768302496e-05,
      "loss": 1.025,
      "step": 7430
    },
    {
      "epoch": 0.37409493161705554,
      "grad_norm": 22.0,
      "learning_rate": 1.9251810136765892e-05,
      "loss": 1.5303,
      "step": 7440
    },
    {
      "epoch": 0.374597747385358,
      "grad_norm": 21.5,
      "learning_rate": 1.9250804505229284e-05,
      "loss": 0.9467,
      "step": 7450
    },
    {
      "epoch": 0.37510056315366047,
      "grad_norm": 15.75,
      "learning_rate": 1.924979887369268e-05,
      "loss": 0.9006,
      "step": 7460
    },
    {
      "epoch": 0.375603378921963,
      "grad_norm": 37.75,
      "learning_rate": 1.9248793242156076e-05,
      "loss": 1.4195,
      "step": 7470
    },
    {
      "epoch": 0.37610619469026546,
      "grad_norm": 30.875,
      "learning_rate": 1.9247787610619472e-05,
      "loss": 0.9651,
      "step": 7480
    },
    {
      "epoch": 0.376609010458568,
      "grad_norm": 17.5,
      "learning_rate": 1.9246781979082864e-05,
      "loss": 1.0637,
      "step": 7490
    },
    {
      "epoch": 0.37711182622687045,
      "grad_norm": 8.5,
      "learning_rate": 1.924577634754626e-05,
      "loss": 0.8582,
      "step": 7500
    },
    {
      "epoch": 0.37711182622687045,
      "eval_accuracy": 0.5097174020823004,
      "eval_loss": 1.0517877340316772,
      "eval_runtime": 466.1231,
      "eval_samples_per_second": 86.544,
      "eval_steps_per_second": 86.544,
      "step": 7500
    },
    {
      "epoch": 0.377614641995173,
      "grad_norm": 7.40625,
      "learning_rate": 1.9244770716009656e-05,
      "loss": 1.2873,
      "step": 7510
    },
    {
      "epoch": 0.37811745776347544,
      "grad_norm": 20.75,
      "learning_rate": 1.9243765084473052e-05,
      "loss": 1.0061,
      "step": 7520
    },
    {
      "epoch": 0.37862027353177796,
      "grad_norm": 39.5,
      "learning_rate": 1.9242759452936445e-05,
      "loss": 1.1145,
      "step": 7530
    },
    {
      "epoch": 0.37912308930008043,
      "grad_norm": 43.25,
      "learning_rate": 1.924175382139984e-05,
      "loss": 0.8651,
      "step": 7540
    },
    {
      "epoch": 0.37962590506838295,
      "grad_norm": 25.0,
      "learning_rate": 1.9240748189863236e-05,
      "loss": 0.8312,
      "step": 7550
    },
    {
      "epoch": 0.3801287208366854,
      "grad_norm": 11.875,
      "learning_rate": 1.9239742558326632e-05,
      "loss": 1.1551,
      "step": 7560
    },
    {
      "epoch": 0.38063153660498794,
      "grad_norm": 37.25,
      "learning_rate": 1.9238736926790025e-05,
      "loss": 0.7049,
      "step": 7570
    },
    {
      "epoch": 0.3811343523732904,
      "grad_norm": 18.375,
      "learning_rate": 1.923773129525342e-05,
      "loss": 1.0855,
      "step": 7580
    },
    {
      "epoch": 0.38163716814159293,
      "grad_norm": 10.5625,
      "learning_rate": 1.9236725663716816e-05,
      "loss": 1.0569,
      "step": 7590
    },
    {
      "epoch": 0.3821399839098954,
      "grad_norm": 25.25,
      "learning_rate": 1.9235720032180212e-05,
      "loss": 1.1306,
      "step": 7600
    },
    {
      "epoch": 0.3826427996781979,
      "grad_norm": 10.875,
      "learning_rate": 1.9234714400643605e-05,
      "loss": 0.9195,
      "step": 7610
    },
    {
      "epoch": 0.3831456154465004,
      "grad_norm": 12.875,
      "learning_rate": 1.9233708769107e-05,
      "loss": 0.9547,
      "step": 7620
    },
    {
      "epoch": 0.3836484312148029,
      "grad_norm": 28.625,
      "learning_rate": 1.9232703137570397e-05,
      "loss": 1.0324,
      "step": 7630
    },
    {
      "epoch": 0.3841512469831054,
      "grad_norm": 5.78125,
      "learning_rate": 1.923169750603379e-05,
      "loss": 0.6095,
      "step": 7640
    },
    {
      "epoch": 0.3846540627514079,
      "grad_norm": 36.75,
      "learning_rate": 1.9230691874497185e-05,
      "loss": 0.9417,
      "step": 7650
    },
    {
      "epoch": 0.38515687851971037,
      "grad_norm": 21.5,
      "learning_rate": 1.922968624296058e-05,
      "loss": 1.4055,
      "step": 7660
    },
    {
      "epoch": 0.3856596942880129,
      "grad_norm": 55.75,
      "learning_rate": 1.9228680611423977e-05,
      "loss": 1.0479,
      "step": 7670
    },
    {
      "epoch": 0.38616251005631536,
      "grad_norm": 16.625,
      "learning_rate": 1.9227674979887373e-05,
      "loss": 0.9061,
      "step": 7680
    },
    {
      "epoch": 0.3866653258246179,
      "grad_norm": 31.625,
      "learning_rate": 1.9226669348350765e-05,
      "loss": 1.1156,
      "step": 7690
    },
    {
      "epoch": 0.38716814159292035,
      "grad_norm": 6.09375,
      "learning_rate": 1.922566371681416e-05,
      "loss": 1.0987,
      "step": 7700
    },
    {
      "epoch": 0.38767095736122287,
      "grad_norm": 18.5,
      "learning_rate": 1.9224658085277557e-05,
      "loss": 0.5755,
      "step": 7710
    },
    {
      "epoch": 0.38817377312952533,
      "grad_norm": 28.625,
      "learning_rate": 1.922365245374095e-05,
      "loss": 1.0541,
      "step": 7720
    },
    {
      "epoch": 0.38867658889782786,
      "grad_norm": 12.375,
      "learning_rate": 1.9222646822204345e-05,
      "loss": 0.8172,
      "step": 7730
    },
    {
      "epoch": 0.3891794046661303,
      "grad_norm": 50.25,
      "learning_rate": 1.922164119066774e-05,
      "loss": 1.1797,
      "step": 7740
    },
    {
      "epoch": 0.38968222043443285,
      "grad_norm": 16.0,
      "learning_rate": 1.9220635559131137e-05,
      "loss": 1.157,
      "step": 7750
    },
    {
      "epoch": 0.3901850362027353,
      "grad_norm": 12.6875,
      "learning_rate": 1.9219629927594533e-05,
      "loss": 0.9178,
      "step": 7760
    },
    {
      "epoch": 0.39068785197103784,
      "grad_norm": 19.875,
      "learning_rate": 1.9218624296057925e-05,
      "loss": 1.0154,
      "step": 7770
    },
    {
      "epoch": 0.3911906677393403,
      "grad_norm": 49.5,
      "learning_rate": 1.921761866452132e-05,
      "loss": 1.3162,
      "step": 7780
    },
    {
      "epoch": 0.3916934835076428,
      "grad_norm": 12.1875,
      "learning_rate": 1.9216613032984717e-05,
      "loss": 1.0808,
      "step": 7790
    },
    {
      "epoch": 0.3921962992759453,
      "grad_norm": 7.09375,
      "learning_rate": 1.921560740144811e-05,
      "loss": 1.0398,
      "step": 7800
    },
    {
      "epoch": 0.3926991150442478,
      "grad_norm": 41.5,
      "learning_rate": 1.9214601769911505e-05,
      "loss": 0.9079,
      "step": 7810
    },
    {
      "epoch": 0.3932019308125503,
      "grad_norm": 37.0,
      "learning_rate": 1.92135961383749e-05,
      "loss": 1.0544,
      "step": 7820
    },
    {
      "epoch": 0.39370474658085275,
      "grad_norm": 24.875,
      "learning_rate": 1.9212590506838297e-05,
      "loss": 1.2406,
      "step": 7830
    },
    {
      "epoch": 0.39420756234915527,
      "grad_norm": 26.25,
      "learning_rate": 1.9211584875301693e-05,
      "loss": 0.9638,
      "step": 7840
    },
    {
      "epoch": 0.39471037811745774,
      "grad_norm": 15.25,
      "learning_rate": 1.9210579243765086e-05,
      "loss": 1.0341,
      "step": 7850
    },
    {
      "epoch": 0.39521319388576026,
      "grad_norm": 12.5625,
      "learning_rate": 1.920957361222848e-05,
      "loss": 1.0407,
      "step": 7860
    },
    {
      "epoch": 0.39571600965406273,
      "grad_norm": 16.625,
      "learning_rate": 1.9208567980691877e-05,
      "loss": 0.8385,
      "step": 7870
    },
    {
      "epoch": 0.39621882542236525,
      "grad_norm": 34.5,
      "learning_rate": 1.920756234915527e-05,
      "loss": 0.9981,
      "step": 7880
    },
    {
      "epoch": 0.3967216411906677,
      "grad_norm": 7.5,
      "learning_rate": 1.9206556717618666e-05,
      "loss": 0.8401,
      "step": 7890
    },
    {
      "epoch": 0.39722445695897024,
      "grad_norm": 9.4375,
      "learning_rate": 1.920555108608206e-05,
      "loss": 1.1007,
      "step": 7900
    },
    {
      "epoch": 0.3977272727272727,
      "grad_norm": 19.75,
      "learning_rate": 1.9204545454545454e-05,
      "loss": 1.3505,
      "step": 7910
    },
    {
      "epoch": 0.39823008849557523,
      "grad_norm": 9.625,
      "learning_rate": 1.9203539823008853e-05,
      "loss": 1.5682,
      "step": 7920
    },
    {
      "epoch": 0.3987329042638777,
      "grad_norm": 12.5625,
      "learning_rate": 1.9202534191472246e-05,
      "loss": 0.9939,
      "step": 7930
    },
    {
      "epoch": 0.3992357200321802,
      "grad_norm": 16.25,
      "learning_rate": 1.9201528559935642e-05,
      "loss": 1.0358,
      "step": 7940
    },
    {
      "epoch": 0.3997385358004827,
      "grad_norm": 15.3125,
      "learning_rate": 1.9200522928399038e-05,
      "loss": 0.9366,
      "step": 7950
    },
    {
      "epoch": 0.4002413515687852,
      "grad_norm": 47.5,
      "learning_rate": 1.919951729686243e-05,
      "loss": 1.0754,
      "step": 7960
    },
    {
      "epoch": 0.4007441673370877,
      "grad_norm": 12.0,
      "learning_rate": 1.9198511665325826e-05,
      "loss": 0.9934,
      "step": 7970
    },
    {
      "epoch": 0.4012469831053902,
      "grad_norm": 26.125,
      "learning_rate": 1.9197506033789222e-05,
      "loss": 1.0099,
      "step": 7980
    },
    {
      "epoch": 0.40174979887369267,
      "grad_norm": 3.578125,
      "learning_rate": 1.9196500402252614e-05,
      "loss": 0.9386,
      "step": 7990
    },
    {
      "epoch": 0.4022526146419952,
      "grad_norm": 5.25,
      "learning_rate": 1.9195494770716014e-05,
      "loss": 0.9987,
      "step": 8000
    },
    {
      "epoch": 0.4022526146419952,
      "eval_accuracy": 0.5106346058502726,
      "eval_loss": 1.047487497329712,
      "eval_runtime": 466.1439,
      "eval_samples_per_second": 86.54,
      "eval_steps_per_second": 86.54,
      "step": 8000
    },
    {
      "epoch": 0.40275543041029765,
      "grad_norm": 11.0,
      "learning_rate": 1.9194489139179406e-05,
      "loss": 1.0605,
      "step": 8010
    },
    {
      "epoch": 0.4032582461786002,
      "grad_norm": 13.75,
      "learning_rate": 1.9193483507642802e-05,
      "loss": 1.0363,
      "step": 8020
    },
    {
      "epoch": 0.40376106194690264,
      "grad_norm": 22.0,
      "learning_rate": 1.9192477876106198e-05,
      "loss": 1.0794,
      "step": 8030
    },
    {
      "epoch": 0.40426387771520517,
      "grad_norm": 12.625,
      "learning_rate": 1.919147224456959e-05,
      "loss": 0.7906,
      "step": 8040
    },
    {
      "epoch": 0.40476669348350763,
      "grad_norm": 12.0625,
      "learning_rate": 1.9190466613032986e-05,
      "loss": 0.931,
      "step": 8050
    },
    {
      "epoch": 0.40526950925181016,
      "grad_norm": 22.0,
      "learning_rate": 1.9189460981496382e-05,
      "loss": 1.0059,
      "step": 8060
    },
    {
      "epoch": 0.4057723250201126,
      "grad_norm": 34.5,
      "learning_rate": 1.9188455349959775e-05,
      "loss": 1.0417,
      "step": 8070
    },
    {
      "epoch": 0.40627514078841515,
      "grad_norm": 21.25,
      "learning_rate": 1.9187449718423174e-05,
      "loss": 1.1063,
      "step": 8080
    },
    {
      "epoch": 0.4067779565567176,
      "grad_norm": 76.5,
      "learning_rate": 1.9186444086886566e-05,
      "loss": 1.2771,
      "step": 8090
    },
    {
      "epoch": 0.40728077232502014,
      "grad_norm": 15.9375,
      "learning_rate": 1.9185438455349962e-05,
      "loss": 1.1099,
      "step": 8100
    },
    {
      "epoch": 0.4077835880933226,
      "grad_norm": 20.75,
      "learning_rate": 1.9184432823813358e-05,
      "loss": 0.8827,
      "step": 8110
    },
    {
      "epoch": 0.4082864038616251,
      "grad_norm": 67.0,
      "learning_rate": 1.918342719227675e-05,
      "loss": 1.0049,
      "step": 8120
    },
    {
      "epoch": 0.4087892196299276,
      "grad_norm": 22.875,
      "learning_rate": 1.9182421560740146e-05,
      "loss": 1.0271,
      "step": 8130
    },
    {
      "epoch": 0.4092920353982301,
      "grad_norm": 10.5,
      "learning_rate": 1.9181415929203542e-05,
      "loss": 0.8669,
      "step": 8140
    },
    {
      "epoch": 0.4097948511665326,
      "grad_norm": 26.0,
      "learning_rate": 1.9180410297666935e-05,
      "loss": 1.3271,
      "step": 8150
    },
    {
      "epoch": 0.4102976669348351,
      "grad_norm": 16.375,
      "learning_rate": 1.917940466613033e-05,
      "loss": 0.8798,
      "step": 8160
    },
    {
      "epoch": 0.41080048270313757,
      "grad_norm": 27.875,
      "learning_rate": 1.9178399034593727e-05,
      "loss": 1.0289,
      "step": 8170
    },
    {
      "epoch": 0.41130329847144004,
      "grad_norm": 6.21875,
      "learning_rate": 1.917739340305712e-05,
      "loss": 0.9026,
      "step": 8180
    },
    {
      "epoch": 0.41180611423974256,
      "grad_norm": 23.75,
      "learning_rate": 1.917638777152052e-05,
      "loss": 1.0456,
      "step": 8190
    },
    {
      "epoch": 0.412308930008045,
      "grad_norm": 30.875,
      "learning_rate": 1.917538213998391e-05,
      "loss": 1.0572,
      "step": 8200
    },
    {
      "epoch": 0.41281174577634755,
      "grad_norm": 18.875,
      "learning_rate": 1.9174376508447307e-05,
      "loss": 0.9083,
      "step": 8210
    },
    {
      "epoch": 0.41331456154465,
      "grad_norm": 30.625,
      "learning_rate": 1.9173370876910703e-05,
      "loss": 0.9577,
      "step": 8220
    },
    {
      "epoch": 0.41381737731295254,
      "grad_norm": 5.40625,
      "learning_rate": 1.9172365245374095e-05,
      "loss": 0.9914,
      "step": 8230
    },
    {
      "epoch": 0.414320193081255,
      "grad_norm": 8.0625,
      "learning_rate": 1.917135961383749e-05,
      "loss": 1.0267,
      "step": 8240
    },
    {
      "epoch": 0.41482300884955753,
      "grad_norm": 18.25,
      "learning_rate": 1.9170353982300887e-05,
      "loss": 1.1447,
      "step": 8250
    },
    {
      "epoch": 0.41532582461786,
      "grad_norm": 16.875,
      "learning_rate": 1.916934835076428e-05,
      "loss": 0.9569,
      "step": 8260
    },
    {
      "epoch": 0.4158286403861625,
      "grad_norm": 18.25,
      "learning_rate": 1.916834271922768e-05,
      "loss": 0.7938,
      "step": 8270
    },
    {
      "epoch": 0.416331456154465,
      "grad_norm": 34.75,
      "learning_rate": 1.916733708769107e-05,
      "loss": 1.0018,
      "step": 8280
    },
    {
      "epoch": 0.4168342719227675,
      "grad_norm": 9.6875,
      "learning_rate": 1.9166331456154467e-05,
      "loss": 0.8144,
      "step": 8290
    },
    {
      "epoch": 0.41733708769107,
      "grad_norm": 10.375,
      "learning_rate": 1.9165325824617863e-05,
      "loss": 0.8868,
      "step": 8300
    },
    {
      "epoch": 0.4178399034593725,
      "grad_norm": 5.40625,
      "learning_rate": 1.9164320193081255e-05,
      "loss": 0.9223,
      "step": 8310
    },
    {
      "epoch": 0.41834271922767496,
      "grad_norm": 27.0,
      "learning_rate": 1.916331456154465e-05,
      "loss": 1.0824,
      "step": 8320
    },
    {
      "epoch": 0.4188455349959775,
      "grad_norm": 24.5,
      "learning_rate": 1.9162308930008047e-05,
      "loss": 1.0215,
      "step": 8330
    },
    {
      "epoch": 0.41934835076427995,
      "grad_norm": 9.0,
      "learning_rate": 1.916130329847144e-05,
      "loss": 0.9315,
      "step": 8340
    },
    {
      "epoch": 0.4198511665325825,
      "grad_norm": 31.5,
      "learning_rate": 1.916029766693484e-05,
      "loss": 1.4123,
      "step": 8350
    },
    {
      "epoch": 0.42035398230088494,
      "grad_norm": 6.78125,
      "learning_rate": 1.915929203539823e-05,
      "loss": 0.9441,
      "step": 8360
    },
    {
      "epoch": 0.42085679806918747,
      "grad_norm": 9.625,
      "learning_rate": 1.9158286403861627e-05,
      "loss": 0.8382,
      "step": 8370
    },
    {
      "epoch": 0.42135961383748993,
      "grad_norm": 45.75,
      "learning_rate": 1.9157280772325023e-05,
      "loss": 1.0135,
      "step": 8380
    },
    {
      "epoch": 0.42186242960579245,
      "grad_norm": 3.609375,
      "learning_rate": 1.9156275140788416e-05,
      "loss": 1.0677,
      "step": 8390
    },
    {
      "epoch": 0.4223652453740949,
      "grad_norm": 65.5,
      "learning_rate": 1.915526950925181e-05,
      "loss": 1.0144,
      "step": 8400
    },
    {
      "epoch": 0.42286806114239744,
      "grad_norm": 51.25,
      "learning_rate": 1.9154263877715207e-05,
      "loss": 1.6016,
      "step": 8410
    },
    {
      "epoch": 0.4233708769106999,
      "grad_norm": 8.875,
      "learning_rate": 1.91532582461786e-05,
      "loss": 1.062,
      "step": 8420
    },
    {
      "epoch": 0.42387369267900243,
      "grad_norm": 7.0,
      "learning_rate": 1.9152252614641996e-05,
      "loss": 0.8623,
      "step": 8430
    },
    {
      "epoch": 0.4243765084473049,
      "grad_norm": 35.25,
      "learning_rate": 1.915124698310539e-05,
      "loss": 1.0106,
      "step": 8440
    },
    {
      "epoch": 0.4248793242156074,
      "grad_norm": 36.5,
      "learning_rate": 1.9150241351568784e-05,
      "loss": 0.9767,
      "step": 8450
    },
    {
      "epoch": 0.4253821399839099,
      "grad_norm": 36.5,
      "learning_rate": 1.9149235720032183e-05,
      "loss": 1.1468,
      "step": 8460
    },
    {
      "epoch": 0.4258849557522124,
      "grad_norm": 23.375,
      "learning_rate": 1.9148230088495576e-05,
      "loss": 1.1806,
      "step": 8470
    },
    {
      "epoch": 0.4263877715205149,
      "grad_norm": 29.0,
      "learning_rate": 1.9147224456958972e-05,
      "loss": 0.8954,
      "step": 8480
    },
    {
      "epoch": 0.4268905872888174,
      "grad_norm": 31.125,
      "learning_rate": 1.9146218825422368e-05,
      "loss": 0.9266,
      "step": 8490
    },
    {
      "epoch": 0.42739340305711987,
      "grad_norm": 17.5,
      "learning_rate": 1.914521319388576e-05,
      "loss": 1.126,
      "step": 8500
    },
    {
      "epoch": 0.42739340305711987,
      "eval_accuracy": 0.5114278631631135,
      "eval_loss": 1.0403167009353638,
      "eval_runtime": 466.2786,
      "eval_samples_per_second": 86.515,
      "eval_steps_per_second": 86.515,
      "step": 8500
    },
    {
      "epoch": 0.4278962188254224,
      "grad_norm": 32.25,
      "learning_rate": 1.9144207562349156e-05,
      "loss": 0.9443,
      "step": 8510
    },
    {
      "epoch": 0.42839903459372486,
      "grad_norm": 47.5,
      "learning_rate": 1.9143201930812552e-05,
      "loss": 0.9892,
      "step": 8520
    },
    {
      "epoch": 0.4289018503620273,
      "grad_norm": 59.5,
      "learning_rate": 1.9142196299275944e-05,
      "loss": 1.1795,
      "step": 8530
    },
    {
      "epoch": 0.42940466613032985,
      "grad_norm": 41.75,
      "learning_rate": 1.9141190667739344e-05,
      "loss": 1.228,
      "step": 8540
    },
    {
      "epoch": 0.4299074818986323,
      "grad_norm": 9.125,
      "learning_rate": 1.9140185036202736e-05,
      "loss": 0.9201,
      "step": 8550
    },
    {
      "epoch": 0.43041029766693484,
      "grad_norm": 36.5,
      "learning_rate": 1.9139179404666132e-05,
      "loss": 0.8624,
      "step": 8560
    },
    {
      "epoch": 0.4309131134352373,
      "grad_norm": 12.8125,
      "learning_rate": 1.9138173773129528e-05,
      "loss": 1.1639,
      "step": 8570
    },
    {
      "epoch": 0.4314159292035398,
      "grad_norm": 48.5,
      "learning_rate": 1.913716814159292e-05,
      "loss": 0.8888,
      "step": 8580
    },
    {
      "epoch": 0.4319187449718423,
      "grad_norm": 23.125,
      "learning_rate": 1.9136162510056316e-05,
      "loss": 0.9679,
      "step": 8590
    },
    {
      "epoch": 0.4324215607401448,
      "grad_norm": 62.75,
      "learning_rate": 1.9135156878519712e-05,
      "loss": 0.9227,
      "step": 8600
    },
    {
      "epoch": 0.4329243765084473,
      "grad_norm": 15.625,
      "learning_rate": 1.9134151246983105e-05,
      "loss": 1.0606,
      "step": 8610
    },
    {
      "epoch": 0.4334271922767498,
      "grad_norm": 14.9375,
      "learning_rate": 1.9133145615446504e-05,
      "loss": 1.3711,
      "step": 8620
    },
    {
      "epoch": 0.4339300080450523,
      "grad_norm": 23.75,
      "learning_rate": 1.9132139983909896e-05,
      "loss": 1.304,
      "step": 8630
    },
    {
      "epoch": 0.4344328238133548,
      "grad_norm": 10.0625,
      "learning_rate": 1.9131134352373292e-05,
      "loss": 1.2273,
      "step": 8640
    },
    {
      "epoch": 0.43493563958165726,
      "grad_norm": 20.25,
      "learning_rate": 1.9130128720836688e-05,
      "loss": 1.1622,
      "step": 8650
    },
    {
      "epoch": 0.4354384553499598,
      "grad_norm": 13.0,
      "learning_rate": 1.912912308930008e-05,
      "loss": 0.9036,
      "step": 8660
    },
    {
      "epoch": 0.43594127111826225,
      "grad_norm": 17.75,
      "learning_rate": 1.9128117457763477e-05,
      "loss": 0.9222,
      "step": 8670
    },
    {
      "epoch": 0.4364440868865648,
      "grad_norm": 24.25,
      "learning_rate": 1.9127111826226872e-05,
      "loss": 0.6133,
      "step": 8680
    },
    {
      "epoch": 0.43694690265486724,
      "grad_norm": 6.28125,
      "learning_rate": 1.9126106194690265e-05,
      "loss": 0.8539,
      "step": 8690
    },
    {
      "epoch": 0.43744971842316976,
      "grad_norm": 21.375,
      "learning_rate": 1.912510056315366e-05,
      "loss": 1.1073,
      "step": 8700
    },
    {
      "epoch": 0.43795253419147223,
      "grad_norm": 28.75,
      "learning_rate": 1.9124094931617057e-05,
      "loss": 1.1409,
      "step": 8710
    },
    {
      "epoch": 0.43845534995977475,
      "grad_norm": 30.5,
      "learning_rate": 1.9123089300080453e-05,
      "loss": 0.989,
      "step": 8720
    },
    {
      "epoch": 0.4389581657280772,
      "grad_norm": 13.3125,
      "learning_rate": 1.912208366854385e-05,
      "loss": 1.1508,
      "step": 8730
    },
    {
      "epoch": 0.43946098149637974,
      "grad_norm": 29.625,
      "learning_rate": 1.912107803700724e-05,
      "loss": 1.114,
      "step": 8740
    },
    {
      "epoch": 0.4399637972646822,
      "grad_norm": 16.625,
      "learning_rate": 1.9120072405470637e-05,
      "loss": 0.8936,
      "step": 8750
    },
    {
      "epoch": 0.44046661303298473,
      "grad_norm": 15.375,
      "learning_rate": 1.9119066773934033e-05,
      "loss": 0.9774,
      "step": 8760
    },
    {
      "epoch": 0.4409694288012872,
      "grad_norm": 63.0,
      "learning_rate": 1.9118061142397425e-05,
      "loss": 1.1199,
      "step": 8770
    },
    {
      "epoch": 0.4414722445695897,
      "grad_norm": 58.75,
      "learning_rate": 1.911705551086082e-05,
      "loss": 0.8529,
      "step": 8780
    },
    {
      "epoch": 0.4419750603378922,
      "grad_norm": 49.75,
      "learning_rate": 1.9116049879324217e-05,
      "loss": 1.2643,
      "step": 8790
    },
    {
      "epoch": 0.4424778761061947,
      "grad_norm": 13.5,
      "learning_rate": 1.9115044247787613e-05,
      "loss": 1.2814,
      "step": 8800
    },
    {
      "epoch": 0.4429806918744972,
      "grad_norm": 13.4375,
      "learning_rate": 1.911403861625101e-05,
      "loss": 1.1046,
      "step": 8810
    },
    {
      "epoch": 0.4434835076427997,
      "grad_norm": 5.71875,
      "learning_rate": 1.91130329847144e-05,
      "loss": 0.9602,
      "step": 8820
    },
    {
      "epoch": 0.44398632341110217,
      "grad_norm": 9.25,
      "learning_rate": 1.9112027353177797e-05,
      "loss": 0.7677,
      "step": 8830
    },
    {
      "epoch": 0.4444891391794047,
      "grad_norm": 7.5625,
      "learning_rate": 1.9111021721641193e-05,
      "loss": 0.9796,
      "step": 8840
    },
    {
      "epoch": 0.44499195494770716,
      "grad_norm": 48.75,
      "learning_rate": 1.9110016090104585e-05,
      "loss": 1.1555,
      "step": 8850
    },
    {
      "epoch": 0.4454947707160097,
      "grad_norm": 6.8125,
      "learning_rate": 1.910901045856798e-05,
      "loss": 0.8604,
      "step": 8860
    },
    {
      "epoch": 0.44599758648431215,
      "grad_norm": 42.25,
      "learning_rate": 1.9108004827031377e-05,
      "loss": 1.484,
      "step": 8870
    },
    {
      "epoch": 0.4465004022526146,
      "grad_norm": 10.3125,
      "learning_rate": 1.9106999195494773e-05,
      "loss": 0.7972,
      "step": 8880
    },
    {
      "epoch": 0.44700321802091714,
      "grad_norm": 54.5,
      "learning_rate": 1.910599356395817e-05,
      "loss": 0.8643,
      "step": 8890
    },
    {
      "epoch": 0.4475060337892196,
      "grad_norm": 6.59375,
      "learning_rate": 1.910498793242156e-05,
      "loss": 1.2997,
      "step": 8900
    },
    {
      "epoch": 0.4480088495575221,
      "grad_norm": 10.125,
      "learning_rate": 1.9103982300884957e-05,
      "loss": 1.0439,
      "step": 8910
    },
    {
      "epoch": 0.4485116653258246,
      "grad_norm": 13.4375,
      "learning_rate": 1.9102976669348353e-05,
      "loss": 0.929,
      "step": 8920
    },
    {
      "epoch": 0.4490144810941271,
      "grad_norm": 9.1875,
      "learning_rate": 1.910197103781175e-05,
      "loss": 1.2822,
      "step": 8930
    },
    {
      "epoch": 0.4495172968624296,
      "grad_norm": 10.9375,
      "learning_rate": 1.910096540627514e-05,
      "loss": 0.9477,
      "step": 8940
    },
    {
      "epoch": 0.4500201126307321,
      "grad_norm": 22.375,
      "learning_rate": 1.9099959774738537e-05,
      "loss": 1.0526,
      "step": 8950
    },
    {
      "epoch": 0.4505229283990346,
      "grad_norm": 17.5,
      "learning_rate": 1.9098954143201933e-05,
      "loss": 0.9101,
      "step": 8960
    },
    {
      "epoch": 0.4510257441673371,
      "grad_norm": 11.0,
      "learning_rate": 1.9097948511665326e-05,
      "loss": 0.9082,
      "step": 8970
    },
    {
      "epoch": 0.45152855993563956,
      "grad_norm": 11.6875,
      "learning_rate": 1.909694288012872e-05,
      "loss": 1.013,
      "step": 8980
    },
    {
      "epoch": 0.4520313757039421,
      "grad_norm": 35.5,
      "learning_rate": 1.9095937248592118e-05,
      "loss": 0.7793,
      "step": 8990
    },
    {
      "epoch": 0.45253419147224455,
      "grad_norm": 21.5,
      "learning_rate": 1.9094931617055513e-05,
      "loss": 1.3949,
      "step": 9000
    },
    {
      "epoch": 0.45253419147224455,
      "eval_accuracy": 0.5107833415964304,
      "eval_loss": 1.0375735759735107,
      "eval_runtime": 465.7876,
      "eval_samples_per_second": 86.606,
      "eval_steps_per_second": 86.606,
      "step": 9000
    },
    {
      "epoch": 0.4530370072405471,
      "grad_norm": 36.0,
      "learning_rate": 1.909392598551891e-05,
      "loss": 1.1965,
      "step": 9010
    },
    {
      "epoch": 0.45353982300884954,
      "grad_norm": 35.75,
      "learning_rate": 1.9092920353982302e-05,
      "loss": 0.9698,
      "step": 9020
    },
    {
      "epoch": 0.45404263877715206,
      "grad_norm": 9.9375,
      "learning_rate": 1.9091914722445698e-05,
      "loss": 1.0362,
      "step": 9030
    },
    {
      "epoch": 0.45454545454545453,
      "grad_norm": 42.5,
      "learning_rate": 1.9090909090909094e-05,
      "loss": 1.1106,
      "step": 9040
    },
    {
      "epoch": 0.45504827031375705,
      "grad_norm": 8.4375,
      "learning_rate": 1.9089903459372486e-05,
      "loss": 1.1679,
      "step": 9050
    },
    {
      "epoch": 0.4555510860820595,
      "grad_norm": 47.5,
      "learning_rate": 1.9088897827835882e-05,
      "loss": 1.0969,
      "step": 9060
    },
    {
      "epoch": 0.45605390185036204,
      "grad_norm": 14.3125,
      "learning_rate": 1.9087892196299278e-05,
      "loss": 1.2004,
      "step": 9070
    },
    {
      "epoch": 0.4565567176186645,
      "grad_norm": 25.25,
      "learning_rate": 1.9086886564762674e-05,
      "loss": 1.2328,
      "step": 9080
    },
    {
      "epoch": 0.45705953338696703,
      "grad_norm": 13.4375,
      "learning_rate": 1.908588093322607e-05,
      "loss": 0.9409,
      "step": 9090
    },
    {
      "epoch": 0.4575623491552695,
      "grad_norm": 34.25,
      "learning_rate": 1.9084875301689462e-05,
      "loss": 0.9461,
      "step": 9100
    },
    {
      "epoch": 0.458065164923572,
      "grad_norm": 62.0,
      "learning_rate": 1.9083869670152858e-05,
      "loss": 1.2634,
      "step": 9110
    },
    {
      "epoch": 0.4585679806918745,
      "grad_norm": 33.75,
      "learning_rate": 1.9082864038616254e-05,
      "loss": 0.9378,
      "step": 9120
    },
    {
      "epoch": 0.459070796460177,
      "grad_norm": 24.25,
      "learning_rate": 1.9081858407079646e-05,
      "loss": 0.7848,
      "step": 9130
    },
    {
      "epoch": 0.4595736122284795,
      "grad_norm": 6.6875,
      "learning_rate": 1.9080852775543042e-05,
      "loss": 0.9517,
      "step": 9140
    },
    {
      "epoch": 0.460076427996782,
      "grad_norm": 5.84375,
      "learning_rate": 1.9079847144006438e-05,
      "loss": 1.0956,
      "step": 9150
    },
    {
      "epoch": 0.46057924376508447,
      "grad_norm": 21.75,
      "learning_rate": 1.9078841512469834e-05,
      "loss": 0.8775,
      "step": 9160
    },
    {
      "epoch": 0.461082059533387,
      "grad_norm": 41.25,
      "learning_rate": 1.907783588093323e-05,
      "loss": 0.8674,
      "step": 9170
    },
    {
      "epoch": 0.46158487530168946,
      "grad_norm": 19.375,
      "learning_rate": 1.9076830249396622e-05,
      "loss": 1.0514,
      "step": 9180
    },
    {
      "epoch": 0.462087691069992,
      "grad_norm": 19.5,
      "learning_rate": 1.9075824617860018e-05,
      "loss": 0.9587,
      "step": 9190
    },
    {
      "epoch": 0.46259050683829445,
      "grad_norm": 38.75,
      "learning_rate": 1.9074818986323414e-05,
      "loss": 1.097,
      "step": 9200
    },
    {
      "epoch": 0.46309332260659697,
      "grad_norm": 73.0,
      "learning_rate": 1.9073813354786807e-05,
      "loss": 1.2164,
      "step": 9210
    },
    {
      "epoch": 0.46359613837489944,
      "grad_norm": 33.0,
      "learning_rate": 1.9072807723250202e-05,
      "loss": 1.4168,
      "step": 9220
    },
    {
      "epoch": 0.46409895414320196,
      "grad_norm": 11.9375,
      "learning_rate": 1.90718020917136e-05,
      "loss": 0.9627,
      "step": 9230
    },
    {
      "epoch": 0.4646017699115044,
      "grad_norm": 18.625,
      "learning_rate": 1.907079646017699e-05,
      "loss": 0.8799,
      "step": 9240
    },
    {
      "epoch": 0.4651045856798069,
      "grad_norm": 15.8125,
      "learning_rate": 1.906979082864039e-05,
      "loss": 1.0375,
      "step": 9250
    },
    {
      "epoch": 0.4656074014481094,
      "grad_norm": 4.90625,
      "learning_rate": 1.9068785197103783e-05,
      "loss": 0.8948,
      "step": 9260
    },
    {
      "epoch": 0.4661102172164119,
      "grad_norm": 17.625,
      "learning_rate": 1.906777956556718e-05,
      "loss": 1.2458,
      "step": 9270
    },
    {
      "epoch": 0.4666130329847144,
      "grad_norm": 51.0,
      "learning_rate": 1.9066773934030574e-05,
      "loss": 0.9732,
      "step": 9280
    },
    {
      "epoch": 0.46711584875301687,
      "grad_norm": 14.5,
      "learning_rate": 1.9065768302493967e-05,
      "loss": 1.1307,
      "step": 9290
    },
    {
      "epoch": 0.4676186645213194,
      "grad_norm": 13.6875,
      "learning_rate": 1.9064762670957363e-05,
      "loss": 0.967,
      "step": 9300
    },
    {
      "epoch": 0.46812148028962186,
      "grad_norm": 32.25,
      "learning_rate": 1.906375703942076e-05,
      "loss": 1.0604,
      "step": 9310
    },
    {
      "epoch": 0.4686242960579244,
      "grad_norm": 18.25,
      "learning_rate": 1.906275140788415e-05,
      "loss": 0.8459,
      "step": 9320
    },
    {
      "epoch": 0.46912711182622685,
      "grad_norm": 22.0,
      "learning_rate": 1.906174577634755e-05,
      "loss": 1.0903,
      "step": 9330
    },
    {
      "epoch": 0.4696299275945294,
      "grad_norm": 48.75,
      "learning_rate": 1.9060740144810943e-05,
      "loss": 1.1277,
      "step": 9340
    },
    {
      "epoch": 0.47013274336283184,
      "grad_norm": 40.0,
      "learning_rate": 1.905973451327434e-05,
      "loss": 0.9395,
      "step": 9350
    },
    {
      "epoch": 0.47063555913113436,
      "grad_norm": 6.21875,
      "learning_rate": 1.9058728881737735e-05,
      "loss": 0.93,
      "step": 9360
    },
    {
      "epoch": 0.47113837489943683,
      "grad_norm": 29.25,
      "learning_rate": 1.9057723250201127e-05,
      "loss": 1.3166,
      "step": 9370
    },
    {
      "epoch": 0.47164119066773935,
      "grad_norm": 34.0,
      "learning_rate": 1.9056717618664523e-05,
      "loss": 0.9168,
      "step": 9380
    },
    {
      "epoch": 0.4721440064360418,
      "grad_norm": 44.0,
      "learning_rate": 1.905571198712792e-05,
      "loss": 1.0779,
      "step": 9390
    },
    {
      "epoch": 0.47264682220434434,
      "grad_norm": 41.25,
      "learning_rate": 1.905470635559131e-05,
      "loss": 0.8738,
      "step": 9400
    },
    {
      "epoch": 0.4731496379726468,
      "grad_norm": 27.125,
      "learning_rate": 1.905370072405471e-05,
      "loss": 0.9966,
      "step": 9410
    },
    {
      "epoch": 0.47365245374094933,
      "grad_norm": 61.5,
      "learning_rate": 1.9052695092518103e-05,
      "loss": 1.3641,
      "step": 9420
    },
    {
      "epoch": 0.4741552695092518,
      "grad_norm": 13.6875,
      "learning_rate": 1.90516894609815e-05,
      "loss": 0.9884,
      "step": 9430
    },
    {
      "epoch": 0.4746580852775543,
      "grad_norm": 10.4375,
      "learning_rate": 1.9050683829444895e-05,
      "loss": 1.0463,
      "step": 9440
    },
    {
      "epoch": 0.4751609010458568,
      "grad_norm": 4.9375,
      "learning_rate": 1.9049678197908287e-05,
      "loss": 0.8838,
      "step": 9450
    },
    {
      "epoch": 0.4756637168141593,
      "grad_norm": 51.0,
      "learning_rate": 1.9048672566371683e-05,
      "loss": 0.8219,
      "step": 9460
    },
    {
      "epoch": 0.4761665325824618,
      "grad_norm": 42.25,
      "learning_rate": 1.904766693483508e-05,
      "loss": 1.2924,
      "step": 9470
    },
    {
      "epoch": 0.4766693483507643,
      "grad_norm": 17.875,
      "learning_rate": 1.904666130329847e-05,
      "loss": 0.7876,
      "step": 9480
    },
    {
      "epoch": 0.47717216411906677,
      "grad_norm": 21.0,
      "learning_rate": 1.9045655671761867e-05,
      "loss": 1.0719,
      "step": 9490
    },
    {
      "epoch": 0.4776749798873693,
      "grad_norm": 8.25,
      "learning_rate": 1.9044650040225263e-05,
      "loss": 1.0151,
      "step": 9500
    },
    {
      "epoch": 0.4776749798873693,
      "eval_accuracy": 0.5104610808130887,
      "eval_loss": 1.034855604171753,
      "eval_runtime": 466.3895,
      "eval_samples_per_second": 86.494,
      "eval_steps_per_second": 86.494,
      "step": 9500
    },
    {
      "epoch": 0.47817779565567176,
      "grad_norm": 51.0,
      "learning_rate": 1.9043644408688656e-05,
      "loss": 1.219,
      "step": 9510
    },
    {
      "epoch": 0.4786806114239743,
      "grad_norm": 9.25,
      "learning_rate": 1.9042638777152055e-05,
      "loss": 1.0742,
      "step": 9520
    },
    {
      "epoch": 0.47918342719227675,
      "grad_norm": 29.25,
      "learning_rate": 1.9041633145615448e-05,
      "loss": 0.8912,
      "step": 9530
    },
    {
      "epoch": 0.47968624296057927,
      "grad_norm": 17.25,
      "learning_rate": 1.9040627514078843e-05,
      "loss": 1.0665,
      "step": 9540
    },
    {
      "epoch": 0.48018905872888173,
      "grad_norm": 28.375,
      "learning_rate": 1.903962188254224e-05,
      "loss": 1.1278,
      "step": 9550
    },
    {
      "epoch": 0.48069187449718426,
      "grad_norm": 10.25,
      "learning_rate": 1.9038616251005632e-05,
      "loss": 1.1241,
      "step": 9560
    },
    {
      "epoch": 0.4811946902654867,
      "grad_norm": 29.25,
      "learning_rate": 1.9037610619469028e-05,
      "loss": 0.9313,
      "step": 9570
    },
    {
      "epoch": 0.48169750603378925,
      "grad_norm": 18.25,
      "learning_rate": 1.9036604987932424e-05,
      "loss": 1.1297,
      "step": 9580
    },
    {
      "epoch": 0.4822003218020917,
      "grad_norm": 71.5,
      "learning_rate": 1.9035599356395816e-05,
      "loss": 1.1165,
      "step": 9590
    },
    {
      "epoch": 0.4827031375703942,
      "grad_norm": 23.0,
      "learning_rate": 1.9034593724859215e-05,
      "loss": 0.93,
      "step": 9600
    },
    {
      "epoch": 0.4832059533386967,
      "grad_norm": 65.0,
      "learning_rate": 1.9033588093322608e-05,
      "loss": 0.8615,
      "step": 9610
    },
    {
      "epoch": 0.48370876910699917,
      "grad_norm": 37.5,
      "learning_rate": 1.9032582461786004e-05,
      "loss": 0.8139,
      "step": 9620
    },
    {
      "epoch": 0.4842115848753017,
      "grad_norm": 20.5,
      "learning_rate": 1.90315768302494e-05,
      "loss": 1.2609,
      "step": 9630
    },
    {
      "epoch": 0.48471440064360416,
      "grad_norm": 12.8125,
      "learning_rate": 1.9030571198712792e-05,
      "loss": 0.9516,
      "step": 9640
    },
    {
      "epoch": 0.4852172164119067,
      "grad_norm": 33.0,
      "learning_rate": 1.9029565567176188e-05,
      "loss": 1.1764,
      "step": 9650
    },
    {
      "epoch": 0.48572003218020915,
      "grad_norm": 22.625,
      "learning_rate": 1.9028559935639584e-05,
      "loss": 1.2671,
      "step": 9660
    },
    {
      "epoch": 0.48622284794851167,
      "grad_norm": 23.0,
      "learning_rate": 1.9027554304102976e-05,
      "loss": 1.1002,
      "step": 9670
    },
    {
      "epoch": 0.48672566371681414,
      "grad_norm": 64.5,
      "learning_rate": 1.9026548672566376e-05,
      "loss": 1.049,
      "step": 9680
    },
    {
      "epoch": 0.48722847948511666,
      "grad_norm": 15.75,
      "learning_rate": 1.9025543041029768e-05,
      "loss": 0.9913,
      "step": 9690
    },
    {
      "epoch": 0.48773129525341913,
      "grad_norm": 49.0,
      "learning_rate": 1.9024537409493164e-05,
      "loss": 1.1387,
      "step": 9700
    },
    {
      "epoch": 0.48823411102172165,
      "grad_norm": 22.5,
      "learning_rate": 1.902353177795656e-05,
      "loss": 1.103,
      "step": 9710
    },
    {
      "epoch": 0.4887369267900241,
      "grad_norm": 23.375,
      "learning_rate": 1.9022526146419952e-05,
      "loss": 0.8626,
      "step": 9720
    },
    {
      "epoch": 0.48923974255832664,
      "grad_norm": 42.75,
      "learning_rate": 1.9021520514883348e-05,
      "loss": 1.0339,
      "step": 9730
    },
    {
      "epoch": 0.4897425583266291,
      "grad_norm": 14.8125,
      "learning_rate": 1.9020514883346744e-05,
      "loss": 0.8951,
      "step": 9740
    },
    {
      "epoch": 0.49024537409493163,
      "grad_norm": 34.25,
      "learning_rate": 1.9019509251810137e-05,
      "loss": 1.2779,
      "step": 9750
    },
    {
      "epoch": 0.4907481898632341,
      "grad_norm": 17.125,
      "learning_rate": 1.9018503620273532e-05,
      "loss": 1.1898,
      "step": 9760
    },
    {
      "epoch": 0.4912510056315366,
      "grad_norm": 19.125,
      "learning_rate": 1.901749798873693e-05,
      "loss": 0.9314,
      "step": 9770
    },
    {
      "epoch": 0.4917538213998391,
      "grad_norm": 22.125,
      "learning_rate": 1.901649235720032e-05,
      "loss": 0.9469,
      "step": 9780
    },
    {
      "epoch": 0.4922566371681416,
      "grad_norm": 30.375,
      "learning_rate": 1.901548672566372e-05,
      "loss": 1.0304,
      "step": 9790
    },
    {
      "epoch": 0.4927594529364441,
      "grad_norm": 10.625,
      "learning_rate": 1.9014481094127113e-05,
      "loss": 1.0151,
      "step": 9800
    },
    {
      "epoch": 0.4932622687047466,
      "grad_norm": 21.875,
      "learning_rate": 1.901347546259051e-05,
      "loss": 0.7649,
      "step": 9810
    },
    {
      "epoch": 0.49376508447304907,
      "grad_norm": 26.375,
      "learning_rate": 1.9012469831053904e-05,
      "loss": 0.9071,
      "step": 9820
    },
    {
      "epoch": 0.4942679002413516,
      "grad_norm": 14.3125,
      "learning_rate": 1.9011464199517297e-05,
      "loss": 1.0004,
      "step": 9830
    },
    {
      "epoch": 0.49477071600965405,
      "grad_norm": 8.5,
      "learning_rate": 1.9010458567980693e-05,
      "loss": 0.8321,
      "step": 9840
    },
    {
      "epoch": 0.4952735317779566,
      "grad_norm": 10.9375,
      "learning_rate": 1.900945293644409e-05,
      "loss": 1.0412,
      "step": 9850
    },
    {
      "epoch": 0.49577634754625904,
      "grad_norm": 26.0,
      "learning_rate": 1.900844730490748e-05,
      "loss": 0.8688,
      "step": 9860
    },
    {
      "epoch": 0.49627916331456157,
      "grad_norm": 12.5,
      "learning_rate": 1.900744167337088e-05,
      "loss": 0.8936,
      "step": 9870
    },
    {
      "epoch": 0.49678197908286403,
      "grad_norm": 11.875,
      "learning_rate": 1.9006436041834273e-05,
      "loss": 1.2581,
      "step": 9880
    },
    {
      "epoch": 0.49728479485116656,
      "grad_norm": 20.5,
      "learning_rate": 1.900543041029767e-05,
      "loss": 0.9878,
      "step": 9890
    },
    {
      "epoch": 0.497787610619469,
      "grad_norm": 21.125,
      "learning_rate": 1.9004424778761065e-05,
      "loss": 0.9876,
      "step": 9900
    },
    {
      "epoch": 0.49829042638777155,
      "grad_norm": 8.25,
      "learning_rate": 1.9003419147224457e-05,
      "loss": 0.9665,
      "step": 9910
    },
    {
      "epoch": 0.498793242156074,
      "grad_norm": 24.125,
      "learning_rate": 1.9002413515687853e-05,
      "loss": 1.3668,
      "step": 9920
    },
    {
      "epoch": 0.49929605792437654,
      "grad_norm": 6.875,
      "learning_rate": 1.900140788415125e-05,
      "loss": 0.7967,
      "step": 9930
    },
    {
      "epoch": 0.499798873692679,
      "grad_norm": 15.4375,
      "learning_rate": 1.900040225261464e-05,
      "loss": 0.9284,
      "step": 9940
    },
    {
      "epoch": 0.5003016894609815,
      "grad_norm": 18.5,
      "learning_rate": 1.899939662107804e-05,
      "loss": 0.9197,
      "step": 9950
    },
    {
      "epoch": 0.500804505229284,
      "grad_norm": 25.875,
      "learning_rate": 1.8998390989541433e-05,
      "loss": 0.9592,
      "step": 9960
    },
    {
      "epoch": 0.5013073209975865,
      "grad_norm": 28.0,
      "learning_rate": 1.899738535800483e-05,
      "loss": 1.2216,
      "step": 9970
    },
    {
      "epoch": 0.5018101367658889,
      "grad_norm": 20.75,
      "learning_rate": 1.8996379726468225e-05,
      "loss": 1.1536,
      "step": 9980
    },
    {
      "epoch": 0.5023129525341915,
      "grad_norm": 54.25,
      "learning_rate": 1.8995374094931617e-05,
      "loss": 1.3039,
      "step": 9990
    },
    {
      "epoch": 0.502815768302494,
      "grad_norm": 18.5,
      "learning_rate": 1.8994368463395013e-05,
      "loss": 0.9787,
      "step": 10000
    },
    {
      "epoch": 0.502815768302494,
      "eval_accuracy": 0.5106346058502726,
      "eval_loss": 1.0351945161819458,
      "eval_runtime": 466.2164,
      "eval_samples_per_second": 86.526,
      "eval_steps_per_second": 86.526,
      "step": 10000
    },
    {
      "epoch": 0.5033185840707964,
      "grad_norm": 19.75,
      "learning_rate": 1.899336283185841e-05,
      "loss": 0.9965,
      "step": 10010
    },
    {
      "epoch": 0.5038213998390989,
      "grad_norm": 21.125,
      "learning_rate": 1.89923572003218e-05,
      "loss": 1.0149,
      "step": 10020
    },
    {
      "epoch": 0.5043242156074015,
      "grad_norm": 5.09375,
      "learning_rate": 1.8991351568785197e-05,
      "loss": 0.9242,
      "step": 10030
    },
    {
      "epoch": 0.504827031375704,
      "grad_norm": 17.375,
      "learning_rate": 1.8990345937248593e-05,
      "loss": 1.2138,
      "step": 10040
    },
    {
      "epoch": 0.5053298471440064,
      "grad_norm": 5.9375,
      "learning_rate": 1.898934030571199e-05,
      "loss": 0.8992,
      "step": 10050
    },
    {
      "epoch": 0.5058326629123089,
      "grad_norm": 13.0,
      "learning_rate": 1.8988334674175385e-05,
      "loss": 1.0119,
      "step": 10060
    },
    {
      "epoch": 0.5063354786806115,
      "grad_norm": 22.0,
      "learning_rate": 1.8987329042638778e-05,
      "loss": 0.798,
      "step": 10070
    },
    {
      "epoch": 0.5068382944489139,
      "grad_norm": 5.59375,
      "learning_rate": 1.8986323411102173e-05,
      "loss": 1.0676,
      "step": 10080
    },
    {
      "epoch": 0.5073411102172164,
      "grad_norm": 52.5,
      "learning_rate": 1.898531777956557e-05,
      "loss": 1.0114,
      "step": 10090
    },
    {
      "epoch": 0.5078439259855189,
      "grad_norm": 14.3125,
      "learning_rate": 1.8984312148028962e-05,
      "loss": 1.0609,
      "step": 10100
    },
    {
      "epoch": 0.5083467417538214,
      "grad_norm": 76.0,
      "learning_rate": 1.8983306516492358e-05,
      "loss": 0.9045,
      "step": 10110
    },
    {
      "epoch": 0.5088495575221239,
      "grad_norm": 60.0,
      "learning_rate": 1.8982300884955754e-05,
      "loss": 1.2703,
      "step": 10120
    },
    {
      "epoch": 0.5093523732904264,
      "grad_norm": 44.0,
      "learning_rate": 1.898129525341915e-05,
      "loss": 0.9816,
      "step": 10130
    },
    {
      "epoch": 0.5098551890587288,
      "grad_norm": 11.3125,
      "learning_rate": 1.8980289621882545e-05,
      "loss": 1.0559,
      "step": 10140
    },
    {
      "epoch": 0.5103580048270314,
      "grad_norm": 11.875,
      "learning_rate": 1.8979283990345938e-05,
      "loss": 0.7811,
      "step": 10150
    },
    {
      "epoch": 0.5108608205953339,
      "grad_norm": 7.46875,
      "learning_rate": 1.8978278358809334e-05,
      "loss": 0.9885,
      "step": 10160
    },
    {
      "epoch": 0.5113636363636364,
      "grad_norm": 23.625,
      "learning_rate": 1.897727272727273e-05,
      "loss": 1.1783,
      "step": 10170
    },
    {
      "epoch": 0.5118664521319388,
      "grad_norm": 21.25,
      "learning_rate": 1.8976267095736122e-05,
      "loss": 1.1508,
      "step": 10180
    },
    {
      "epoch": 0.5123692679002414,
      "grad_norm": 14.4375,
      "learning_rate": 1.8975261464199518e-05,
      "loss": 0.7945,
      "step": 10190
    },
    {
      "epoch": 0.5128720836685439,
      "grad_norm": 38.75,
      "learning_rate": 1.8974255832662914e-05,
      "loss": 1.182,
      "step": 10200
    },
    {
      "epoch": 0.5133748994368463,
      "grad_norm": 19.375,
      "learning_rate": 1.897325020112631e-05,
      "loss": 0.8987,
      "step": 10210
    },
    {
      "epoch": 0.5138777152051488,
      "grad_norm": 10.1875,
      "learning_rate": 1.8972244569589706e-05,
      "loss": 0.994,
      "step": 10220
    },
    {
      "epoch": 0.5143805309734514,
      "grad_norm": 21.25,
      "learning_rate": 1.8971238938053098e-05,
      "loss": 0.9795,
      "step": 10230
    },
    {
      "epoch": 0.5148833467417538,
      "grad_norm": 31.0,
      "learning_rate": 1.8970233306516494e-05,
      "loss": 1.0142,
      "step": 10240
    },
    {
      "epoch": 0.5153861625100563,
      "grad_norm": 27.625,
      "learning_rate": 1.896922767497989e-05,
      "loss": 1.1256,
      "step": 10250
    },
    {
      "epoch": 0.5158889782783588,
      "grad_norm": 11.4375,
      "learning_rate": 1.8968222043443282e-05,
      "loss": 1.1286,
      "step": 10260
    },
    {
      "epoch": 0.5163917940466614,
      "grad_norm": 23.625,
      "learning_rate": 1.8967216411906678e-05,
      "loss": 1.1225,
      "step": 10270
    },
    {
      "epoch": 0.5168946098149638,
      "grad_norm": 47.75,
      "learning_rate": 1.8966210780370074e-05,
      "loss": 1.25,
      "step": 10280
    },
    {
      "epoch": 0.5173974255832663,
      "grad_norm": 33.25,
      "learning_rate": 1.896520514883347e-05,
      "loss": 1.1116,
      "step": 10290
    },
    {
      "epoch": 0.5179002413515688,
      "grad_norm": 22.5,
      "learning_rate": 1.8964199517296862e-05,
      "loss": 0.6778,
      "step": 10300
    },
    {
      "epoch": 0.5184030571198712,
      "grad_norm": 48.25,
      "learning_rate": 1.896319388576026e-05,
      "loss": 0.957,
      "step": 10310
    },
    {
      "epoch": 0.5189058728881738,
      "grad_norm": 4.5,
      "learning_rate": 1.8962188254223654e-05,
      "loss": 1.1111,
      "step": 10320
    },
    {
      "epoch": 0.5194086886564763,
      "grad_norm": 43.0,
      "learning_rate": 1.896118262268705e-05,
      "loss": 1.0707,
      "step": 10330
    },
    {
      "epoch": 0.5199115044247787,
      "grad_norm": 21.625,
      "learning_rate": 1.8960176991150443e-05,
      "loss": 0.8648,
      "step": 10340
    },
    {
      "epoch": 0.5204143201930812,
      "grad_norm": 38.75,
      "learning_rate": 1.895917135961384e-05,
      "loss": 0.766,
      "step": 10350
    },
    {
      "epoch": 0.5209171359613838,
      "grad_norm": 12.0,
      "learning_rate": 1.8958165728077234e-05,
      "loss": 1.0474,
      "step": 10360
    },
    {
      "epoch": 0.5214199517296862,
      "grad_norm": 37.75,
      "learning_rate": 1.895716009654063e-05,
      "loss": 1.0527,
      "step": 10370
    },
    {
      "epoch": 0.5219227674979887,
      "grad_norm": 5.0625,
      "learning_rate": 1.8956154465004023e-05,
      "loss": 1.2607,
      "step": 10380
    },
    {
      "epoch": 0.5224255832662912,
      "grad_norm": 8.25,
      "learning_rate": 1.895514883346742e-05,
      "loss": 0.8445,
      "step": 10390
    },
    {
      "epoch": 0.5229283990345938,
      "grad_norm": 26.875,
      "learning_rate": 1.8954143201930815e-05,
      "loss": 1.0285,
      "step": 10400
    },
    {
      "epoch": 0.5234312148028962,
      "grad_norm": 28.0,
      "learning_rate": 1.895313757039421e-05,
      "loss": 1.4137,
      "step": 10410
    },
    {
      "epoch": 0.5239340305711987,
      "grad_norm": 6.5625,
      "learning_rate": 1.8952131938857603e-05,
      "loss": 1.0679,
      "step": 10420
    },
    {
      "epoch": 0.5244368463395012,
      "grad_norm": 17.0,
      "learning_rate": 1.8951126307321e-05,
      "loss": 0.9416,
      "step": 10430
    },
    {
      "epoch": 0.5249396621078037,
      "grad_norm": 65.0,
      "learning_rate": 1.8950120675784395e-05,
      "loss": 1.0251,
      "step": 10440
    },
    {
      "epoch": 0.5254424778761062,
      "grad_norm": 14.3125,
      "learning_rate": 1.894911504424779e-05,
      "loss": 1.2048,
      "step": 10450
    },
    {
      "epoch": 0.5259452936444087,
      "grad_norm": 12.1875,
      "learning_rate": 1.8948109412711183e-05,
      "loss": 0.9678,
      "step": 10460
    },
    {
      "epoch": 0.5264481094127111,
      "grad_norm": 28.25,
      "learning_rate": 1.894710378117458e-05,
      "loss": 1.3121,
      "step": 10470
    },
    {
      "epoch": 0.5269509251810137,
      "grad_norm": 18.125,
      "learning_rate": 1.8946098149637975e-05,
      "loss": 1.1789,
      "step": 10480
    },
    {
      "epoch": 0.5274537409493162,
      "grad_norm": 33.75,
      "learning_rate": 1.894509251810137e-05,
      "loss": 0.9325,
      "step": 10490
    },
    {
      "epoch": 0.5279565567176187,
      "grad_norm": 10.75,
      "learning_rate": 1.8944086886564763e-05,
      "loss": 1.1319,
      "step": 10500
    },
    {
      "epoch": 0.5279565567176187,
      "eval_accuracy": 0.5112543381259296,
      "eval_loss": 1.0339479446411133,
      "eval_runtime": 465.1461,
      "eval_samples_per_second": 86.725,
      "eval_steps_per_second": 86.725,
      "step": 10500
    },
    {
      "epoch": 0.5284593724859211,
      "grad_norm": 9.75,
      "learning_rate": 1.894308125502816e-05,
      "loss": 1.4224,
      "step": 10510
    },
    {
      "epoch": 0.5289621882542237,
      "grad_norm": 10.1875,
      "learning_rate": 1.8942075623491555e-05,
      "loss": 0.937,
      "step": 10520
    },
    {
      "epoch": 0.5294650040225262,
      "grad_norm": 20.0,
      "learning_rate": 1.894106999195495e-05,
      "loss": 0.9158,
      "step": 10530
    },
    {
      "epoch": 0.5299678197908286,
      "grad_norm": 6.84375,
      "learning_rate": 1.8940064360418343e-05,
      "loss": 1.0714,
      "step": 10540
    },
    {
      "epoch": 0.5304706355591311,
      "grad_norm": 25.125,
      "learning_rate": 1.893905872888174e-05,
      "loss": 1.2289,
      "step": 10550
    },
    {
      "epoch": 0.5309734513274337,
      "grad_norm": 70.0,
      "learning_rate": 1.8938053097345135e-05,
      "loss": 1.3075,
      "step": 10560
    },
    {
      "epoch": 0.5314762670957361,
      "grad_norm": 33.25,
      "learning_rate": 1.8937047465808528e-05,
      "loss": 1.114,
      "step": 10570
    },
    {
      "epoch": 0.5319790828640386,
      "grad_norm": 11.75,
      "learning_rate": 1.8936041834271923e-05,
      "loss": 0.8508,
      "step": 10580
    },
    {
      "epoch": 0.5324818986323411,
      "grad_norm": 25.5,
      "learning_rate": 1.893503620273532e-05,
      "loss": 0.9953,
      "step": 10590
    },
    {
      "epoch": 0.5329847144006437,
      "grad_norm": 39.25,
      "learning_rate": 1.8934030571198715e-05,
      "loss": 1.2255,
      "step": 10600
    },
    {
      "epoch": 0.5334875301689461,
      "grad_norm": 32.75,
      "learning_rate": 1.893302493966211e-05,
      "loss": 1.0123,
      "step": 10610
    },
    {
      "epoch": 0.5339903459372486,
      "grad_norm": 21.125,
      "learning_rate": 1.8932019308125504e-05,
      "loss": 0.9988,
      "step": 10620
    },
    {
      "epoch": 0.5344931617055511,
      "grad_norm": 40.0,
      "learning_rate": 1.89310136765889e-05,
      "loss": 0.9863,
      "step": 10630
    },
    {
      "epoch": 0.5349959774738536,
      "grad_norm": 14.875,
      "learning_rate": 1.8930008045052295e-05,
      "loss": 0.8027,
      "step": 10640
    },
    {
      "epoch": 0.5354987932421561,
      "grad_norm": 29.0,
      "learning_rate": 1.8929002413515688e-05,
      "loss": 1.098,
      "step": 10650
    },
    {
      "epoch": 0.5360016090104586,
      "grad_norm": 35.75,
      "learning_rate": 1.8927996781979087e-05,
      "loss": 1.0168,
      "step": 10660
    },
    {
      "epoch": 0.536504424778761,
      "grad_norm": 28.375,
      "learning_rate": 1.892699115044248e-05,
      "loss": 1.1876,
      "step": 10670
    },
    {
      "epoch": 0.5370072405470635,
      "grad_norm": 41.5,
      "learning_rate": 1.8925985518905875e-05,
      "loss": 1.1681,
      "step": 10680
    },
    {
      "epoch": 0.5375100563153661,
      "grad_norm": 25.625,
      "learning_rate": 1.892497988736927e-05,
      "loss": 0.8655,
      "step": 10690
    },
    {
      "epoch": 0.5380128720836685,
      "grad_norm": 15.0,
      "learning_rate": 1.8923974255832664e-05,
      "loss": 0.802,
      "step": 10700
    },
    {
      "epoch": 0.538515687851971,
      "grad_norm": 37.25,
      "learning_rate": 1.892296862429606e-05,
      "loss": 1.0533,
      "step": 10710
    },
    {
      "epoch": 0.5390185036202735,
      "grad_norm": 14.75,
      "learning_rate": 1.8921962992759456e-05,
      "loss": 1.1517,
      "step": 10720
    },
    {
      "epoch": 0.5395213193885761,
      "grad_norm": 10.0625,
      "learning_rate": 1.8920957361222848e-05,
      "loss": 0.7469,
      "step": 10730
    },
    {
      "epoch": 0.5400241351568785,
      "grad_norm": 12.9375,
      "learning_rate": 1.8919951729686247e-05,
      "loss": 0.8551,
      "step": 10740
    },
    {
      "epoch": 0.540526950925181,
      "grad_norm": 16.75,
      "learning_rate": 1.891894609814964e-05,
      "loss": 0.9784,
      "step": 10750
    },
    {
      "epoch": 0.5410297666934835,
      "grad_norm": 25.25,
      "learning_rate": 1.8917940466613036e-05,
      "loss": 0.6296,
      "step": 10760
    },
    {
      "epoch": 0.541532582461786,
      "grad_norm": 45.25,
      "learning_rate": 1.891693483507643e-05,
      "loss": 0.9257,
      "step": 10770
    },
    {
      "epoch": 0.5420353982300885,
      "grad_norm": 13.0625,
      "learning_rate": 1.8915929203539824e-05,
      "loss": 1.2737,
      "step": 10780
    },
    {
      "epoch": 0.542538213998391,
      "grad_norm": 60.75,
      "learning_rate": 1.891492357200322e-05,
      "loss": 1.1031,
      "step": 10790
    },
    {
      "epoch": 0.5430410297666934,
      "grad_norm": 21.0,
      "learning_rate": 1.8913917940466616e-05,
      "loss": 1.1281,
      "step": 10800
    },
    {
      "epoch": 0.543543845534996,
      "grad_norm": 88.5,
      "learning_rate": 1.8912912308930008e-05,
      "loss": 1.237,
      "step": 10810
    },
    {
      "epoch": 0.5440466613032985,
      "grad_norm": 51.0,
      "learning_rate": 1.8911906677393404e-05,
      "loss": 1.1597,
      "step": 10820
    },
    {
      "epoch": 0.544549477071601,
      "grad_norm": 6.875,
      "learning_rate": 1.89109010458568e-05,
      "loss": 0.9978,
      "step": 10830
    },
    {
      "epoch": 0.5450522928399034,
      "grad_norm": 42.5,
      "learning_rate": 1.8909895414320193e-05,
      "loss": 1.0994,
      "step": 10840
    },
    {
      "epoch": 0.545555108608206,
      "grad_norm": 5.71875,
      "learning_rate": 1.8908889782783592e-05,
      "loss": 0.7362,
      "step": 10850
    },
    {
      "epoch": 0.5460579243765085,
      "grad_norm": 19.5,
      "learning_rate": 1.8907884151246984e-05,
      "loss": 1.0743,
      "step": 10860
    },
    {
      "epoch": 0.5465607401448109,
      "grad_norm": 49.25,
      "learning_rate": 1.890687851971038e-05,
      "loss": 1.1288,
      "step": 10870
    },
    {
      "epoch": 0.5470635559131134,
      "grad_norm": 33.25,
      "learning_rate": 1.8905872888173776e-05,
      "loss": 1.2567,
      "step": 10880
    },
    {
      "epoch": 0.547566371681416,
      "grad_norm": 9.8125,
      "learning_rate": 1.890486725663717e-05,
      "loss": 0.8506,
      "step": 10890
    },
    {
      "epoch": 0.5480691874497184,
      "grad_norm": 19.0,
      "learning_rate": 1.8903861625100564e-05,
      "loss": 0.8912,
      "step": 10900
    },
    {
      "epoch": 0.5485720032180209,
      "grad_norm": 24.0,
      "learning_rate": 1.890285599356396e-05,
      "loss": 0.8131,
      "step": 10910
    },
    {
      "epoch": 0.5490748189863234,
      "grad_norm": 12.9375,
      "learning_rate": 1.8901850362027353e-05,
      "loss": 0.6741,
      "step": 10920
    },
    {
      "epoch": 0.549577634754626,
      "grad_norm": 62.75,
      "learning_rate": 1.8900844730490752e-05,
      "loss": 1.4142,
      "step": 10930
    },
    {
      "epoch": 0.5500804505229284,
      "grad_norm": 9.1875,
      "learning_rate": 1.8899839098954145e-05,
      "loss": 1.1467,
      "step": 10940
    },
    {
      "epoch": 0.5505832662912309,
      "grad_norm": 14.375,
      "learning_rate": 1.889883346741754e-05,
      "loss": 0.9077,
      "step": 10950
    },
    {
      "epoch": 0.5510860820595334,
      "grad_norm": 8.0,
      "learning_rate": 1.8897827835880936e-05,
      "loss": 0.8574,
      "step": 10960
    },
    {
      "epoch": 0.5515888978278359,
      "grad_norm": 30.25,
      "learning_rate": 1.889682220434433e-05,
      "loss": 0.7793,
      "step": 10970
    },
    {
      "epoch": 0.5520917135961384,
      "grad_norm": 36.0,
      "learning_rate": 1.8895816572807725e-05,
      "loss": 0.936,
      "step": 10980
    },
    {
      "epoch": 0.5525945293644409,
      "grad_norm": 6.6875,
      "learning_rate": 1.889481094127112e-05,
      "loss": 0.7789,
      "step": 10990
    },
    {
      "epoch": 0.5530973451327433,
      "grad_norm": 7.3125,
      "learning_rate": 1.8893805309734513e-05,
      "loss": 0.9668,
      "step": 11000
    },
    {
      "epoch": 0.5530973451327433,
      "eval_accuracy": 0.5116757560733763,
      "eval_loss": 1.0370365381240845,
      "eval_runtime": 464.6848,
      "eval_samples_per_second": 86.812,
      "eval_steps_per_second": 86.812,
      "step": 11000
    }
  ],
  "logging_steps": 10,
  "max_steps": 198880,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "total_flos": 0.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
